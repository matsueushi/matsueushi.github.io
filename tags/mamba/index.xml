<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mamba on matsueushi</title>
    <link>https://matsueushi.github.io/tags/mamba/</link>
    <description>Recent content in Mamba on matsueushi</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 17 Apr 2019 21:44:20 -0400</lastBuildDate>
    
	<atom:link href="https://matsueushi.github.io/tags/mamba/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Juliaで体験するベイズ推論(7) - The Price Is Right</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-7/</link>
      <pubDate>Wed, 17 Apr 2019 21:44:20 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-7/</guid>
      <description>引き続き「Pythonで体験するベイズ推論」のJulia+Mambaによる実装に挑戦している。わざわざ特別Mediumに書くような題材は無いな、と思っていたのだが、第5章の「例題 : テレビ番組 “The Price Is Right”の最適化」のモデリング( pm.potential が出てくるところ)でちょっと詰まったので、Mambaでの実装について記しておく。
問題を単純化すると、
 二つの賞品A, Bの合計価格(これを真の価格と今後呼ぶ)を予想したい 真の価格は正規分布 \( \text{Normal}(35000, 7500^2) \) に従うと仮定する 賞品A, Bの価格の事前分布はそれぞれ正規分布 \( \text{Normal}(12000, 3000^2) \) , \( \text{Normal}(3000,500^2) \) に従うと仮定する このような条件のモデリングである。  実際にモデリングをやってみて、賞品A, Bの事前分布と、その和をモデリングするところまでは下のようにすればいいので簡単であるのだが、( using 等は略した)真の価格の分布とサンプリングした賞品A, Bの価格の分布の和を結びつける段階で、はて？？？となった。
data = Dict{Symbol, Any}( :data_mu =&amp;gt; [3e3, 12e3], :data_std =&amp;gt; [5e2, 3e3], :mu_prior =&amp;gt; 35e3, :std_prior =&amp;gt; 75e2, ) model = Model( prize = Stochastic(1, (data_mu, data_std) -&amp;gt; MvNormal(data_mu, data_std)), price_estimate = Logical(prize -&amp;gt; sum(prize)), ) モデルを下のようにしてしまうと、</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(6) -スペースシャトル「チャレンジャー号」の悲劇</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-6/</link>
      <pubDate>Wed, 10 Apr 2019 00:24:53 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-6/</guid>
      <description>最近はGaussianRandomWalkを使った時系列ベイズモデルの推定に挑戦していたが、あまりうまくいかなかったので一旦「Pythonで体験するベイズ推論」に戻ろうと思う。
今回は「Pythonで体験するベイズ推論」の「2.2.27 例題 カンニングした学生の割合」をJuliaで実装した内容を紹介する。
まずはライブラリのインポート
using Distributed addprocs(3) using CSV using DataFrames using HTTP using LaTeXStrings using LinearAlgebra @everywhere using Mamba using Plots データの加工はこのような形で行った。DataFrame で Int64 にパースしたい行にMissing valueやNaNがあるとき、convertではエラーになるので、 パースできない場合は missing になる tryparse を使って、その後 nothing になる行を削除して、Union{Nothing, Int64} から Int64 にもう一度変換している。
r = HTTP.request(&amp;#34;GET&amp;#34;, &amp;#34;https://git.io/vXknD&amp;#34;); challengers_data = CSV.read(IOBuffer(r.body)) names!(challengers_data, [:date, :temperature, :incident]) # incidentのパース challengers_data[:incident] = tryparse.(Int64, challengers_data[:incident]) # NaNを削除 challengers_data = challengers_data[challengers_data[:incident] .!= nothing, :] challengers_data[:incident] = convert.(Int64, challengers_data[:incident]) disallowmissing!(challengers_data) データの図示をする。weighted_color_mean を使って、マーカーの色を青から赤にグラデーションさせた。</description>
    </item>
    
    <item>
      <title>Mamba.jlでGaussianRandomWalkを作って使う</title>
      <link>https://matsueushi.github.io/posts/mamba-gaussianrandomwalk/</link>
      <pubDate>Wed, 03 Apr 2019 21:52:38 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/mamba-gaussianrandomwalk/</guid>
      <description>PyMC3にはTimeseriesとして GaussianRandomWalk などの時系列モデルが実装されている。
https://docs.pymc.io/api/distributions/timeseries.html#pymc3.distributions.timeseries.GaussianRandomWalk
だが残念なことに私が使っているMamba.jl(0.12.1)には時系列モデルがない。下のように cumsum を使ってモデルを作成することは可能ではあるが、面倒だし次元が大きくなってきたりモデルが複雑になってくると遅い。
local_level_model = Model( obs = Stochastic(1, (N, T, sigma_I) -&amp;gt; MvNormal(T, sigma_I), false ), T = Logical(1, (T_0, disturbance) -&amp;gt; T_0 .+ vcat([0], cumsum(disturbance)), ), disturbance = Stochastic(1, (N, sigma_T) -&amp;gt; MvNormal(N - 1, sigma_T), false ), sigma_I = Stochastic(() -&amp;gt; InverseGamma()), sigma_T = Stochastic(() -&amp;gt; InverseGamma()), T_0 = Stochastic(T_init -&amp;gt; Normal(T_init, 100)), ) だからと言ってそのためにわざわざPython+PyMC3に移るのも癪だし、練習を兼ねてJulia+Mamba用の確率分布を試しに作ってみようと思ったのが今回の内容である。幸いなことに、Mamba.jlには作り方のガイドラインが書いてあるので、多変量分布用のガイドラインを参考にして作ることができた。
今回は、GaussianRandomWalk は、初期値の分布 \( D \) とドリフト \( \mu_i \) , 分散 \( \sigma \) とした時に、</description>
    </item>
    
    <item>
      <title>Mamba.jl v0.12.0のStackOverflowError:</title>
      <link>https://matsueushi.github.io/posts/mamba-v-0-12-0/</link>
      <pubDate>Sun, 31 Mar 2019 21:47:30 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/mamba-v-0-12-0/</guid>
      <description>GCPに環境を作っていて気づいたのだが、Distibution.jlのv0.17.0と関数が干渉していて using Mamba すると下のようなワーニングが出て、
WARNING: Method definition (::Type{Distributions.DiscreteNonParametric{Int64, P, Base.OneTo{Int64}, Ps} where Ps where P})(AbstractArray{T&amp;lt;:Real, 1}) where {T&amp;lt;:Real} in module Distributions at /Users/apple/.julia/packages/Distributions/fMt8c/src/univariate/discrete/categorical.jl:40 overwritten in module Mamba at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:7. WARNING: Method definition (::Type{Distributions.MvNormal{T, Cov, Mean} where Mean&amp;lt;:(AbstractArray{T, 1} where T) where Cov&amp;lt;:(PDMats.AbstractPDMat{T} where T&amp;lt;:Real) where T&amp;lt;:Real})(AbstractArray{T&amp;lt;:Real, 1}, Real) where {T&amp;lt;:Real} in module Distributions at /Users/apple/.julia/packages/Distributions/fMt8c/src/multivariate/mvnormal.jl:200 overwritten in module Mamba at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:35. WARNING: Method definition (::Type{Distributions.MvNormalCanon{T, P, V} where V&amp;lt;:(AbstractArray{T, 1} where T) where P&amp;lt;:(PDMats.</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(5) -嘘に対抗するアルゴリズム</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-5/</link>
      <pubDate>Fri, 22 Mar 2019 21:22:17 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-5/</guid>
      <description>「Pythonで体験するベイズ推論」の「2.2.7 例題 カンニングした学生の割合」をやってみよう。
学生が試験中にカンニングする頻度を求めたい。観測データは個人がカンニングしたかどうかは特定できない、以下のアルゴリズムを用いる。
 コイントスを(こっそり)行い、表が出たら正直に答える 裏が出た場合、もう一枚コインを(こっそり)投げ、表が出たら「カンニングした」と答え、裏が出たら「カンニングしなかった」と答える。   カンニングが全くなければ、「カンニングした」という回答がある確率は 1/2 * 1/2 = 1/4, 全員カンニングしていれば 1/2 + 1/2 * 1/2 = 3/4 になる。
まずはライブラリをインポート。
using Distributed addprocs(3) @everywhere using Mamba using Plots 学生の数が100人、「カンニングした」という回答が35人とする。
N = 100 X = 35 Mambaのモデルは次のようになる。
model = Model( obs = Stochastic( (proportion, N) -&amp;gt; Binomial(N, proportion), false ), proportion = Logical( (true_answers, first_coin_flips, second_coin_flips) -&amp;gt; (observed = @.(first_coin_flips * true_answers + (1 - first_coin_flips) * second_coin_flips); mean(observed)), false ), true_answers = Stochastic(1, p -&amp;gt; Bernoulli(p), false), first_coin_flips = Stochastic(1, () -&amp;gt; Bernoulli(0.</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(4) -ベイズ的 A/B</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-4/</link>
      <pubDate>Thu, 21 Mar 2019 21:05:35 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-4/</guid>
      <description>今回はMambaを使って、「Pythonで体験するベイズ推論」の「例題 : ベイズ的 A/B」 をモデリングする。
例題 : ベイズ的 A/B テスト A/Bテストの例題を解いてみよう。
サイトAを見せられたユーザーが最終的にコンバージョンにつながる確率を \( p_A \)と仮定し、\( N \) 人がサイトAを見せられて、そのうち \( n \) 人がコンバージョンにつながったとする。
まずはベルヌーイ分布を使って、\( N \) 回の試行をシミュレートする。
# 定数をセット p_true = 0.05 N = 1500 occurrences = rand(Bernoulli(p_true), N) Mamba.jlで推論アルゴリズムを作成すると、次のようになる。\( p \) の事前分布は \( [0, 1] \) の一様分布に従うとしている。
model0 = Model( obs = Stochastic(1, (p, N) -&amp;gt; UnivariateDistribution[Bernoulli(p) for _ in 1:N], false), p = Stochastic(() -&amp;gt; Uniform()), ) モデルは、等価な次の形で書いた方が単純になってわかりやすいかもしれない。
model0 = Model( obs = Stochastic(1, p -&amp;gt; Bernoulli(p), false), p = Stochastic(() -&amp;gt; Uniform()), ) 観測データと初期値を作ってサンプリングし、</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(3) -新しいデータセットの生成</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-3/</link>
      <pubDate>Wed, 20 Mar 2019 20:58:08 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-3/</guid>
      <description>引き続き「Pythonで体験するベイズ推論」の第2章の新しいデータセットの作成をJuliaでやってみる。
新しいデータセットの生成 PyMCについての説明はスキップして、シミュレーションによるメッセージ数のデータ生成から行う。
Mamba.jlは分布の作成にDistributions.jlを使っているので、シミュレーションだけ行いたかったらDistributionsを using すれば十分。
using Distributions using Plots データセットの作成とプロットは下のようになる。
function plot_artificial_sms_dataset() tau = rand(DiscreteUniform(0, 80)) theta = 20 lambda_1, lambda_2 = rand(Exponential(theta), 2) lambda_ = cat(fill(lambda_1, tau), fill(lambda_2, 80 - tau), dims = 1) data = @.rand(Poisson(lambda_)) barc = fill(1, 80) barc[tau] = 2 bar(0:80-1, data, linecolor = :transparent, fillcolor = barc, xlabel = &amp;#34;Time(days)&amp;#34;, ylabel = &amp;#34;Countofmessages&amp;#34;, label = &amp;#34;&amp;#34;) end plts = [] for i in 1:4 push!</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(2) -メッセージ数に変化はあるか？ </title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-2/</link>
      <pubDate>Wed, 20 Mar 2019 20:45:02 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-2/</guid>
      <description>前回に引き続き、「Pythonで体験するベイズ推論」をJuliaでやってみる。本に従い、前回作成した「メッセージ数に変化はあるか？」を二つの変化点の場合に拡張する。
変化点が二つの場合を考えてみる。モデルは変化点が一つの場合とほぼ同じで、
model2 = Model( obs = Stochastic(1, (lambda, N) -&amp;gt; UnivariateDistribution[Poisson(lambda[i]) for i in 1:N], false ), lambda = Logical(1, (lambda1, lambda2, lambda3, tau1, tau2, N) -&amp;gt; (out = fill(lambda1, N); i1 = Int64(tau1.value) + 1; # Juliaは1-indexingのため i2 = Int64(tau2.value) + 1; out[i1:end] .= lambda2; out[i2:end] .= lambda3; out), false, ), lambda1 = Stochastic(theta -&amp;gt; Exponential(theta)), lambda2 = Stochastic(theta -&amp;gt; Exponential(theta)), lambda3 = Stochastic(theta -&amp;gt; Exponential(theta)), tau1 = Stochastic(N -&amp;gt; DiscreteUniform(0, N-1)), tau2 = Stochastic((tau1, N) -&amp;gt; DiscreteUniform(tau1, N)), ) 初期値とサンプリングスキームを同様に与えてサンプリングすると、</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(1) -メッセージ数に変化はあるか？</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-1/</link>
      <pubDate>Tue, 19 Mar 2019 23:30:41 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-1/</guid>
      <description>久保拓弥「データ解析のための統計モデリング入門」を読み終えたので、次はCameron Davidson-Pilon著、玉木徹訳の「Pythonで体験するベイズ推論」(GitHubリポジトリ) をJuliaとMamba.jlでモデリングしていきたいと思う。
まず例題1.4.1の「メッセージ数に変化はあるか？」をやってみる。
元のノートブックはこれ。
JuliaでCSVファイルをhttps上から取るには、パッケージ HTTP , CSV をインポートして
r = HTTP.request(&amp;#34;GET&amp;#34;, &amp;#34;https://git.io/vXTVC&amp;#34;); count_data = CSV.read(IOBuffer(r.body), header=[&amp;#34;messages&amp;#34;]) とすれば良い。 Plotsでプロットすると下のような感じ。Juliaはインデックスが1から始まるので、x軸を 0:N-1 にしておく。
N = length(count_data.messages) bar(0:N-1, count_data.messages, label = &amp;#34;&amp;#34;, size = [600, 200], linecolor = :transparent, xlabel = &amp;#34;Time(days)&amp;#34;, ylabel = &amp;#34;Countofmessages&amp;#34;) \( i \) 日目のメッセージ数 \( C_i \) がポアソン分布 \( \text{Poisson}(\lambda) \) に従い、\( \lambda \) の値が突然ある日 \( \lambda \) で変わる日があるとする。\( \tau &amp;lt; \lambda \) のとき \( \lambda = \lambda_1, \tau \ge \lambda \) の時 \( \lambda=\lambda_2 \)とする。</description>
    </item>
    
    <item>
      <title>Julia版「データ解析のための統計モデリング入門」読書ノート</title>
      <link>https://matsueushi.github.io/posts/julia-kubo/</link>
      <pubDate>Mon, 04 Mar 2019 23:01:57 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/julia-kubo/</guid>
      <description>最近、久保拓弥「データ解析のための統計モデリング入門――一般化線形モデル・階層ベイズモデル・MCMC (確率と情報の科学)を読んでいる。
 生態学のデータ解析 - 久保拓弥
http://hosho.ees.hokudai.ac.jp/~kubo/ce/KuboTakuya.html
 本ではR + WinBUGSを使っているが、今回はJulia(1.1.0) + Mambaを使って実装した(10章まで)。実装はGithubに載せてある。
 実装の中身は上のJupyter Notebookを見てもらうとして、それ以外に実装していて何点か躓いたことがあったので備忘のために記載しておく。
Binomial分布のGLM  formula で指定する説明変数は、0から1の間になっている必要がある。個体の数で割って、wtsに個体の数を指定してフィッティングを行う。
df.yy = df.y ./ df.N df.N = convert(Array{Float64}, df.N) result = glm(@formula(yy ~ x + f), df, Binomial(), wts = df.N) モデルのグラフ表示 Mambaのチュートリアルではモデルのグラフ表示にGraphViz.jlパッケージを使っている。
ただGraphViz.jlはメンテナンスが止まっているようで、Julia v0.7以降では動かないようである。
ForneyLab.jlがGraphViz.jlの後継としてモデルのグラフ表示をサポートしているので、こちらを使用すれば良い。
Multiprocessing Mambaは addproc でプロセスを追加して、
using Distributed addprocs(3) Mambaをインポートするときに @everywhere を付ければMambaが自動的にMCMCのチェインごとのサンプリングを並列化してくれる。(section10.ipynb参照)
@everywhere using Mamba 11章の空間構造のある階層ベイズモデル(intrinsic Gaussian CARモデル)も実装できたらアップデートしたい。
3/14追記: 11章の空間構造のある階層ベイズモデルも実装したのでアップデートした。これで一通り読破したことになるのかな？次は以前読もうとして諦めた「Pythonで体験するベイズ推論」をJuliaでやってみようか。</description>
    </item>
    
  </channel>
</rss>