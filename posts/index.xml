<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on matsueushi</title>
    <link>https://matsueushi.github.io/posts/</link>
    <description>Recent content in Blog on matsueushi</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Thu, 27 Jun 2019 00:55:38 -0400</lastBuildDate>
    
	<atom:link href="https://matsueushi.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>ガウス過程の補助変数法 (Inducing variable method) を理解する</title>
      <link>https://matsueushi.github.io/posts/sparse-approximate-gp/</link>
      <pubDate>Thu, 27 Jun 2019 00:55:38 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/sparse-approximate-gp/</guid>
      <description>6&amp;frasl;27 追記: \( p(\mathbf{y} | \mathbf{f}) \) の誤字を修正, \( q_{\text{FITC}}(\mathbf{f}_* | \mathbf{y}) \) の二番目の等号を修正 (\( \sigma^{-2} \)) を削除
「ガウス過程と機械学習」を読んでいるが、5.2補助変数法のところで、どの部分で近似が行われているのかよく分からなくなってしまった。
そのため、今回は原論文であるQuinonero Candela, J. and Rasmussen, CE.の &amp;ldquo;A Unifying View of Sparse Approximate Gaussian Process Regression&amp;rdquo; を読んでスパース近似についてまとめて見ようと思う。ゴールは、The Fully Independent Training Conditional (FITC) の理解である。
\( \mathbf{X}=(\mathbf{x}_1, \ldots, \mathbf{x}_N) \) を学習データ、 \( \mathbf{y}=(y_1, \ldots, y_N)^\top \) を観測値とする。学習データと観測値の関係は、ガウス過程から生成される関数 \( f \) と誤差 \( \epsilon_n \) を用いて
$$ y_n = f(\mathbf{x_n}) + \epsilon_n,$$ $$\epsilon_n \sim \mathcal{N}(0, \sigma^2)$$</description>
    </item>
    
    <item>
      <title>Softman - 500ms (2018)</title>
      <link>https://matsueushi.github.io/posts/softman-500ms/</link>
      <pubDate>Sun, 16 Jun 2019 16:20:34 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/softman-500ms/</guid>
      <description>500ms by Softman たまたまbandcampを徘徊していたら出会ったGlitch。
言葉で表現するのが難しいのだが、パソコンとか家電の起動音とか動作音とかの一番綺麗な部分が切り取られて、ノイズと共に閉じ込められて音楽になったような感じだろうか……
シンガポールのアンビエントレーベルEvening Chantsというところからリリースされていて、フィジカルはカセットテープのみ。 
レーベルは2018年の9月に立ち上がったばかりで、他のリリースも配信とカセットテープなので何かこだわりがあるのかと思ったが、 このような記事もあったので、アンビエント界隈ではカセットテープリリースというのがよくあることなのかもしれない。
ロンドンベースのミュージシャンということ以外Softmanの素性は不明(bandcampに写真は載っている)で、 Twitterやウェブサイトでの言及もほとんど見つからず、謎が多い。
 “The track listings avoids implying anything or to artificially making you feel something - just face value. It’s not meant to be about anything,”
https://softman.bandcamp.com/album/500ms
 と書かれているので、細かいことは追求せず純粋にノイズの美しい揺らめきに耳を傾けよう。
好きな曲: 500ms_07, 500ms_12, 500ms_22</description>
    </item>
    
    <item>
      <title>Juliaでガウス過程を実装&amp;パラメーター推定</title>
      <link>https://matsueushi.github.io/posts/gp-parameter-estimation/</link>
      <pubDate>Sat, 08 Jun 2019 20:08:12 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/gp-parameter-estimation/</guid>
      <description>「ガウス過程と機械学習」を3章まで読み終えたので、復習を兼ねてJulia(1.1.0)でガウス過程を実装し、 カーネルのハイパーパラメーターをOptim.jlで推定するところまでをまとめる。数学的に細かい内容は本を読んで欲しい。 図3.23の陸上男子100mの世界記録の回帰モデルを作成することを今回の目標とする。
ガウスカーネルによる回帰: ガウスカーネル＋線形カーネルによる回帰: 任意の有限の入力 \( x_1, \ldots , x_n \) を与えたときに、出力 \( (f(x_1), \ldots , f(x_n)) \) が平均 \( (\mu(x_1), \ldots , \mu(x_n)) \) 分散 \( (k(x_n, x_{nm} )) \) のガウス分布に従う時、 \( f \) をガウス過程と呼び、 \( f \sim \text{GP} (\mu(x), k(x, x^\prime)) \) と書く。そして \( \mu \) を平均関数、 \( k \) をカーネル関数と呼んでいるのであった。
今回は本と同様、簡単のために平均関数が恒等的に0となるものだけを考える。
ガウスカーネルの定義 もっとも基本的なカーネルであるガウスカーネルを定義して、ガウス過程を構成する。ガウスカーネルのカーネル関数は次のものとする。 $$ k(x, x^\prime ) = \exp \left( -\frac{|x-x^\prime|^2}{\theta}\right) $$ 本文では $$ k(x, x^\prime ) = \theta_1 \exp \left( -\frac{|x-x^\prime|^2}{\theta_2}\right) $$ この形で紹介されていたが、後々カーネルの線型結合を考えるのでここでは \( exp \) の前に係数を付けない前者を採用する。</description>
    </item>
    
    <item>
      <title>GitHub Pagesに引っ越した</title>
      <link>https://matsueushi.github.io/posts/hugo/</link>
      <pubDate>Thu, 06 Jun 2019 22:48:39 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/hugo/</guid>
      <description>過去のポストをこっちのGitHub Pagesに移行させた。疲れた。</description>
    </item>
    
    <item>
      <title>KaTeXで複数行の数式を入力</title>
      <link>https://matsueushi.github.io/posts/katex-multiline/</link>
      <pubDate>Wed, 05 Jun 2019 22:19:14 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/katex-multiline/</guid>
      <description>結構手間取った。
バックスラッシュを4つ重ねた後スペースを置く \\\\ と改行できる。
\\( \begin{aligned} x &amp;amp;= 1+1 \\\\ &amp;amp;= 2 \end{aligned} \\) 結果:
\( \begin{aligned} x &amp;amp;= 1+1 \\ &amp;amp;= 2 \end{aligned} \)
参考 :
&amp;gt; Cannot achieve line break in multiline equation (LaTeX/Mathjax)
&amp;gt; https://github.com/gcushen/hugo-academic/wiki/FAQ</description>
    </item>
    
    <item>
      <title>KaTeX Test</title>
      <link>https://matsueushi.github.io/posts/katex-test/</link>
      <pubDate>Sat, 01 Jun 2019 21:05:25 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/katex-test/</guid>
      <description>KaTeX Test
\( \lim \sum \int \)
Katexでは \( \varprojlim \) はサポートされていない
_ではなく\_を使うと \( x_{mn} \)などの添字が出せる</description>
    </item>
    
    <item>
      <title>ガウス過程と機械学習: 3.5まで</title>
      <link>https://matsueushi.github.io/posts/gp-nlp-2/</link>
      <pubDate>Sun, 19 May 2019 22:37:52 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/gp-nlp-2/</guid>
      <description>引き続き「ガウス過程と機械学習(第二刷)」を読み進めJuliaで実装している。
ハイパーパラメーターの最適化(勾配を使わず、Optim.jlの optimize を使ってしまった)のところまで読み進めた。
 3.4.2のガウス過程回帰の計算を行う際、予測分布の分散共分散行列が計算誤差の影響で対称行列にならずエラーが発生することがあったので、場合によっては対称化が必要。 図3.16のガウスカーネル
\( \begin{aligned} k(x, x^\prime) = \theta_1 \exp \left( - \frac{|x-x^\prime|^2}{\theta_2} \right) \end{aligned} \) のパラメーター推定で、\( (\theta_1, \theta_2, \theta_3)=(1, 0.4, 0.1) \) とすると下のようになり本と違ってしまった。  \( (\theta_1, \theta_2, \theta_3)=(1, 0.4, 0.01) \) とすると近い図になる(全く同じには見えない)
 尤度の計算が合わなかった。尤度を図示した図3.16で-5未満を切り捨てるとうまくいかなかった。20以下を切り捨てると近い図になった。  本文の局所解(ii)に該当する点の尤度は-2.0299となり本文の-1.934とは違ってしまった。
図3.20のパラメーター推定は正しくできたが、こちらも対数尤度が違ってしまった((a):本文-1.788、実装-1.738, (b):本文-2.174, 実装-2.5029) 詳細は下のレポジトリ、ノートブックを見て下さい。更新は下のMedium用のブランチではなく、masterの方に行う予定です。
https://github.com/matsueushi/gp_and_mlp/tree/blog-2019-05-19
https://nbviewer.jupyter.org/github/matsueushi/gp_and_mlp/blob/blog-2019-05-19/gp.ipynb</description>
    </item>
    
    <item>
      <title>「ガウス過程と機械学習 」を読み始めた</title>
      <link>https://matsueushi.github.io/posts/gp-nlp-1/</link>
      <pubDate>Fri, 10 May 2019 22:30:45 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/gp-nlp-1/</guid>
      <description>持橋・大羽の「ガウス過程と機会学習」を読み始めた。Juliaでコードを書きながら内容を確かめている。
本を読むまで定義も理解していなかったレベルだったが、無限次元のガウス分布を考えるというモチベーションから「有限次元に制限すれば(通常の)ガウス分布になるもの」としてガウス過程の定義が出てくるのは非常に自然だと思った。
分散共分散行列の成分を作る時に使われるカーネル \( k(x,x^\prime) \) は \( x \) と \(x^\prime \) の「近さ」を表す関数とでも考えれば良いのだろうか。
なんでそういうことを考えるのかという気持ちの部分が丁寧に説明されているので意図がわからずに数式の中に闇雲に迷い込むことなく今の所楽しく読み進められている。
エラッタ:
http://chasen.org/~daiti-m/gpbook/errata.html
https://scrapbox.io/GPandML2019/support
3.3の「ガウス過程とカーネル」のところまで読んだ。
自分が躓いた点
 “3.2.4 ガウス過程からのサンプル”で図3.9のようなサンプルを実装するときは正則化項を入れないと計算がうまくいかないことがある(1.4 リッジ回帰の部分で触れられている)。著者のサンプルコードでは非常に正則化項として1e-6を導入していた。共分散行列の計算の際に対角成分に正規化項を加えればよい。 “3.3.1 ガウス過程のRBFカーネル”で、線形モデルの基底関数のグリッドを無限に細かくするとRBFカーネルになると書かれている部分は、本文中の基底関数を使うと \( H \rightarrow \infty \) とした時にカーネル関数がRBF関数に収束しない。基底関数に \( 1 / \sqrt{H} \) を掛けたものを考えればOK “3.3.2 さまざまなカーネル”で線形カーネルを実装するときに、カーネル関数は dot(x1, x2) ではなく、必ず1となる入力の最初の次元も考慮して 1 + dot(x1, x2) とする。他のカーネルの場合は x1 — x2 の計算の段階で消えるので考慮する必要はない また、Matérnカーネルを定義する際に、Juliaでは第二種のベッセル関数は SpecialFunctions の besselk を使えば良い。ベッセル関数は \( x=0 \) で特異性を持つので、カーネル関数 k(x1, x2) を定義するときは x1 = x2 の時に条件分岐で1を返すようにすればいい  カーネルとガウシアン過程を定義したjlファイル:</description>
    </item>
    
    <item>
      <title>Distribution.jlで分布をシフト・スケールさせる</title>
      <link>https://matsueushi.github.io/posts/shift-scale-distribution/</link>
      <pubDate>Tue, 30 Apr 2019 21:58:27 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/shift-scale-distribution/</guid>
      <description>公式ドキュメントでは記述が見つけられなかったが、 LocationScale を使えば良いっぽい。
 Distributions.jl/src/univariate/continuous/locationscale.jl https://github.com/JuliaStats/Distributions.jl/blob/master/src/univariate/continuous/locationscale.jl
 例えば、PyMC3の StudentT
pm.StudentT(&amp;#39;x&amp;#39;, nu=nu, mu=mu, lam=lam) に対応する分布をDistribution.jlで使いたいとき、Distribution.jlでの TDist のパラメトライズは nu だけで mu や lam は指定できないが、
LocationScale(mu, lam, TDist(nu)) とすればOK。PyMCの StudentT に出ている pdf と同じグラフを書いて確認しよう。
using Distributions using Plots using Printf # StudentT分布のシフト x = -8:0.01:8 mu = [0, 0, -2, -2] lam = [1, 1, 1, 2] nu = [1, 5, 5, 5] plt = Plots.plot() for i in 1:4 y = pdf.(LocationScale(mu[i], lam[i], TDist(nu[i])), x) Plots.</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(7) - The Price Is Right</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-7/</link>
      <pubDate>Wed, 17 Apr 2019 21:44:20 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-7/</guid>
      <description>引き続き「Pythonで体験するベイズ推論」のJulia+Mambaによる実装に挑戦している。わざわざ特別Mediumに書くような題材は無いな、と思っていたのだが、第5章の「例題 : テレビ番組 “The Price Is Right”の最適化」のモデリング( pm.potential が出てくるところ)でちょっと詰まったので、Mambaでの実装について記しておく。
問題を単純化すると、
 二つの賞品A, Bの合計価格(これを真の価格と今後呼ぶ)を予想したい 真の価格は正規分布 \( \text{Normal}(35000, 7500^2) \) に従うと仮定する 賞品A, Bの価格の事前分布はそれぞれ正規分布 \( \text{Normal}(12000, 3000^2) \) , \( \text{Normal}(3000,500^2) \) に従うと仮定する このような条件のモデリングである。  実際にモデリングをやってみて、賞品A, Bの事前分布と、その和をモデリングするところまでは下のようにすればいいので簡単であるのだが、( using 等は略した)真の価格の分布とサンプリングした賞品A, Bの価格の分布の和を結びつける段階で、はて？？？となった。
data = Dict{Symbol, Any}( :data_mu =&amp;gt; [3e3, 12e3], :data_std =&amp;gt; [5e2, 3e3], :mu_prior =&amp;gt; 35e3, :std_prior =&amp;gt; 75e2, ) model = Model( prize = Stochastic(1, (data_mu, data_std) -&amp;gt; MvNormal(data_mu, data_std)), price_estimate = Logical(prize -&amp;gt; sum(prize)), ) モデルを下のようにしてしまうと、</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(6) -スペースシャトル「チャレンジャー号」の悲劇</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-6/</link>
      <pubDate>Wed, 10 Apr 2019 00:24:53 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-6/</guid>
      <description>最近はGaussianRandomWalkを使った時系列ベイズモデルの推定に挑戦していたが、あまりうまくいかなかったので一旦「Pythonで体験するベイズ推論」に戻ろうと思う。
今回は「Pythonで体験するベイズ推論」の「2.2.27 例題 カンニングした学生の割合」をJuliaで実装した内容を紹介する。
まずはライブラリのインポート
using Distributed addprocs(3) using CSV using DataFrames using HTTP using LaTeXStrings using LinearAlgebra @everywhere using Mamba using Plots データの加工はこのような形で行った。DataFrame で Int64 にパースしたい行にMissing valueやNaNがあるとき、convertではエラーになるので、 パースできない場合は missing になる tryparse を使って、その後 nothing になる行を削除して、Union{Nothing, Int64} から Int64 にもう一度変換している。
r = HTTP.request(&amp;#34;GET&amp;#34;, &amp;#34;https://git.io/vXknD&amp;#34;); challengers_data = CSV.read(IOBuffer(r.body)) names!(challengers_data, [:date, :temperature, :incident]) # incidentのパース challengers_data[:incident] = tryparse.(Int64, challengers_data[:incident]) # NaNを削除 challengers_data = challengers_data[challengers_data[:incident] .!= nothing, :] challengers_data[:incident] = convert.(Int64, challengers_data[:incident]) disallowmissing!(challengers_data) データの図示をする。weighted_color_mean を使って、マーカーの色を青から赤にグラデーションさせた。</description>
    </item>
    
    <item>
      <title>JuliaでRollingWindow</title>
      <link>https://matsueushi.github.io/posts/rollingwindow/</link>
      <pubDate>Sun, 07 Apr 2019 00:29:01 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/rollingwindow/</guid>
      <description>Pandasの pd.rolling のようなことをJuliaで行うためのメモ
https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html
 複雑なことがやりたければこれを使えば良さそうだ。
 JeffreySarnoff/RollingFunctions.jl
https://github.com/JeffreySarnoff/RollingFunctions.jl
 </description>
    </item>
    
    <item>
      <title>Juliaの2次元のArrayを1次元にする / Juliaの3次元のArrayを2次元にする</title>
      <link>https://matsueushi.github.io/posts/julia-array-dim/</link>
      <pubDate>Fri, 05 Apr 2019 00:20:33 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/julia-array-dim/</guid>
      <description>やり方がよくわからなくなるので自分用メモを兼ねて。JuliaのVersion は1.1.0 (2019–01–21)。
2次元 julia&amp;gt; x = [1 2; 3 4] 2×2 Array{Int64,2}: 1 2 3 4 縦方向に拾っていきたいときは簡単で、 vec
julia&amp;gt; vec(x) 4-element Array{Int64,1}: 1 3 2 4 横方向に拾いたい場合は permutedims を噛ませる。
julia&amp;gt; vec(permutedims(x)) 4-element Array{Int64,1}: 1 2 3 4 &amp;nbsp;transpose と collect を使う
julia&amp;gt; vec(collect(transpose(x))) 4-element Array{Int64,1}: 1 2 3 4 だと場合によっては問題があり、 Transpose は LinearAlgebra の操作なので、例えば Array{Char, 2} に対しては定義されていないので実行できない。
julia&amp;gt; [&amp;#39;a&amp;#39; &amp;#39;b&amp;#39;;&amp;#39;c&amp;#39; &amp;#39;d&amp;#39;] 2×2 Array{Char,2}: &amp;#39;a&amp;#39; &amp;#39;b&amp;#39; &amp;#39;c&amp;#39; &amp;#39;d&amp;#39; julia&amp;gt; transpose([&amp;#39;a&amp;#39; &amp;#39;b&amp;#39;;&amp;#39;c&amp;#39; &amp;#39;d&amp;#39;]) 2×2 LinearAlgebra.</description>
    </item>
    
    <item>
      <title>Mamba.jlでGaussianRandomWalkを作って使う</title>
      <link>https://matsueushi.github.io/posts/mamba-gaussianrandomwalk/</link>
      <pubDate>Wed, 03 Apr 2019 21:52:38 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/mamba-gaussianrandomwalk/</guid>
      <description>PyMC3にはTimeseriesとして GaussianRandomWalk などの時系列モデルが実装されている。
https://docs.pymc.io/api/distributions/timeseries.html#pymc3.distributions.timeseries.GaussianRandomWalk
だが残念なことに私が使っているMamba.jl(0.12.1)には時系列モデルがない。下のように cumsum を使ってモデルを作成することは可能ではあるが、面倒だし次元が大きくなってきたりモデルが複雑になってくると遅い。
local_level_model = Model( obs = Stochastic(1, (N, T, sigma_I) -&amp;gt; MvNormal(T, sigma_I), false ), T = Logical(1, (T_0, disturbance) -&amp;gt; T_0 .+ vcat([0], cumsum(disturbance)), ), disturbance = Stochastic(1, (N, sigma_T) -&amp;gt; MvNormal(N - 1, sigma_T), false ), sigma_I = Stochastic(() -&amp;gt; InverseGamma()), sigma_T = Stochastic(() -&amp;gt; InverseGamma()), T_0 = Stochastic(T_init -&amp;gt; Normal(T_init, 100)), ) だからと言ってそのためにわざわざPython+PyMC3に移るのも癪だし、練習を兼ねてJulia+Mamba用の確率分布を試しに作ってみようと思ったのが今回の内容である。幸いなことに、Mamba.jlには作り方のガイドラインが書いてあるので、多変量分布用のガイドラインを参考にして作ることができた。
今回は、GaussianRandomWalk は、初期値の分布 \( D \) とドリフト \( \mu_i \) , 分散 \( \sigma \) とした時に、</description>
    </item>
    
    <item>
      <title>Mamba.jl v0.12.0のStackOverflowError:</title>
      <link>https://matsueushi.github.io/posts/mamba-v-0-12-0/</link>
      <pubDate>Sun, 31 Mar 2019 21:47:30 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/mamba-v-0-12-0/</guid>
      <description>GCPに環境を作っていて気づいたのだが、Distibution.jlのv0.17.0と関数が干渉していて using Mamba すると下のようなワーニングが出て、
WARNING: Method definition (::Type{Distributions.DiscreteNonParametric{Int64, P, Base.OneTo{Int64}, Ps} where Ps where P})(AbstractArray{T&amp;lt;:Real, 1}) where {T&amp;lt;:Real} in module Distributions at /Users/apple/.julia/packages/Distributions/fMt8c/src/univariate/discrete/categorical.jl:40 overwritten in module Mamba at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:7. WARNING: Method definition (::Type{Distributions.MvNormal{T, Cov, Mean} where Mean&amp;lt;:(AbstractArray{T, 1} where T) where Cov&amp;lt;:(PDMats.AbstractPDMat{T} where T&amp;lt;:Real) where T&amp;lt;:Real})(AbstractArray{T&amp;lt;:Real, 1}, Real) where {T&amp;lt;:Real} in module Distributions at /Users/apple/.julia/packages/Distributions/fMt8c/src/multivariate/mvnormal.jl:200 overwritten in module Mamba at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:35. WARNING: Method definition (::Type{Distributions.MvNormalCanon{T, P, V} where V&amp;lt;:(AbstractArray{T, 1} where T) where P&amp;lt;:(PDMats.</description>
    </item>
    
    <item>
      <title>GCPでJuliaのノートブックを実行</title>
      <link>https://matsueushi.github.io/posts/gcp-julia/</link>
      <pubDate>Sat, 30 Mar 2019 21:37:57 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/gcp-julia/</guid>
      <description>自分用メモ
ローカルの公開鍵をGCPのインスタンスに登録
 [秘密鍵/公開鍵]GCPにSSHで接続する方法
https://sleepless-se.net/2018/09/15/gcp-ssh/
 Juliaのバイナリをダウンロード
curl -OL https://julialang-s3.julialang.org/bin/linux/x64/1.1/julia-1.1.0-linux-x86_64.tar.gz 解凍
$ sudo mkdir /bin/julia $ sudo tar xvzf julia-1.1.0-linux-x86_64.tar.gz -C /bin/julia $ /bin/julia/julia-1.1.0/bin/julia _ _ _ _(_)_ | Documentation: https://docs.julialang.org (_) | (_) (_) | _ _ _| |_ __ _ | Type &amp;#34;?&amp;#34; for help, &amp;#34;]?&amp;#34; for Pkg help. | | | | | | |/ _` | | | | |_| | | | (_| | | Version 1.</description>
    </item>
    
    <item>
      <title>Plots.jlでx軸、y軸のスケールを揃える</title>
      <link>https://matsueushi.github.io/posts/plotly-scale/</link>
      <pubDate>Sun, 24 Mar 2019 21:43:34 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/plotly-scale/</guid>
      <description>&amp;nbsp;aspece_ratio=1 とすれば良いだけだった。簡単だった。
using Distributions using Plots x = y = 0:0.5:5 exp_x = Exponential(3) exp_y = Exponential(10) z = Surface((s, t) -&amp;gt; pdf(exp_x, s) * pdf(exp_y, t), x, y) heatmap(x, y, z) heatmap(x, y, z, aspect_ratio = 1) </description>
    </item>
    
    <item>
      <title>Arrayを横に並べてMatrixにする</title>
      <link>https://matsueushi.github.io/posts/julia-array-matrix/</link>
      <pubDate>Sat, 23 Mar 2019 21:36:07 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/julia-array-matrix/</guid>
      <description>自分用メモ。Juliaで Array を横に並べて Matrix にする方法は、repeat で第1引数を1にして、第2引数を並べたい個数にすればいい。
julia&amp;gt; xs = [1, 2, 3, 4, 5] 5-element Array{Int64,1}: 1 2 3 4 5 julia&amp;gt; repeat([1, 2, 3, 4, 5], 1, 4) 5×4 Array{Int64,2}: 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(5) -嘘に対抗するアルゴリズム</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-5/</link>
      <pubDate>Fri, 22 Mar 2019 21:22:17 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-5/</guid>
      <description>「Pythonで体験するベイズ推論」の「2.2.7 例題 カンニングした学生の割合」をやってみよう。
学生が試験中にカンニングする頻度を求めたい。観測データは個人がカンニングしたかどうかは特定できない、以下のアルゴリズムを用いる。
 コイントスを(こっそり)行い、表が出たら正直に答える 裏が出た場合、もう一枚コインを(こっそり)投げ、表が出たら「カンニングした」と答え、裏が出たら「カンニングしなかった」と答える。  カンニングが全くなければ、「カンニングした」という回答がある確率は 1&amp;frasl;2 * 1&amp;frasl;2 = 1&amp;frasl;4, 全員カンニングしていれば 1&amp;frasl;2 + 1&amp;frasl;2 * 1&amp;frasl;2 = 3&amp;frasl;4 になる。  まずはライブラリをインポート。
using Distributed addprocs(3) @everywhere using Mamba using Plots 学生の数が100人、「カンニングした」という回答が35人とする。
N = 100 X = 35 Mambaのモデルは次のようになる。
model = Model( obs = Stochastic( (proportion, N) -&amp;gt; Binomial(N, proportion), false ), proportion = Logical( (true_answers, first_coin_flips, second_coin_flips) -&amp;gt; (observed = @.(first_coin_flips * true_answers + (1 - first_coin_flips) * second_coin_flips); mean(observed)), false ), true_answers = Stochastic(1, p -&amp;gt; Bernoulli(p), false), first_coin_flips = Stochastic(1, () -&amp;gt; Bernoulli(0.</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(4) -ベイズ的 A/B</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-4/</link>
      <pubDate>Thu, 21 Mar 2019 21:05:35 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-4/</guid>
      <description>今回はMambaを使って、「Pythonで体験するベイズ推論」の「例題 : ベイズ的 A/B」 をモデリングする。
例題 : ベイズ的 A/B テスト A/Bテストの例題を解いてみよう。
サイトAを見せられたユーザーが最終的にコンバージョンにつながる確率を \( p_A \)と仮定し、\( N \) 人がサイトAを見せられて、そのうち \( n \) 人がコンバージョンにつながったとする。
まずはベルヌーイ分布を使って、\( N \) 回の試行をシミュレートする。
# 定数をセット p_true = 0.05 N = 1500 occurrences = rand(Bernoulli(p_true), N) Mamba.jlで推論アルゴリズムを作成すると、次のようになる。\( p \) の事前分布は \( [0, 1] \) の一様分布に従うとしている。
model0 = Model( obs = Stochastic(1, (p, N) -&amp;gt; UnivariateDistribution[Bernoulli(p) for _ in 1:N], false), p = Stochastic(() -&amp;gt; Uniform()), ) モデルは、等価な次の形で書いた方が単純になってわかりやすいかもしれない。</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(3) -新しいデータセットの生成</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-3/</link>
      <pubDate>Wed, 20 Mar 2019 20:58:08 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-3/</guid>
      <description>引き続き「Pythonで体験するベイズ推論」の第2章の新しいデータセットの作成をJuliaでやってみる。
新しいデータセットの生成 PyMCについての説明はスキップして、シミュレーションによるメッセージ数のデータ生成から行う。
Mamba.jlは分布の作成にDistributions.jlを使っているので、シミュレーションだけ行いたかったらDistributionsを using すれば十分。
using Distributions using Plots データセットの作成とプロットは下のようになる。
function plot_artificial_sms_dataset() tau = rand(DiscreteUniform(0, 80)) theta = 20 lambda_1, lambda_2 = rand(Exponential(theta), 2) lambda_ = cat(fill(lambda_1, tau), fill(lambda_2, 80 - tau), dims = 1) data = @.rand(Poisson(lambda_)) barc = fill(1, 80) barc[tau] = 2 bar(0:80-1, data, linecolor = :transparent, fillcolor = barc, xlabel = &amp;#34;Time (days)&amp;#34;, ylabel = &amp;#34;Count of messages&amp;#34;, label = &amp;#34;&amp;#34;) end plts = [] for i in 1:4 push!</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(2) -メッセージ数に変化はあるか？ </title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-2/</link>
      <pubDate>Wed, 20 Mar 2019 20:45:02 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-2/</guid>
      <description>前回に引き続き、「Pythonで体験するベイズ推論」をJuliaでやってみる。本に従い、前回作成した「メッセージ数に変化はあるか？」を二つの変化点の場合に拡張する。
変化点が二つの場合を考えてみる。モデルは変化点が一つの場合とほぼ同じで、
model2 = Model( obs = Stochastic(1, (lambda, N) -&amp;gt; UnivariateDistribution[Poisson(lambda[i]) for i in 1:N], false ), lambda = Logical(1, (lambda1, lambda2, lambda3, tau1, tau2, N) -&amp;gt; (out = fill(lambda1, N); i1 = Int64(tau1.value) + 1; # Juliaは1-indexingのため i2 = Int64(tau2.value) + 1; out[i1:end] .= lambda2; out[i2:end] .= lambda3; out), false, ), lambda1 = Stochastic(theta -&amp;gt; Exponential(theta)), lambda2 = Stochastic(theta -&amp;gt; Exponential(theta)), lambda3 = Stochastic(theta -&amp;gt; Exponential(theta)), tau1 = Stochastic(N -&amp;gt; DiscreteUniform(0, N-1)), tau2 = Stochastic((tau1, N) -&amp;gt; DiscreteUniform(tau1, N)), ) 初期値とサンプリングスキームを同様に与えてサンプリングすると、</description>
    </item>
    
    <item>
      <title>JuliaでArray of Arrayを1次元Vectorにする方法</title>
      <link>https://matsueushi.github.io/posts/julia-array-of-array/</link>
      <pubDate>Wed, 20 Mar 2019 00:33:19 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/julia-array-of-array/</guid>
      <description>よく忘れるのでメモ。
結論から言うと Base.Iterators.flatten を適用して collect すれば良い。
julia&amp;gt; import Base.Iterators: flatten julia&amp;gt; xs = [[1, 2, 3], [4, 5, 6]] 2-element Array{Array{Int64,1},1}: [1, 2, 3] [4, 5, 6] julia&amp;gt; collect(flatten(xs)) 6-element Array{Int64,1}: 1 2 3 4 5 6 追記(2019/4/7):
&amp;nbsp;vcat を使った方が簡潔だった。
julia&amp;gt; vcat(xs...) 6-element Array{Int64,1}: 1 2 3 4 5 6</description>
    </item>
    
    <item>
      <title>Juliaで体験するベイズ推論(1) -メッセージ数に変化はあるか？</title>
      <link>https://matsueushi.github.io/posts/bayesian-methods-julia-1/</link>
      <pubDate>Tue, 19 Mar 2019 23:30:41 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bayesian-methods-julia-1/</guid>
      <description>久保拓弥「データ解析のための統計モデリング入門」を読み終えたので、次はCameron Davidson-Pilon著、玉木徹訳の「Pythonで体験するベイズ推論」(GitHubリポジトリ) をJuliaとMamba.jlでモデリングしていきたいと思う。
まず例題1.4.1の「メッセージ数に変化はあるか？」をやってみる。
元のノートブックはこれ。
JuliaでCSVファイルをhttps上から取るには、パッケージ HTTP , CSV をインポートして
r = HTTP.request(&amp;#34;GET&amp;#34;, &amp;#34;https://git.io/vXTVC&amp;#34;); count_data = CSV.read(IOBuffer(r.body), header=[&amp;#34;messages&amp;#34;]) とすれば良い。 Plotsでプロットすると下のような感じ。Juliaはインデックスが1から始まるので、x軸を 0:N-1 にしておく。
N = length(count_data.messages) bar(0:N-1, count_data.messages, label = &amp;#34;&amp;#34;, size = [600, 200], linecolor = :transparent, xlabel = &amp;#34;Time (days)&amp;#34;, ylabel = &amp;#34;Count of messages&amp;#34;) \( i \) 日目のメッセージ数 \( C_i \) がポアソン分布 \( \text{Poisson}(\lambda) \) に従い、\( \lambda \) の値が突然ある日 \( \lambda \) で変わる日があるとする。\( \tau &amp;lt; \lambda \) のとき \( \lambda = \lambda_1, \tau \ge \lambda \) の時 \( \lambda=\lambda_2 \)とする。</description>
    </item>
    
    <item>
      <title>Intrinsic Gaussian CARモデルをMambaで実装</title>
      <link>https://matsueushi.github.io/posts/intrinsic-gaussian-car/</link>
      <pubDate>Sun, 10 Mar 2019 23:14:30 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/intrinsic-gaussian-car/</guid>
      <description>「データ解析のための統計モデリング入門」第11章の空間構造のある階層ベイズモデルに挑戦する前に、まずPyMC3のIntrinsic Gaussian ModelのサンプルをMambaで実装した。
https://github.com/matsueushi/lip_stick_mamba
参考にしたMatrix Multiplicationを用いたPyMC3の実装:
https://docs.pymc.io/notebooks/PyMC3_tips_and_heuristic.html#PyMC3-implementation-using-Matrix-multiplication
PyMCのモデル
with pm.Model() as model3: # Vague prior on intercept and effect beta = pm.Normal(&amp;#39;beta&amp;#39;, mu=0.0, tau=1.0, shape=(2, 1)) # Priors for spatial random effects tau = pm.Gamma(&amp;#39;tau&amp;#39;, alpha=2., beta=2.) alpha = pm.Uniform(&amp;#39;alpha&amp;#39;, lower=0, upper=1) phi = pm.MvNormal(&amp;#39;phi&amp;#39;, mu=0, tau=tau*(D - alpha*W), shape=(1, N)) # Mean model mu = pm.Deterministic(&amp;#39;mu&amp;#39;, tt.exp(tt.dot(X, beta) + phi.T + log_offset)) # Likelihood Yi = pm.Poisson(&amp;#39;Yi&amp;#39;, mu=mu.ravel(), observed=O) trace3 = pm.</description>
    </item>
    
    <item>
      <title>Julia版「データ解析のための統計モデリング入門」読書ノート</title>
      <link>https://matsueushi.github.io/posts/julia-kubo/</link>
      <pubDate>Mon, 04 Mar 2019 23:01:57 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/julia-kubo/</guid>
      <description>最近、久保拓弥「データ解析のための統計モデリング入門――一般化線形モデル・階層ベイズモデル・MCMC (確率と情報の科学)を読んでいる。
 生態学のデータ解析 - 久保拓弥
http://hosho.ees.hokudai.ac.jp/~kubo/ce/KuboTakuya.html
 本ではR + WinBUGSを使っているが、今回はJulia(1.1.0) + Mambaを使って実装した(10章まで)。実装はGithubに載せてある。
実装の中身は上のJupyter Notebookを見てもらうとして、それ以外に実装していて何点か躓いたことがあったので備忘のために記載しておく。
Binomial分布のGLM &amp;nbsp; formula で指定する説明変数は、0から1の間になっている必要がある。個体の数で割って、wtsに個体の数を指定してフィッティングを行う。
df.yy = df.y ./ df.N df.N = convert(Array{Float64}, df.N) result = glm(@formula(yy ~ x + f), df, Binomial(), wts = df.N) モデルのグラフ表示 Mambaのチュートリアルではモデルのグラフ表示にGraphViz.jlパッケージを使っている。
ただGraphViz.jlはメンテナンスが止まっているようで、Julia v0.7以降では動かないようである。
ForneyLab.jlがGraphViz.jlの後継としてモデルのグラフ表示をサポートしているので、こちらを使用すれば良い。
Multiprocessing Mambaは addproc でプロセスを追加して、
using Distributed addprocs(3) Mambaをインポートするときに @everywhere を付ければMambaが自動的にMCMCのチェインごとのサンプリングを並列化してくれる。(section10.ipynb参照)
@everywhere using Mamba 11章の空間構造のある階層ベイズモデル(intrinsic Gaussian CARモデル)も実装できたらアップデートしたい。
3/14追記: 11章の空間構造のある階層ベイズモデルも実装したのでアップデートした。これで一通り読破したことになるのかな？次は以前読もうとして諦めた「Pythonで体験するベイズ推論」をJuliaでやってみようか。</description>
    </item>
    
    <item>
      <title>ヒイラギペイジ</title>
      <link>https://matsueushi.github.io/posts/hiiragipage/</link>
      <pubDate>Sun, 03 Mar 2019 22:15:31 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/hiiragipage/</guid>
      <description>さて、Lolica Tonicaの記事に引き続き、メンバーの一人であるヒイラギペイジのLolica Tonica前の活動や提供曲について紹介したい。
ヒイラギペイジの名前に至るまで、PAIGE → PAGE → TemoTemoe →ヒイラギペイジと言う変遷があったと思われる。
ヒイラギペイジは一番最初はPAIGEと言う名義で活動しているニコラッパーでニコニコにラップ動画をアップしていたようだ（現在は削除されている）。
 マナツニミタユメ / PAIGE
夢が僕の夢を叶えてくれる。9月4日に日比谷で発売したデモアルバムに収録した曲です。Track.by Salty Mixed.by Jill mylist/28073427 https://www.nicovideo.jp/watch/sm15603665
 
 Monochrome / PAIGE
Monochrome Track.by Tiger　Lyric.by PAIGE(mylist/28073427) Mixed.by 黒衣えすてる(mylist/8488406)
■孤独な自分と味気ない日々について。 ■何もかも上手くいかない鬱な気持ち。 ■感情を上手く言葉にするのが苦手です。
□耳がキンキンするというコメントがあったので、修正版mp3を用意しました。 □a cappellaとLyricもzipに詰めときました。Remixとかもしてくれたら飛んで喜びます。宜しくお願いします。 □http://www1.axfc.net/uploader/H/so/140127.zip&amp;amp;key=monokuro
https://www.nicovideo.jp/watch/sm15244635
 Monochromeのリミックスはまだ残っていた。
[ニコラップ] Monochrome(kome remix) / PAIGE [remix] そして2011年には閃光ライオットでグランプリを獲得しており、同じぐらいのタイミングで名前をPAGEに変えている。  https://ja.wikipedia.org/wiki/PAGE_%28%E3%83%A9%E3%83%83%E3%83%91%E3%83%BC%29 \  TOKYO FM「SCHOOL OF LOCK！」の呼び掛けにより集まった1万組を超える応募から、＜閃光ライオット2011＞グランプリを獲得したのは愛媛県出身の16歳ラッパーのPAIGE（ペイジ）だった。  https://www.barks.jp/news/?id=1000072980 この頃の曲はLolica Tonicaの音楽性とはかなり違う。アルバム「ノンフィクショーン・ガール」に収録されている2曲目の「あ・い・ど・る」は特にチップチューンのトラックにアイドルに恋するオタク目線の妄想的な歌詞が鏤められてかなり好きである。  --- また、ヒイラギペイジは初期はTemoTemoeという名義を使っていたようだ。  [Lolica Tonica](https://soundcloud.com/lolicatonica) is a Tokyo based duo made up of [Ky7ie](https://soundcloud.</description>
    </item>
    
    <item>
      <title>Jupyter Notebookのkernelの位置を調べる</title>
      <link>https://matsueushi.github.io/posts/jupyter-kernel-location/</link>
      <pubDate>Fri, 01 Mar 2019 22:52:53 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/jupyter-kernel-location/</guid>
      <description>$ jupyter kernelspec list Available kernels: julia-1.1 /home/matsueushi/.local/share/jupyter/kernels/julia-1.1 python3 /home/matsueushi/.local/share/jupyter/kernels/python3  How do I add python3 kernel to jupyter (IPython) https://stackoverflow.com/questions/28831854/how-do-i-add-python3-kernel-to-jupyter-ipython/44072803#44072803
 </description>
    </item>
    
    <item>
      <title>Yubikey</title>
      <link>https://matsueushi.github.io/posts/yubikey/</link>
      <pubDate>Thu, 03 Jan 2019 22:47:53 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/yubikey/</guid>
      <description>物理セキュリティーキーが欲しかったので買ってしまった。
公式サイトから購入し、バックアップ用と合わせて2つで$90+Tax $7.99=$97.99だった。
良い点
 難しい設定がなく挿して押すだけで二段階認証が使える  悪い点
 iPhoneでYubikeyを使おうとしても、LastPassのiPhoneアプリぐらいしかNFCに対応していない LastPassだとプレミアム会員($2/month)ではないとYubikeyが使えない  </description>
    </item>
    
    <item>
      <title>忘られぬLolica Tonica</title>
      <link>https://matsueushi.github.io/posts/lolica-tonica/</link>
      <pubDate>Sun, 21 Oct 2018 17:16:51 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/lolica-tonica/</guid>
      <description>Lolica Tonica(Twitter: @LolicaTonica)とはKy7ie.とPage Hiiragi(ヒイラギペイジ)からなる、 キラキラしたシンセとカットアップされたボーカルによる可愛らしい曲調が特徴的なFutureBassユニットである。 ただ可愛らしいだけではなく、時にゴリゴリのビートが同居している所もまた魅力的で、 すでに解散しているのだが、今でも再結成していないか定期的にチェックしているぐらいである。
Lolica Tonicaが活動を開始したのは2015年5月頃のようだ。名前がLolica Tonicaに決まる前は別の名前があったらしい。「ダサい」って言われるような名前、何だったんだろう……
 まぁそれはそれとしてだな、今ペイジくんとのユニット「Lolica Tonica」でテンションくそ高いブート作ってるんで、これはぜひ早くみんなに聞いてもらいたい、そしてあわよくば現場で使って欲しい
— @ky7ieee
 
 【新曲】ペイジくんとのユニット「Lolica Tonica」でアリアナ・グランデの曲をREMIXしたよ！フリーDLも！ &amp;lsquo;ARIANA GRANDE - The Way (Lolica Tonica Bootleg REMIX)&amp;rsquo; https://t.co/CEO3vUp1ag
— @ky7ieee
 
 Lolica Tonicaだいたいこういう感じでやっていきますんでよろしくお願いします
— @ky7ieee
 
 andrew Lolica TonicaはKy7ie.くんの方はLOUNGE NEO周りでDJをやってて、個人の曲も作ってて、僕はたまに喋ってたんです。でもヒイラギペイジくんと一緒に作るようになって音がだいぶ変わって。それをSeimeiがすごくいいって言って。
futatsuki 僕も１曲目でピンときて、Masayoshi Iimoriのプロデュースがうまくいってたんで、彼らをゼロからプロデュースしようということになったんです。会った時はLolica Tonicaっていう名前もなかったんですよ。前の名前があって、「いやそれはダサイでしょ」って言ったりとか。
TREKKIE TRAX THE BEST &amp;ldquo;2011&amp;rdquo;-2015 トレッキー、はじまりの場所へ行く。 [ CARELESS CRITIC ]
http://carelesscritic.com/sp/trekkietrax/
 本格始動し始めたのはLolica TonicaのTwitterが開設された2015年7月だろうか。
Hello, world
&amp;mdash; Lolica Tonica (@LolicaTonica) July 22, 2015</description>
    </item>
    
    <item>
      <title>ブルックリンのレコードショップ</title>
      <link>https://matsueushi.github.io/posts/blooklyn-record-store/</link>
      <pubDate>Sun, 14 Oct 2018 16:47:50 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/blooklyn-record-store/</guid>
      <description>前回のマンハッタン編に引き続き、今回はブルックリン編。
マンハッタンよりもブルックリンの方がCDが置いてある店が少なく、レコードメイン。 また、こっちの方が若者向けの店が多く活気がある印象で、ロックとかエレクトロニカなどが強い気がする。
Academy Records Annex アカデミーレコードのブルックリン店。 ブルックリンのレコード屋のなかで一押し。広くて綺麗で安い。
置いてあるボリュームが相当あるので、嬉しいことに、自分の好きなジャンルの棚をじっくり見ようとすると相当な時間がかかる。
テクノとかエレクトロニカとかハウスとかディスコとかの、ロック以外もジャンル関わらず充実しているような印象を受けた。 ライブラリーミュージックとかプライベートプレスとかマニアなジャンルも隅の方にあり、見ていて飽きない。
店内奥の壁際の方に少しだけCDの取扱いがあるが、あまり流行っていない感じ。
85 Oak St
Brooklyn, NY 11222
https://academy-lps.com/
Yelp : https://www.yelp.com/biz/academy-records-annex-brooklyn-2
Rough Trade NYC ブルックリンのEast River State Park近くにある。
スタイリッシュで入りやすい雰囲気で、自分が立ち寄った時は若い人も多く活気がある。店内はとても広く、 置いてある新品LPはかなりの量があり、メジャー寄りのラインナップであるような印象。
ニューリリースの取扱いは手厚く、各レーベルのアーティスト紹介のブースもあって新しいアーティストを追いかけたいならオススメ。 隅の方に少しだけ中古LPの取り扱いがあり、あまりよく見てませんが珍しそうなものもちょこちょこ混ざっていた。 ブルックリンでは珍しく、CDの品揃えも充実していてなかなかマニアなものも置いてあった。
二階には音楽やアート関係の本と、なぜか卓球台が置いてある。
64 N 9th St
Williamsburg, NY 11249
https://www.roughtrade.com/us
Yelp : https://www.yelp.com/biz/rough-trade-nyc-williamsburg
Captured Tracks Shop ブルックリンのGreenpoint Av駅近くにある、レコードレーベルCaptured Tracksの直営店です。階段を降りて半地下みたいな空間に店がある。
Captured Tracksに所属しているアーティストをはじめとしたインディー系の新譜の品揃えが魅力で、 所属しているアーティストはLPだけでなく、カセットテープも置いてある。CDの取扱いはない。 幅広く中古も取り揃えてあり、棚の上の方においてあるレア盤のジャケットを眺めるのも楽しい。
195 Calyer St
Brooklyn, NY 11222
https://capturedtracks.com/
https://www.omnianmusicgroup.com/collections/captured-tracks
Yelp : https://www.yelp.com/biz/captured-tracks-shop-brooklyn
Record Grouch こちらもGreepoint駅近くにある。レコードのみ。</description>
    </item>
    
    <item>
      <title>マンハッタンのレコードショップ</title>
      <link>https://matsueushi.github.io/posts/manhattan-record-store/</link>
      <pubDate>Sun, 14 Oct 2018 15:51:19 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/manhattan-record-store/</guid>
      <description>今ニューヨークで暮らしていて、交友関係が皆無に近く旅行もそれほど好きではないのでレコードショップを巡っているので、 自分用まとめも兼ねて今まで行ったレコードショップをまとめたいと思う。
もともと日本でCDをちょくちょく購入していたが、マンハッタンやブルックリンだとCDはそもそもショップで扱っていないところも多く、 置かれていても棚を眺めている人や購入している人は少なく、商品はあまり入れ替わっていないように感じる（クラシックだとまだ少し残っている印象はありますが)。 そのためCDという媒体に活気があまりないため、レコードプレイヤーを買ってレコードを見るようにした。
新品LPの標準的な価格は20ドルくらいで日本よりもだいぶ安く、中古に至っては10ドルしないことが多い（クリアランスだと1ドルとかで置いてあったりする)。 食べ物とか他の物価が高いことを考えると気楽にレコードが買えるような価格設定だと思う。
新規開拓したら随時更新したいと思う。順番は適当です。
Generation Records Bleecker St駅、Houston Street Station駅から等距離くらいかな？少し歩く。
綺麗にジャンルごとに分かれて整理されていて見やすく、取り扱いのジャンルや量も豊富で、価格も手頃。 僕が訪れた時は平日夜にも関わらず賑わっていて、土日に行った時も幅広い年齢層の人が集まっていた。 一階と地下に分かれていて、一階はロック系の新譜・中古の取り扱いが充実し、 階段を降りて地下に入っていくとヒップホップとかソウルとかディスコとかサウンドトラックとかが揃っている。 （最初入って行く時ちょっと勇気必要だったけど……）
この店は珍しく中古CDがそれなりの量置いてあり、カセットやポスターの取り扱いもされている。
210 Thompson St
New York, NY 10012
http://www.generationrecordsnyc.com/generation/generation.html
Yelp : https://www.yelp.com/biz/generation-records-new-york
Academy Records &amp;amp; CDs 23th St駅で降りて少し下って18th St, 5Avと6Avの間にある。 似た名前のAcademy Recordsというのがマンハッタンとブルックリンにあるが、ホームページが異なるので多分系列店ではないはず。
クラシックやジャズのCD、LPが他のショップに比べ充実しているのが特徴で、お客さんの年齢層も若干高め。 珍しくCDがしっかりと（レコードの隅に追いやられるような形ではなく）陳列されているお店。 佇まいとしては日本のディスクユニオンのクラシック館のような雰囲気。
12 W 18th St
New York, NY 10011
http://academy-records.com/
Yelp : https://www.yelp.com/biz/academy-records-and-cds-new-york
Academy Records (マンハッタン店) 1st Av駅から近い。レコードのみ。ブルックリンに姉妹店があり、自分の中では広さや品揃えの点でこちらが支店で、ブルックリンが本店という印象。
ブルックリン店よりも店内は小さく、ジャズとか古いロックとかクラシックの取り扱いが多い。 ロックとかディスコとかヒップホップとかエレクトロニカとかはブルックリンの方が充実していて、 マンハッタンとブルックリンの店でジャンルの住み分けをしていると思われる。
415 E 12th St
New York, NY 10009</description>
    </item>
    
    <item>
      <title>Black Dog Productions - Bytes (1993)</title>
      <link>https://matsueushi.github.io/posts/bdp-bytes/</link>
      <pubDate>Wed, 19 Oct 2016 00:25:56 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/bdp-bytes/</guid>
      <description>カッチリした硬質のビートが刻む複雑なリズム、ひんやりとしたメロディ。簡潔でミニマルだが、隙のないほどに知的なテクノだと思う。
90年代のアナログ感満載のちょっとこもった感じの音もどこか懐かしい。
アルバムの中でも、冒頭曲Object Orientの畳み掛けるような性急なリズム、奇妙な展開は特にお気に入りだ。
聞いていると頭にビートが染み込み、電子の海を漂っているような気分になる素晴らしい一枚。</description>
    </item>
    
    <item>
      <title>BOaT - RORO (2001)</title>
      <link>https://matsueushi.github.io/posts/boat-roro/</link>
      <pubDate>Wed, 10 Aug 2016 00:21:13 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/boat-roro/</guid>
      <description>最近はすっかり暑くなってきていよいよ夏本番という気がするが、この季節になるとBOaTを聴きたくなる。
2001年に解散した後相当時間が経ってからバンドを知ったのでリアルタイムにリリースやライブを体験することはできなかったが、マイフェイバリット邦楽バンドTOP3に必ずランクインするほど好きなバンドだ。もしタイムマシンを1回だけ使うことができて好きなバンドの解散ライブを見ることができたらおそらくBOaTの解散ライブに行くだろう。 マイナーバンドなので好きなバンドを聞かれた時にBOaTの名前は基本的に出さないけども、酔っ払って気分が良くなっているときには、ふーんそうなんだ、聞いたことないけど、と言われるのを承知で喋ってしまう。
BOaTが残した音源は少ない。オリジナルアルバム4枚(フルーツ☆リー、SOUL.THRASH.TRAIN、LISTENING SUICIDAL、RORO)とシングル数枚、コンピレーションに提供した曲ぐらいだ。どれも素晴らしいのだが、その中でもラストアルバムであるROROは一際輝く屈指の名作である。
3枚目までのポップでファンキーなミクスチャーロック路線とは大きく変わり、3枚目のLISTENING SUICIDALに見え隠れしていたプログレ方面のアプローチが進化し、曲は長く、シリアスで叙情的になっている。
夏の到来を告げるようなオーガニックな雰囲気を漂わせながら一曲目のAllが始まる。気分がゆっくりと高まってきていつの間にかROROの奇妙でポップ、そしてエモーショナルな世界観に引き込まれている。
Akiramujinaはインスト曲で、ギターロック系の轟音ポストロックといった雰囲気。混沌かつ清冽な音がうねりながら変化していって、テンション高く暴れまわるギターとポップなメロディの融合が織りなすサウンドスケープには胸打たれる。
そして続くRoots Of Summerは繰り返されるサビが聞いてて心地よく、爽やかかつめちゃくちゃポップな胸キュン曲。途中まで溜めて溜めてサビのところで一気に爆発してポップになる感じ、白熱するテンション、絶妙なバランスで絡みつくツインボーカルがスーパーエモーショナルで思わず歌い出しそうになる。「アキラムジナ吸って　夏を裏付けた」というどういうことか良くわからない歌詞も頭に残って印象的。何よりも、アインのキュートなボーカルが特徴的な、ラストで繰り返されるサビで味わう高揚感が最高だ。
 
Rummy Nightは前作LISTENING SUICIDAL (こちらのアルバムも名盤である) の初回限定版8cmに収録されているNIGHT HAWK NIGHTがさらに進化したようなポストロック風味の曲で、夜の静謐さが徐々に混沌へと変わっていくような印象で、美しくサイケデリックだ。
Tuesdayは長尺のプログレ調のインスト曲。2曲めのAkiramujinaもその点は共通するが、Akiramujinaがだんだんとテンションが上がって高揚していくような盛り上がり方をするのとは対照的に、Tuesdayは聞いているうちに、より深く、自分の内面に染み渡っていくような昂りを覚える。特に、曲の半ばで一旦静けさを取り戻してからの後半部分の盛り上がりが神懸かっていて、無情感とか喪失感とか寂寥感とか、夏の終わりに伴う感情がごちゃまぜになって押し寄せてくる。ROROを聞いているときの精神的な盛り上がりのピークはTuesdayの後半で間違いないと思う。
 
Circle Soundはアルバムのラストを締めくくるポップチューン。イントロのトゥルトゥトゥトゥル〜ですでに最高なんだけど、揺らめくようなAメロ、Bメロから突入するテンション爆上がりのサビ、途中のギターソロも涙が出そうなほどカッコ良く、花火がパッと打ち上がって終わるような余韻で終わるところも好きだ。Listen to the light and don&amp;rsquo;t forgetという歌詞もお気に入りで、blogのタイトルはここから取っている。
このアルバムには初めは大人しめのムードで始まって徐々に気持ちを盛り上げるタイプの曲が多いが、全ての曲の盛り上げ方が自然でいつの間にか気持ちよくなっているのが不思議だ。うまく言葉にできないが、聞いてると妙にノスタルジックな気分になるというか、自分の奥深くの内面が揺れ動く気がする。
 
Allで始まりCircle Soundで終わる、アルバムの中に夏の始まりから終わりがギュッと閉じ込められていて一つの流れになっている。僕の中で夏を裏付けるアルバムと言えばまさにこれであり、初めて聞いた時から何年も経っているが未だによく聞くアルバムでその度に良さを確認している。
一つ悲しいことは、BOaT関連のCDが軒並み廃盤になっているのでこのアルバムに出会いづらいということだ。
フルーツ☆リーとソウルスラッシュトレインに関してはAmazonマーケットプレイスで1000〜2000円ぐらいで買えるし、Apple MusicやiTunes Storeで聴けるのでハードルはそれほど高くない。
LISTENING SUICIDALや(肝心の)ROROは、iTunesには無いので渋谷TSUTAYAやジャニスなどに借りに行くか、高い(ROROだと5000円〜ぐらい)がマケプレやディスクユニオンで買うしか無いと思われるのでちょっと大変。しかし、音楽好きならばコストや手間を払ってまで聞く価値があると思うし、その中でも特にROROは奇跡を感じるアルバムだと思う。
  All
 Akiramujina
 Roots Of Summer
 Rummy Night
 Tuesday
 Circle Sound
  </description>
    </item>
    
    <item>
      <title>挫・人間 - テレポート・ミュージック (2015)</title>
      <link>https://matsueushi.github.io/posts/zaningen-teleport/</link>
      <pubDate>Sun, 31 Jul 2016 00:16:07 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/zaningen-teleport/</guid>
      <description>挫・人間の2ndアルバム、テレポート・ミュージック。 僕が良くやりがちなパターンなのですが、いろいろ聴きたい音楽を調べているうちにYouTubeで「セルアウト禅問答」のPVを見てフォーリンラブ、Apple Musicで一聴してすぐCD買った。
 
歌詞に出てくる「ナゴムの遺伝子」だとか「グミチョコ」だとか「美術館で会った人です」だとかラノベっぽいタイトルのM5「可愛い転校生に告白されて付き合おうと思ったら彼女はなんと狐娘だったので人間のぼくが幸せについて本気出して考えてみた」とかちょくちょく入れ込んでくるサブカル感、そしてアルバムに共通する自意識過剰をこじらせてしまったタイプの妄想的な世界観、引きこもりサブカルこじらせタイプ（僕）は強烈なシンパシーを感じてしまった。
 
ストレートに無条件に「アイラブユー」と言いたい自分自身の愛情表現と、それを冷静に見つめる超自我的の二つが葛藤を繰り返す自意識のぶつかり合い。
ラップバトルっぽい「下川 vs 世間」では自分が脳内で作り上げた世間との脳内バトルが繰り広げられるところとか聞いてると「うわ、めっちゃわかる……」となり、同時に自分の頭の中が覗き見られてるようで恥ずかしい。
このアルバムで最終的に辿り着いた着地点が例えばセルアウト禅問答でのヤケクソの「アイラブユー」だったというところも好きなんですよね。
中心にあるのが「アイラブユー」である点が、自分の「敵」に対する脳内の憎しみをグツグツと煮詰めたような前作の「苺苺苺苺苺」とは少し違うと思う。楽曲的にも世界観的にも段違いにポップになってて、(いい意味で)J-POPとして聞いてて楽しい。メタな視点からこじらせの気持ち悪さ（？）をバカバカしさに変換することに成功しているので、マイルドながらもちゃんとこじらせてる（？？？）ので「前作より丸くなったよね笑、ちょっと物足りないかな」みたいなのとも違うし。
ライブも行って、イメージに違わぬ妄想爆発ぶりで、そこいらに溢れる凡百の軟弱シティポップバンドなんか比べ物にならないほど最高に良かった。
9月に出る新譜も本当に楽しみで、早く聴きたい。</description>
    </item>
    
    <item>
      <title>Girls - Album (2009)</title>
      <link>https://matsueushi.github.io/posts/girls-album/</link>
      <pubDate>Sun, 26 Jun 2016 00:04:20 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/girls-album/</guid>
      <description>アメリカ、サンフランシスコで活動していたバンド、Girls。活動期間は2007-2012年と短く、僅か2枚のスタジオアルバムと1枚のEPを残し解散してしまった。バンド名こそガールズだが、クリストファー・オウエンスとジャック&amp;rdquo;JR&amp;rdquo;ホワイトの男性2人のバンドだ。
Girlsが残した2枚のアルバムは大変な傑作なんだけど、今回は特に僕が愛してやまないファーストアルバム、Albumについて書きたい。
まず内容以前にコンセプトが好きで、バンドの名前がGirlsでアルバムのタイトルがAlbumって言うのが、何でも検索しちゃう今時の風潮に対して斜に構えている感じてイカしてるし、白をベースにした限りなく簡潔なアートワークもいい。余計な情報を頭に入れるより、まずは音源を聞いてくれ、みたいなメッセージなのかもしれない。
 Lust For Lifeのイントロを一聴すればわかる。何かが始まる感覚っていうか、聞いているうちに楽しい世界に誘ってくれるようなワクワクや期待が詰まってて、でもどこか寂しげで心が揺さぶられて、バックコーラスが始まるころには思わず走り出したくなってしまうような特別な曲。
 
Hellhole Ratraceの大げさなまでに感情を込めてくる感じ、i don&amp;rsquo;t want to die～～って思わず歌いたくなる。
 
Morning Lightは 部屋の中で大音量で流したい、退廃的な儚い夢のムード漂うシューゲイザー調の曲。不安げなイントロから始まり、暴力的なフィードバックギターと甘く浮遊感のあるボーカルが絡み、中盤からはただただフィードバックギターのメロディが繰り返され、無常感がある。かわいい女の子とメンバーがじゃれ合ってるPVもどこか寂しげで曲調にマッチしている。
 
ハイプだとかデモテープっぽいとか50/60sのポップソングのパクリとかいろいろ言われてたけど、むしろ、このデモテープっぽい荒削りさは魅力だと思うし、40s,50s,60sのエッセンスを現代に引き直しただけの単なる模倣でははないことは明らか。
パンク、バラード、シューゲイザー、オルタナ、ネオアコなど様々なジャンルの要素をアルバムから感じるし、クリストファー・オウエンスのボーカルスタイルも、HeadachやLauren Marieでは甘ったるく優しく、Big Bad Mean MotherfuckerやSummertimeではおどけた歌い方をしたりと、幅広さを感じるアルバム。 とにかく聞いていて切ない気分になって心酔しちゃう、感傷に浸りたい時に真っ先に聞きたくなる一枚。人によって好みが別れるアルバムだと思うけど、Lust For Lifeを聞いて気に入ったらぜひアルバムを通して聞いて欲しい。</description>
    </item>
    
    <item>
      <title>Mac Demarco - 2 (2012)</title>
      <link>https://matsueushi.github.io/posts/macdemarco-2/</link>
      <pubDate>Tue, 31 May 2016 23:51:30 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/macdemarco-2/</guid>
      <description>ジャケットでにこやかにチェックシャツを着てピースしているのが、カナダ出身、1990年生まれ(若い!)のシンガーソングライター、Mac Demarco。見た目で判断するのはあまり良くないとは思うけど、この愛嬌ある見た目！このちょっと子供っぽい感じ！聞く前から楽しい予感がしてくる。
 INTERVIEW:
MAC DEMARCO: “I’VE REELED IT IN A LITTLE BIT, BUT NOT THAT MUCH”
http://diymag.com/2015/08/08/mac-demarco-interview-ive-reeled-it-in-a-little-bit-but-not-that-much
 この&amp;rdquo;2&amp;rdquo;、郷愁を感じるサイケデリック・ポップで、肩の力の抜けた、自然体のユルさが絶妙に心地よい。
僕が一番アルバムの中で好きなのはお気に入りのタバコについて唄ったOde to Viceroy。
 And oh, don&amp;rsquo;t let me see you crying
&amp;lsquo;Cause oh, honey, I&amp;rsquo;ll smoke you &amp;lsquo;til I&amp;rsquo;m dying
この部分最高。
 
My Kind of Womanなんて20代前半とは思えない哀愁が漂っている。
 
ちょっと疲れた時に気楽に聞きたくなる癒やしの一枚。くたくたになって帰ってきても、このアルバムを流すと部屋全体がやすらぎの空間になる感じ。是非一度生でライブを見てみたい。</description>
    </item>
    
    <item>
      <title>Oval - 94 Diskont (1995)</title>
      <link>https://matsueushi.github.io/posts/oval-94-diskont/</link>
      <pubDate>Sun, 29 May 2016 23:47:05 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/oval-94-diskont/</guid>
      <description>ドイツの実験電子音楽グループOvalの4thアルバム、94 Diskont。 このアルバムは何と言っても1曲目のDo Whileの存在感が際立つ。
温かい電子音の曖昧な揺らめきの反復が生み出す、しこたま飲酒してフラフラになって眠くなっている時のように感じるような、ドラッギーな酩酊。24分間にわたって繰り返されるアンビエントノイズは、聞いているうちに夢のなかに誘い込まれそうなほど幻想的で美しい。
他にアルバムに収録されているCommerce ServerやShop In Stoneは、単体で聞けば結構いい曲だが、曲の長さが短くDo Whileのトリップ感を味わう前に曲が終わってしまうので、前半どっぷりとDo Whileの世界観に浸かってからアルバム後半を聞いていると若干物足りなく感じてしまうこともあるかもしれない。
音源ソースを収録してCDの記録面をマジックペンで汚したり、カッターナイフで傷をつけたりして音飛びを発生させるなどの手法が用いられ、リリース当時は賛否両論だったらしい。
人によってはずっと同じような音が流れているように聞こえて退屈に感じるかもしれないが、騙されたと思ってまずは一度、24分間、揺らぎながら変化していく音響に耳を傾けて欲しい。</description>
    </item>
    
    <item>
      <title>New Order@新木場STUDIO COAST, 2016/5/25(水)</title>
      <link>https://matsueushi.github.io/posts/new-order-coast/</link>
      <pubDate>Sat, 28 May 2016 23:39:58 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/new-order-coast/</guid>
      <description>New Orderの来日公演に行ってきた。New Orderを生で見るのは初。
New Orderに興味を持った時期はアジカンのナノムゲンコンピレーション(アッシュとかエルレガーデンとかの曲が入ってる青いジャケットのやつ)を買って、洋楽に興味を持ち始めた頃なので高校2年ぐらいだったと思う。YouTubeで色々探している間にCrystalのミュージックビデオにたどり着いた。
 
曲がカッコいいし演奏している人もイケてる感じだしこれは総合的に良い感じなのでは……？と思い、Crystalが収録されているGet Readyというアルバムを即座に購入した。
その時引っかかったのは、Amazonのレビューか何かに「New Orderを初めて聞く人にはこのGet Readyはおすすめ出来ない」と言った内容のレビューがあったこと。
「こんなに今風のイケてる感じなのに何言ってんだコイツ」と脳内にハテナマークが浮かんだが、好き嫌いは人それぞれなのでこういうことはよくあるから気にしないで聞いていた。
 しかし、YouTubeでNew Orderのライブ動画を検索しているとおかしなことに気づく。
 
おじさんが謎のダンスをしていたりジャンプしてワオ！とか言ってる感じ、カラオケではしゃいでるおじさんと同じだし、CrystalのPVのアップツーデートな雰囲気と全然違うし、そもそも顔と体型が根本的に違わないか？曲がなんというかスカスカに聞こえるし、歌も特別上手いわけじゃないし、どういう事なんだ……
 調べてみると、CrystalのPVに出てくるイケてる人たちはNew Orderのメンバーでもなんでもない若いイケてる役者で、本当のNew Orderのメンバーは(当然だが)ライブ映像に出てきた冴えない感じのおじさんたちで、完全に騙されていた。
 実はGet ReadyはNew Orderが一度解散した後、復活作としてリリースされたもので、キャリアの中では異色な作品だったということが色んな曲を聞いているうちに分かってきた。
 New Orderで一番有名な曲、Blue Monday。最初に聞いた時は印象的なリズムと憂鬱な雰囲気にびっくりした。
 
花のジャケットが美しいセカンドアルバム、Power,Corruption &amp;amp; Lies(邦題:権力の美学)のラストに収録されている、美しく哀愁あるLeave Me Alone。
 
不審者がビンタしあっているシーンから始まる意味不明なPVも印象深いTrue Faith。
 リズムマシンが生み出す無機質なリズム、チープなシンセが奏でるちょっと物悲しい美しいメロディ、ペラペラなギター、目立つメロディアスな高音ベース、ヘロヘロのあんまり上手くない歌の組み合わせが絶妙で、すべてが微笑ましく、愛おしく聞こえてくるんですよ。
 New Orderの他のアルバムも買って聞いて、全身バンドであるJoy Divisionもそのつながりで聴くようになって、ニューウェーブとかポストパンクとかいったジャンルのCDを集めるようになったのだった。
 知った当初はメンバー同士の不和で解散状態だったんだけど、4年前ぐらいに再結成していた時は嬉しくなったものだ。ベースのフッキーが脱退したことになっていて悲しかったが。
 そんな経緯もあり、10年ぶりの新作、29年ぶりの単独公演となれば狂喜乱舞しないわけがないでしょう。初めて知ってから8年……長かった。
 楽しみすぎて会社の有給取って、午前中は部屋でNew Orderの曲を聴き続けて、18時会場なのに1時間半も早い16時30分に駅に集合。そこは不毛地帯新木場、居酒屋が空いているわけでもないのでコンビニで酒買って駅前の植木を囲んでいる変な石の上でビール飲んで、それでも時間が若干余ったのでハトと戯れた。
 そして向かった新木場STUDIO COAST。驚くほどおじさん(とおばさん)の率が高い。つまりはおじさんの青春なのだ！親に強引に連れてこられたと思しき子供を見かけたが、子供だったらももクロとか嵐とか西野カナとか聞きたいだろうに……笑
 おじさんとともに入場し開演を待つ。開演が1時間押して始まったのが20:00。メンバーが出てきた瞬間興奮して全部どうでも良くなっちゃったけど。
 1曲目は新作Music CompleteからSingularity。1曲目からフロアの沸きが凄いし、思ったより演奏が下手じゃない！ 続いてRegretのイントロが流れた瞬間懐かしさがこみ上げてきて、おじさんたちと一緒に大合唱。
そして Crystalの演奏中には後ろのスクリーンに僕が騙されたCrystalのPVがそのまま流れるという(僕個人にとって)感動の演出があり、PVの偽メンバーとステージ上のメンバーを見比べながらテンション上がってました。
途中ずっと思ってたのですが、バーニーのギターを持たず歌っている時の「おじいちゃんがカラオケボックスで歌っている」感じ、本当にかわいい……（意味不明）
本編ラストのThe Perfect Kiss, True Faith, Temptationの三連チャンは本当に盛り上がった。</description>
    </item>
    
    <item>
      <title>Cymbals - That&#39;s Entertainment (2000)</title>
      <link>https://matsueushi.github.io/posts/cymbals-entertainment/</link>
      <pubDate>Mon, 23 May 2016 10:39:20 -0400</pubDate>
      
      <guid>https://matsueushi.github.io/posts/cymbals-entertainment/</guid>
      <description>渋谷系バンドCymbalsの1stアルバム、That&amp;rsquo;s Entertainment。 Cymbalsのメンバーは土岐麻子、沖井礼二、矢野博康の三人。1997年に結成、当初のコンセプトは「かわいくっていじわるな感じのバンド。ただしパンク」。 2003年12月に解散を発表し、今はそれぞれソロで活動中、とのこと。
POPで楽しくて爽やかで、おしゃれなギターポップ。聞いてるとなんとなく都会的な育ちの良さを感じる。 ジャケットとかのアートワークが洋楽っぽくて、歌詞は英詩の割合が多くてちょっと背伸びして「気取ってる」ところも可愛くてなんかいい。 フリッパーズ・ギターの1枚目の斜に構えた(失礼)英詩の感じとはちょっと趣が違って、素直。
 明るい日差しの中、芝生の上で寝転がりながら聞くWhat A Shiny Day！
シャレオツな喫茶店のテラスで飲むメロンソーダフロート、雲ひとつ無い晴れた日の昼間、My Brave Faceのイントロの軽快な口笛を吹きながら川沿いの堤防でサイクリング！
ま、実際はメロンソーダは注文しないし、サイクリングなんか行かないんだけど、そんなことはどうでもいいんですよ！！！圧倒的なポップセンス最高！
 CD、Amazonにはなかったけどタワーレコードには置いてるのでタワレコに急げ！！！！</description>
    </item>
    
  </channel>
</rss>