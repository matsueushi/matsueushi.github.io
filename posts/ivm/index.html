<!DOCTYPE html>
<html lang='en'><head>
  <meta charset='utf-8'>
<meta name='viewport' content='width=device-width, initial-scale=1'>
<meta name='description' content='前回書いた 「ガウス過程の補助変数法 (Inducing variable method) を理解する 」の続き。 Julia (v1.0) を使って、前回調べた SoD, SoR, DTC, FITC による回帰の近似結果を実際に確認する。
簡単のため、gp.jl により、
 ガウスカーネルのクラス GaussianKernel が定義されていて、
 カーネル k に対してカーネル関数 \( k(x, y) \) と相互共分散 \( (k(x_i, y_j))_{i,j}\) がそれぞれ ker(k, x, y) と cov(k, xs, ys) で計算できる  と仮定する。ということで、まずはライブラリの読み込み。
using Distributions using Plots using LinearAlgebra include(&#34;gp.jl&#34;) データは、MLPシリーズ 「ガウス過程と機械学習」の pp.157, 図5.3 補助入力点の配置 と同じサンプルを使う。上記のページに掲載されている、「補助変数法の例 (1次元の場合).」のデータの生成方法を参考にして次のようにデータを100個作成した。
# サンプルデータの作成 xs = vcat(rand(80),rand(20) * 3 .&#43; 1.0) sort!(xs) fx = sin.'>
<meta name='theme-color' content='#ffcd00'>

<meta property='og:title' content='ガウス過程の変数補助法をJuliaで実装、回帰結果を比較 • matsueushi'>
<meta property='og:description' content='前回書いた 「ガウス過程の補助変数法 (Inducing variable method) を理解する 」の続き。 Julia (v1.0) を使って、前回調べた SoD, SoR, DTC, FITC による回帰の近似結果を実際に確認する。
簡単のため、gp.jl により、
 ガウスカーネルのクラス GaussianKernel が定義されていて、
 カーネル k に対してカーネル関数 \( k(x, y) \) と相互共分散 \( (k(x_i, y_j))_{i,j}\) がそれぞれ ker(k, x, y) と cov(k, xs, ys) で計算できる  と仮定する。ということで、まずはライブラリの読み込み。
using Distributions using Plots using LinearAlgebra include(&#34;gp.jl&#34;) データは、MLPシリーズ 「ガウス過程と機械学習」の pp.157, 図5.3 補助入力点の配置 と同じサンプルを使う。上記のページに掲載されている、「補助変数法の例 (1次元の場合).」のデータの生成方法を参考にして次のようにデータを100個作成した。
# サンプルデータの作成 xs = vcat(rand(80),rand(20) * 3 .&#43; 1.0) sort!(xs) fx = sin.'>
<meta property='og:url' content='https://matsueushi.github.io/posts/ivm/'>
<meta property='og:site_name' content='matsueushi'>
<meta property='og:type' content='article'><meta property='article:section' content='posts'><meta property='article:tag' content='GaussianProcess'><meta property='article:tag' content='InducingVariableMethod'><meta property='article:tag' content='SparseApproximation'><meta property='article:tag' content='SoD'><meta property='article:tag' content='SoR'><meta property='article:tag' content='DTC'><meta property='article:tag' content='FITC'><meta property='article:published_time' content='2019-07-04T10:10:28-04:00'/><meta property='article:modified_time' content='2019-07-04T10:10:28-04:00'/><meta name='twitter:card' content='summary'>

<meta name="generator" content="Hugo 0.55.6" />

  <title>ガウス過程の変数補助法をJuliaで実装、回帰結果を比較 • matsueushi</title>
  <link rel='canonical' href='https://matsueushi.github.io/posts/ivm/'>
  
  
  <link rel='icon' href='/favicon.ico'>
<link rel='stylesheet' href='/assets/css/main.6a060eb7.css'><link rel='stylesheet' href='/css/custom.css'><style>
:root{--color-accent:#ffcd00;}
</style>

<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-141286537-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>

  

</head>
<body class='page type-posts has-sidebar'>

  <div class='site'><div id='sidebar' class='sidebar'>
  <a class='screen-reader-text' href='#main-menu'>Skip to Main Menu</a>

  <div class='container'><section class='widget widget-about sep-after'>
  <header>
    
    <div class='logo'>
      <a href='/'>
        <img src='/images/ushi.jpg'>
      </a>
    </div>
    
    <h2 class='title site-title '>
      <a href='/'>
      matsueushi
      </a>
    </h2>
    <div class='desc'>
    
    </div>
  </header>

</section>
<section class='widget widget-search sep-after'>
  <header>
    <h4 class='title widget-title'>Search</h4>
  </header>

  <form action='/search' id='search-form' class='search-form'>
    <label>
      <span class='screen-reader-text'>Search</span>
      <input id='search-term' class='search-term' type='search' name='q' placeholder='Search&hellip;'>
    </label></form>

</section>
<section class='widget widget-sidebar_menu sep-after'><nav id='sidebar-menu' class='menu sidebar-menu' aria-label='Sidebar Menu'>
    <div class='container'>
      <ul><li class='item'>
  <a href='/'>Home</a></li><li class='item'>
  <a href='/posts/'>Blog</a></li></ul>
    </div>
  </nav>

</section><section class='widget widget-taxonomy_cloud sep-after'>
  <header>
    <h4 class='title widget-title'>Tags</h4>
  </header>

  <div class='container list-container'>
  <ul class='list taxonomy-cloud'><li>
        <a href='/tags/bayesian/' style='font-size:1.3157894736842106em'>Bayesian</a>
      </li><li>
        <a href='/tags/blackdogproductions/' style='font-size:1em'>BlackDogProductions</a>
      </li><li>
        <a href='/tags/boat/' style='font-size:1em'>BOaT</a>
      </li><li>
        <a href='/tags/cymbals/' style='font-size:1em'>Cymbals</a>
      </li><li>
        <a href='/tags/distribution/' style='font-size:1em'>Distribution</a>
      </li><li>
        <a href='/tags/dtc/' style='font-size:1.0526315789473684em'>DTC</a>
      </li><li>
        <a href='/tags/fitc/' style='font-size:1.0526315789473684em'>FITC</a>
      </li><li>
        <a href='/tags/gaussianpocess/' style='font-size:1em'>GaussianPocess</a>
      </li><li>
        <a href='/tags/gaussianprocess/' style='font-size:1.1578947368421053em'>GaussianProcess</a>
      </li><li>
        <a href='/tags/gcp/' style='font-size:1em'>GCP</a>
      </li><li>
        <a href='/tags/girls/' style='font-size:1em'>Girls</a>
      </li><li>
        <a href='/tags/inducingvariablemethod/' style='font-size:1.0526315789473684em'>InducingVariableMethod</a>
      </li><li>
        <a href='/tags/julia/' style='font-size:2em'>Julia</a>
      </li><li>
        <a href='/tags/jupyter/' style='font-size:1.0526315789473684em'>Jupyter</a>
      </li><li>
        <a href='/tags/katex/' style='font-size:1.0526315789473684em'>KaTeX</a>
      </li><li>
        <a href='/tags/lolicatonica/' style='font-size:1.0526315789473684em'>LolicaTonica</a>
      </li><li>
        <a href='/tags/macdemarco/' style='font-size:1em'>MacDemarco</a>
      </li><li>
        <a href='/tags/mamba/' style='font-size:1.4736842105263157em'>Mamba</a>
      </li><li>
        <a href='/tags/mcmc/' style='font-size:1em'>MCMC</a>
      </li><li>
        <a href='/tags/ml/' style='font-size:1em'>ML</a>
      </li><li>
        <a href='/tags/mlp/' style='font-size:1.0526315789473684em'>MLP</a>
      </li><li>
        <a href='/tags/music/' style='font-size:1.631578947368421em'>Music</a>
      </li><li>
        <a href='/tags/neworder/' style='font-size:1em'>NewOrder</a>
      </li><li>
        <a href='/tags/optim/' style='font-size:1em'>Optim</a>
      </li><li>
        <a href='/tags/oval/' style='font-size:1em'>Oval</a>
      </li><li>
        <a href='/tags/plots/' style='font-size:1em'>Plots</a>
      </li><li>
        <a href='/tags/randomwalk/' style='font-size:1em'>RandomWalk</a>
      </li><li>
        <a href='/tags/record/' style='font-size:1.0526315789473684em'>Record</a>
      </li><li>
        <a href='/tags/sod/' style='font-size:1.0526315789473684em'>SoD</a>
      </li><li>
        <a href='/tags/softman/' style='font-size:1em'>Softman</a>
      </li><li>
        <a href='/tags/sor/' style='font-size:1.0526315789473684em'>SoR</a>
      </li><li>
        <a href='/tags/sparseapproximation/' style='font-size:1.0526315789473684em'>SparseApproximation</a>
      </li><li>
        <a href='/tags/test/' style='font-size:1em'>test</a>
      </li><li>
        <a href='/tags/yubikey/' style='font-size:1em'>YubiKey</a>
      </li><li>
        <a href='/tags/zaningen/' style='font-size:1em'>Zaningen</a>
      </li></ul>
</div>


</section>
</div>

  <div class='sidebar-overlay'></div>
</div><div class='main'><nav id='main-menu' class='menu main-menu' aria-label='Main Menu'>
  <div class='container'>
    <a class='screen-reader-text' href='#content'>Skip to Content</a>

<button id='sidebar-toggler' class='sidebar-toggler' aria-controls='sidebar'>
  <span class='screen-reader-text'>Toggle Sidebar</span>
  <span class='open'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="3" y1="12" x2="21" y2="12" />
  <line x1="3" y1="6" x2="21" y2="6" />
  <line x1="3" y1="18" x2="21" y2="18" />
  
</svg>
</span>
  <span class='close'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="18" y1="6" x2="6" y2="18" />
  <line x1="6" y1="6" x2="18" y2="18" />
  
</svg>
</span>
</button>
    <ul><li class='item'>
        <a href='/'>Home</a>
      </li><li class='item'>
        <a href='/posts/'>Blog</a>
      </li><li class='item'>
        <a href='/about/'>About</a>
      </li></ul>
  </div>
</nav><div class='header-widgets'>
        <div class='container'>
    
    <style>.widget-breadcrumbs li:after{content:'\2f '}</style>
  <section class='widget widget-breadcrumbs sep-after'>
    <nav id='breadcrumbs'>
      <ol><li><a href='/'>Home</a></li><li><a href='/posts/'>Blog</a></li><li><span>ガウス過程の変数補助法をJuliaで実装、回帰結果を比較</span></li></ol>
    </nav>
  </section></div>
      </div>

      <header id='header' class='header site-header'>
        <div class='container sep-after'>
          <div class='header-info'><p class='site-title title'>matsueushi</p><p class='desc site-desc'></p>
          </div>
        </div>
      </header>

      <main id='content'>


<article lang='en' class='entry'>
    <header class='header entry-header'>
  <div class='container sep-after'>
    <div class='header-info'>
      <h1 class='title'>ガウス過程の変数補助法をJuliaで実装、回帰結果を比較</h1>
      

    </div>
    <div class='entry-meta'>
  <span class='posted-on'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"/>
  <line x1="16" y1="2" x2="16" y2="6"/>
  <line x1="8" y1="2" x2="8" y2="6"/>
  <line x1="3" y1="10" x2="21" y2="10"/>
  
</svg>
<span class='screen-reader-text'>Posted on </span>
  <time class='entry-date' datetime='2019-07-04T10:10:28-04:00'>2019, Jul 04</time>
</span>

  
  
<span class='reading-time'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <circle cx="12" cy="12" r="10"/>
  <polyline points="12 6 12 12 15 15"/>
  
</svg>
5 mins read
</span>


</div>


  </div>
</header>

    
    

    <div class='container entry-content'>
  

<p>前回書いた 「<a href="../sparse-approximate-gp/">ガウス過程の補助変数法 (Inducing variable method) を理解する</a> 」の続き。
Julia (v1.0) を使って、前回調べた SoD, SoR, DTC, FITC による回帰の近似結果を実際に確認する。</p>

<p>簡単のため、<code>gp.jl</code> により、</p>

<ol>
<li>ガウスカーネルのクラス <code>GaussianKernel</code> が定義されていて、<br /></li>
<li>カーネル <code>k</code> に対してカーネル関数 \( k(x, y) \) と相互共分散 \( (k(x_i, y_j))_{i,j}\) がそれぞれ <code>ker(k, x, y)</code> と <code>cov(k, xs, ys)</code> で計算できる</li>
</ol>

<p>と仮定する。ということで、まずはライブラリの読み込み。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">using</span> Distributions
<span style="color:#66d9ef">using</span> Plots
<span style="color:#66d9ef">using</span> LinearAlgebra

include(<span style="color:#e6db74">&#34;gp.jl&#34;</span>)</code></pre></div>
<p>データは、MLPシリーズ 「<a href="http://chasen.org/~daiti-m/gpbook/" target="_blank">ガウス過程と機械学習</a>」の pp.157, 図5.3 補助入力点の配置 と同じサンプルを使う。上記のページに掲載されている、「補助変数法の例 (1次元の場合).」のデータの生成方法を参考にして次のようにデータを100個作成した。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#75715e"># サンプルデータの作成</span>

xs <span style="color:#f92672">=</span> vcat(rand(<span style="color:#ae81ff">80</span>),rand(<span style="color:#ae81ff">20</span>) <span style="color:#f92672">*</span> <span style="color:#ae81ff">3</span> <span style="color:#f92672">.+</span> <span style="color:#ae81ff">1.0</span>)
sort!(xs)
fx <span style="color:#f92672">=</span> sin<span style="color:#f92672">.</span>(xs<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>)
ys <span style="color:#f92672">=</span> fx <span style="color:#f92672">+</span> rand(Normal(), Base<span style="color:#f92672">.</span>length(fx)) <span style="color:#f92672">*</span> <span style="color:#ae81ff">0.3</span>

ts <span style="color:#f92672">=</span> collect(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">0.01</span><span style="color:#f92672">:</span><span style="color:#ae81ff">5</span>)
plot(ts, sin<span style="color:#f92672">.</span>(ts<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>), lw <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>)

scatter!(xs, ys, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>)</code></pre></div>
<p><img src="/images/posts/ivm-sample-data.png" alt="サンプルデータ" /></p>

<p>\( y = \sin (2x) \) にノイズを加えたもので、\( [0,1] \) の間はデータの密度が高くなっている。<code>ts</code> は、あとで使う分布を予測したい点である。</p>

<p>今回予測するのは、観測値 \( y \) ではなく、出力値 \( f \)とする。
(最初にやっていた時は観測値を予測していて、本の図と同じにならなくて混乱していた)</p>

<p>考えるカーネルは、ガウスカーネル \( k(x, x^\prime) = \exp(-|x- x^\prime|^2) \) である。
観測誤差は \( \sigma^2 = 1.0 \) としておく。コードの中ではこれを <code>eta</code> で表す。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">gk <span style="color:#f92672">=</span> GaussianKernel()
eta <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span></code></pre></div>
<h3 id="gp">GP</h3>

<p>まずは、通常のガウス回帰モデルの場合の予測を確認。予測分布は、</p>

<p>$$
    p(\mathbf{f}_* | \mathbf{y}) = \mathcal{N}(\mathbf{K}_{*, \mathbf{f}} (\mathbf{K}_{\mathbf{f}, \mathbf{f}} + \sigma^2 \mathbf{I})^{-1} \mathbf{y},
    \mathbf{K}_{*, *} - \mathbf{K}_{*, \mathbf{f}} (\mathbf{K}_{\mathbf{f}, \mathbf{f}} + \sigma^2 \mathbf{I})^{-1} \mathbf{K}_{\mathbf{f}, *})
$$</p>

<p>であった。今回は、複数点の同時予測分布からサンプルを発生させることは行わず、各点ごとに予測分布を求めて平均と2.5%, 97.5%点を計算する。</p>

<p>1点の予測分布を計算する関数を実装しよう。自分の実装では、<code>cov</code> は行列を返すため、1x1の行列を <code>first</code> を使ってスカラーにしている。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">Kff <span style="color:#f92672">=</span> cov(gk, xs, xs)
n <span style="color:#f92672">=</span> Base<span style="color:#f92672">.</span>length(xs)
Σ <span style="color:#f92672">=</span> inv(Kff <span style="color:#f92672">+</span> eta <span style="color:#f92672">*</span> <span style="color:#66d9ef">Matrix</span>{<span style="color:#66d9ef">Float64</span>}(I, n, n))

<span style="color:#75715e"># 1点の予測分布</span>

<span style="color:#66d9ef">function</span> gp(t)
    Kft <span style="color:#f92672">=</span> cov(gk, xs, [t])
    Ktf <span style="color:#f92672">=</span> Kft<span style="color:#960050;background-color:#1e0010">&#39;</span>
    Ktt <span style="color:#f92672">=</span> [ker(gk, t, t)]

    gp_mu <span style="color:#f92672">=</span> Ktf <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> ys
    gp_cov <span style="color:#f92672">=</span> Ktt <span style="color:#f92672">-</span> Ktf <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kft
    Normal(first(gp_mu), sqrt(first(gp_cov)))
<span style="color:#66d9ef">end</span></code></pre></div>
<p>以下のコードで表示すると、</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">gp_dists <span style="color:#f92672">=</span> [gp(t) <span style="color:#66d9ef">for</span> t <span style="color:#66d9ef">in</span> ts]
gp_mean <span style="color:#f92672">=</span> mean<span style="color:#f92672">.</span>(gp_dists)
gp_qt <span style="color:#f92672">=</span> hcat([quantile<span style="color:#f92672">.</span>(s, [<span style="color:#ae81ff">0.025</span>, <span style="color:#ae81ff">0.975</span>]) <span style="color:#66d9ef">for</span> s <span style="color:#66d9ef">in</span> gp_dists]<span style="color:#f92672">...</span>)

<span style="color:#66d9ef">function</span> gp_plot()
    plot(ts, gp_qt[<span style="color:#ae81ff">1</span>, <span style="color:#f92672">:</span>], fillrange <span style="color:#f92672">=</span> gp_qt[<span style="color:#ae81ff">2</span>, <span style="color:#f92672">:</span>], 
        fillalpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.4</span>, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>, linewidth <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>)

    plot!(ts, sin<span style="color:#f92672">.</span>(ts<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>), lw <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;y=sin(2x)&#34;</span>)
    plot!(ts, gp_mean, lw <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;GP&#34;</span>)
    scatter!(xs, ys, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>)
<span style="color:#66d9ef">end</span>

gp_plot()</code></pre></div>
<p><img src="/images/posts/ivm-gp.png" alt="GP" /></p>

<p>(なぜか <code>savefig</code> でpng形式で保存すると <code>fillrange</code> した最小値の部分に線が出てしまった。)</p>

<p>早速それぞれの変数補助法でどれくらい近似できているかを見ていこう。補助入力点が、2点、5点、10点ある場合を考え、点は等間隔に配置されているとする。(SoD を除く)</p>

<p>本質的な部分とは関係ないが、先にプロット用の関数を定義しておく。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">function</span> plot_result(gp_mean, gp_qt, mn, qt, ind_xs, label)
    plot(ts, gp_qt[<span style="color:#ae81ff">1</span>, <span style="color:#f92672">:</span>], fillrange <span style="color:#f92672">=</span> gp_qt[<span style="color:#ae81ff">2</span>, <span style="color:#f92672">:</span>], 
        fillalpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.4</span>, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;GP&#34;</span>, linewidth <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>)
    plot!(ts, qt[<span style="color:#ae81ff">1</span>, <span style="color:#f92672">:</span>], fillrange <span style="color:#f92672">=</span> qt[<span style="color:#ae81ff">2</span>, <span style="color:#f92672">:</span>], fillalpha <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.4</span>,
               label <span style="color:#f92672">=</span> label, linewidth <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>)

    plot!(ts, gp_mean, lw <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>)
    
    plot!(ts, mn, lw <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>)

    scatter!(xs, ys, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>)
    scatter!(ind_xs, fill(<span style="color:#f92672">-</span><span style="color:#ae81ff">2</span>, Base<span style="color:#f92672">.</span>length(ind_xs)), 
    markershape <span style="color:#f92672">=</span> <span style="color:#f92672">:</span>x, label <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;&#34;</span>)
<span style="color:#66d9ef">end</span></code></pre></div>
<h2 id="the-subset-of-data-sod">The Subset of Data (SoD)</h2>

<p>SoD は他の SoR, DTC, FITC とは違い、任意に補助入力点を選べる訳ではなく元の入力点の部分集合として選ばなくてはいけない。
ここでは、サンプルの左からの順番が等間隔になるように選んだ。(例えば5点選ぶ場合、左から1, 21, 41, 61, 81番目)。</p>

<p>ランダムに選択したり、なるべく等間隔になるように選んだりすればもっとデータがよく代表されるようになり精度が向上するかもしれない。
実装に関しては、GPの入力点を減らしただけである。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">function</span> sod_plot(sod_xs, sod_ys)
    Kff <span style="color:#f92672">=</span> cov(gk, sod_xs, sod_xs)
    n <span style="color:#f92672">=</span> Base<span style="color:#f92672">.</span>length(sod_xs)
    Σ <span style="color:#f92672">=</span> inv(Kff <span style="color:#f92672">+</span> eta <span style="color:#f92672">*</span> <span style="color:#66d9ef">Matrix</span>{<span style="color:#66d9ef">Float64</span>}(I, n, n))

    <span style="color:#75715e"># 各点の分布を計算して信用区間を計算する</span>

    <span style="color:#66d9ef">function</span> sod(t)
        Kft <span style="color:#f92672">=</span> cov(gk, sod_xs, [t])
        Ktf <span style="color:#f92672">=</span> Kft<span style="color:#960050;background-color:#1e0010">&#39;</span>
        Ktt <span style="color:#f92672">=</span> [ker(gk, t, t)]

        gp_mu <span style="color:#f92672">=</span> Ktf <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> sod_ys
        gp_cov <span style="color:#f92672">=</span> Ktt <span style="color:#f92672">-</span> Ktf <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kft
        Normal(first(gp_mu), sqrt(first(gp_cov)))
    <span style="color:#66d9ef">end</span>

    sod_dists <span style="color:#f92672">=</span> [sod(t) <span style="color:#66d9ef">for</span> t <span style="color:#66d9ef">in</span> ts]
    sod_mean <span style="color:#f92672">=</span> mean<span style="color:#f92672">.</span>(sod_dists)
    sod_qt <span style="color:#f92672">=</span> hcat(
        [quantile<span style="color:#f92672">.</span>(s, [<span style="color:#ae81ff">0.025</span>, <span style="color:#ae81ff">0.975</span>]) <span style="color:#66d9ef">for</span> s <span style="color:#66d9ef">in</span> sod_dists]<span style="color:#f92672">...</span>)

    plot_result(gp_mean, gp_qt, sod_mean, sod_qt, sod_xs, <span style="color:#e6db74">&#34;SoD&#34;</span>)
<span style="color:#66d9ef">end</span>

plts <span style="color:#f92672">=</span> [gp_plot()]

<span style="color:#66d9ef">for</span> where_xs <span style="color:#66d9ef">in</span> [<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">50</span><span style="color:#f92672">:</span><span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">20</span><span style="color:#f92672">:</span><span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span><span style="color:#ae81ff">10</span><span style="color:#f92672">:</span><span style="color:#ae81ff">100</span>]
    sod_xs <span style="color:#f92672">=</span> xs[where_xs]
    sod_ys <span style="color:#f92672">=</span> ys[where_xs]

    push!(plts, sod_plot(sod_xs, sod_ys))
<span style="color:#66d9ef">end</span>

plot(plts<span style="color:#f92672">...</span>, layout <span style="color:#f92672">=</span> (<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), size <span style="color:#f92672">=</span> [<span style="color:#ae81ff">800</span>, <span style="color:#ae81ff">600</span>])</code></pre></div>
<p><img src="/images/posts/ivm-sod.png" alt="SoD" /></p>

<p>左上がGPで、補助入力点のx座標はグラフの下部に示している。データの左から順番で等間隔になるように補助入力点を選ぶと、データがスパースなところの情報が大きく切り捨てられてかなり近似が悪くなるということだろう。</p>

<h3 id="the-subset-of-regressors-sor">The Subset of Regressors (SoR)</h3>

<p>前回考えた、予測分布 \( q_{\text{SoR}}(\mathbf{f}_* | \mathbf{y}) \) が
\( \Sigma = (\sigma^{-2} \mathbf{K}_{\mathbf{u}, \mathbf{f}} \mathbf{K}_{\mathbf{f}, \mathbf{u}} + \mathbf{K}_{\mathbf{u}, \mathbf{u}})^{-1} \) を用いて \( \mathcal{N} (\sigma^{-2} \mathbf{K}_{*, \mathbf{u}} \Sigma \mathbf{K}_{\mathbf{u}, \mathbf{f}} \mathbf{y}, \mathbf{K}_{*, \mathbf{u}} \Sigma \mathbf{K}_{\mathbf{u}, *} ) \) と表されることを思い出すと、SoRは次のように実装できる。<code>us</code> の取り方が SoD と違っていることに注意。</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia"><span style="color:#66d9ef">function</span> sor_plot(us)
    Kuu <span style="color:#f92672">=</span> cov(gk, us, us)
    Kuf <span style="color:#f92672">=</span> cov(gk, us, xs)
    Kfu <span style="color:#f92672">=</span> Kuf<span style="color:#960050;background-color:#1e0010">&#39;</span>
    Σ <span style="color:#f92672">=</span> inv(<span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> eta <span style="color:#f92672">*</span> Kuf <span style="color:#f92672">*</span> Kfu <span style="color:#f92672">+</span> Kuu)

    <span style="color:#66d9ef">function</span> sor(t)
        Kut <span style="color:#f92672">=</span> cov(gk, us, [t])
        Ktu <span style="color:#f92672">=</span> Kut<span style="color:#960050;background-color:#1e0010">&#39;</span>

        sor_mu <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> eta <span style="color:#f92672">*</span> Ktu <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kuf <span style="color:#f92672">*</span> ys
        sor_cov <span style="color:#f92672">=</span> Ktu <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kut
        Normal(first(sor_mu), sqrt(first(sor_cov)))
    <span style="color:#66d9ef">end</span>

    sor_dists <span style="color:#f92672">=</span> [sor(t) <span style="color:#66d9ef">for</span> t <span style="color:#66d9ef">in</span> ts]
    sor_mean <span style="color:#f92672">=</span> mean<span style="color:#f92672">.</span>(sor_dists)
    sor_qt <span style="color:#f92672">=</span> hcat(
        [quantile<span style="color:#f92672">.</span>(s, [<span style="color:#ae81ff">0.025</span>, <span style="color:#ae81ff">0.975</span>]) <span style="color:#66d9ef">for</span> s <span style="color:#66d9ef">in</span> sor_dists]<span style="color:#f92672">...</span>)

    plot_result(gp_mean, gp_qt, sor_mean, sor_qt, us, <span style="color:#e6db74">&#34;SoR&#34;</span>)
<span style="color:#66d9ef">end</span>

plts <span style="color:#f92672">=</span> [gp_plot()]

<span style="color:#66d9ef">for</span> du <span style="color:#66d9ef">in</span> [<span style="color:#ae81ff">2.5</span>, <span style="color:#ae81ff">1.0</span>, <span style="color:#ae81ff">0.5</span>]
    us <span style="color:#f92672">=</span> collect(range(<span style="color:#ae81ff">0</span>, stop <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span> <span style="color:#f92672">-</span> du, step <span style="color:#f92672">=</span> du))

    push!(plts, sor_plot(us))
<span style="color:#66d9ef">end</span>

plot(plts<span style="color:#f92672">...</span>, layout <span style="color:#f92672">=</span> (<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>), size <span style="color:#f92672">=</span> [<span style="color:#ae81ff">800</span>, <span style="color:#ae81ff">600</span>])</code></pre></div>
<p><img src="/images/posts/ivm-sor.png" alt="SoR" /></p>

<p>式を見て結構大胆な近似だと思っていたが、この例だと、5点の段階でも入力データが存在している範囲での予測はそう悪くない。</p>

<h3 id="the-deterministic-training-conditional-dtc">The Deterministic Training Conditional (DTC)</h3>

<p>DTC, FITCに関しては、SoRの共分散の計算がちょっと変わるだけ。
$$
    \begin{aligned}
        q_{\text{DTC}}(\mathbf{f}_* | \mathbf{y})
        = \mathcal{N} (\sigma^{-2} \mathbf{K}_{*, \mathbf{u}} \Sigma \mathbf{K}_{\mathbf{u}, \mathbf{f}} \mathbf{y},
        \mathbf{K}_{*, *} - \mathbf{Q}_{*, *} + \mathbf{K}_{*, \mathbf{u}} \Sigma \mathbf{K}_{\mathbf{u}, *} )
    \end{aligned}
$$</p>

<p>だったから、SoRの最初の計算部分を</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">Kuu <span style="color:#f92672">=</span> cov(gk, us, us)
Kuf <span style="color:#f92672">=</span> cov(gk, us, xs)
Kfu <span style="color:#f92672">=</span> Kuf<span style="color:#960050;background-color:#1e0010">&#39;</span>
Σ <span style="color:#f92672">=</span> inv(<span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> eta <span style="color:#f92672">*</span> Kuf <span style="color:#f92672">*</span> Kfu <span style="color:#f92672">+</span> Kuu)

<span style="color:#66d9ef">function</span> dtc(t)
    Kut <span style="color:#f92672">=</span> cov(gk, us, [t])
    Ktu <span style="color:#f92672">=</span> Kut<span style="color:#960050;background-color:#1e0010">&#39;</span>

    Qtt <span style="color:#f92672">=</span> Ktu <span style="color:#f92672">*</span> inv(Kuu) <span style="color:#f92672">*</span> Kut
    Ktt <span style="color:#f92672">=</span> [ker(gk, t, t)]

    sor_mu <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">/</span> eta <span style="color:#f92672">*</span> Ktu <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kuf <span style="color:#f92672">*</span> ys
    sor_cov <span style="color:#f92672">=</span> Ktt <span style="color:#f92672">-</span> Qtt <span style="color:#f92672">+</span> Ktu <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kut

    Normal(first(sor_mu), sqrt(first(sor_cov)))
<span style="color:#66d9ef">end</span></code></pre></div>
<p>に変えるだけでいい。</p>

<p><img src="/images/posts/ivm-dtc.png" alt="DTC" /></p>

<p>5点の場合のデータがない部分の分散の情報がかなり改善されているし、10点ではほとんど平均、分散共にぴったり近似できている。
そうなるとFITCを使うまでもないということにもなりかねないが……</p>

<h3 id="the-fully-independent-training-conditional-fitc">The Fully Independent Training Conditional (FITC)</h3>

<p>最後にFITC。
$$
    \begin{aligned}
        q_{\text{FITC}}(\mathbf{f}_* | \mathbf{y})
        = \mathcal{N} (\mathbf{K}_{*, \mathbf{u}} \Sigma \mathbf{K}_{\mathbf{u}, \mathbf{f}} \Lambda^{-1} \mathbf{y},
        \mathbf{K}_{*, *} - \mathbf{Q}_{*, *} + \mathbf{K}_{*, \mathbf{u}} \Sigma \mathbf{K}_{\mathbf{u}, *} )
    \end{aligned}
$$</p>

<p>から同様に</p>
<div class="highlight"><pre style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-julia" data-lang="julia">Kuu <span style="color:#f92672">=</span> cov(gk, us, us)
Kuf <span style="color:#f92672">=</span> cov(gk, us, xs)
Kfu <span style="color:#f92672">=</span> Kuf<span style="color:#960050;background-color:#1e0010">&#39;</span>

Λ <span style="color:#f92672">=</span> <span style="color:#66d9ef">Diagonal</span>([ker(gk, xs[i], xs[i]) 
        <span style="color:#f92672">-</span> Kfu[i, <span style="color:#f92672">:</span>]<span style="color:#960050;background-color:#1e0010">&#39;</span> <span style="color:#f92672">*</span> inv(Kuu) <span style="color:#f92672">*</span> Kuf[<span style="color:#f92672">:</span>, i] <span style="color:#f92672">+</span> eta 
        <span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>Base<span style="color:#f92672">.</span>length(xs)])
Σ <span style="color:#f92672">=</span> inv(Kuf <span style="color:#f92672">*</span> inv(Λ) <span style="color:#f92672">*</span> Kfu <span style="color:#f92672">+</span> Kuu)

<span style="color:#66d9ef">function</span> fitc(t)
    Kut <span style="color:#f92672">=</span> cov(gk, us, [t])
    Ktu <span style="color:#f92672">=</span> Kut<span style="color:#960050;background-color:#1e0010">&#39;</span>

    Qtt <span style="color:#f92672">=</span> Ktu <span style="color:#f92672">*</span> inv(Kuu) <span style="color:#f92672">*</span> Kut
    Ktt <span style="color:#f92672">=</span> [ker(gk, t, t)]

    sor_mu <span style="color:#f92672">=</span> Ktu <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kuf <span style="color:#f92672">*</span> inv(Λ) <span style="color:#f92672">*</span> ys
    sor_cov <span style="color:#f92672">=</span> Ktt <span style="color:#f92672">-</span> Qtt <span style="color:#f92672">+</span> Ktu <span style="color:#f92672">*</span> Σ <span style="color:#f92672">*</span> Kut

    Normal(first(sor_mu), sqrt(first(sor_cov)))
<span style="color:#66d9ef">end</span></code></pre></div>
<p><img src="/images/posts/ivm-fitc.png" alt="FITC" /></p>

<p>あまりDTCと変わらない感じになってしまった。この場合だと追加で計算した分散の対角線部分があまり効いてこなかったのだろう。</p>

<h3 id="手法の比較">手法の比較</h3>

<p>最後に、点の数を揃えて比較してみる。図示方法を変えるだけなので、コードは省略。</p>

<h4 id="2点">2点</h4>

<p><img src="/images/posts/ivm-2pts.png" alt="2点" /></p>

<h4 id="5点">5点</h4>

<p><img src="/images/posts/ivm-5pts.png" alt="5点" /></p>

<h4 id="10点">10点</h4>

<p><img src="/images/posts/ivm-10pts.png" alt="10点" /></p>

<p>DTCの段階で十分良く近似できていて、\( \mathbf{f} | \mathbf{u} \) の分散の対角部分を考えるメリットがあまり感じられないような結果となってしまった。
どのような場合にFITCの近似ががDTCの場合より劇的に向上するのか考えてみたい。</p>

<p>Jupyter Notebook: <a href="https://nbviewer.jupyter.org/github/matsueushi/gp_and_mlp/blob/master/ivm.ipynb" target="_blank">https://nbviewer.jupyter.org/github/matsueushi/gp_and_mlp/blob/master/ivm.ipynb</a></p>

<p>レポジトリ: <a href="https://github.com/matsueushi/gp_and_mlp" target="_blank">https://github.com/matsueushi/gp_and_mlp</a></p>

  <a href="https://twitter.com/share?ref_src=twsrc%5Etfw" class="twitter-share-button" data-show-count="false">Tweet</a>
  <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
</div>
    
<footer class='entry-footer'>
  <div class='container sep-before'><div class='tags'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M20.59,13.41l-7.17,7.17a2,2,0,0,1-2.83,0L2,12V2H12l8.59,8.59A2,2,0,0,1,20.59,13.41Z"/>
  <line x1="7" y1="7" x2="7" y2="7"/>
  
</svg>
<span class='screen-reader-text'>Tags: </span><a class='tag' href='/tags/gaussianprocess/'>GaussianProcess</a>, <a class='tag' href='/tags/inducingvariablemethod/'>InducingVariableMethod</a>, <a class='tag' href='/tags/sparseapproximation/'>SparseApproximation</a>, <a class='tag' href='/tags/sod/'>SoD</a>, <a class='tag' href='/tags/sor/'>SoR</a>, <a class='tag' href='/tags/dtc/'>DTC</a>, <a class='tag' href='/tags/fitc/'>FITC</a></div>

  </div>
</footer>


</article>
<div id="disqus_thread"></div>
<script type="application/javascript">
    var disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "matsueushi-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

<nav class='entry-nav'>
  <div class='container'><div class='prev-entry sep-before'>
      <a href='/posts/sparse-approximate-gp/'>
        <span aria-hidden='true'><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <line x1="20" y1="12" x2="4" y2="12"/>
  <polyline points="10 18 4 12 10 6"/>
  
</svg>
 Previous</span>
        <span class='screen-reader-text'>Previous post: </span>ガウス過程の補助変数法 (Inducing variable method) を理解する</a>
    </div></div>
</nav>



      </main>

      <footer id='footer' class='footer'>
        <div class='container sep-before'><section class='widget widget-social_menu sep-after'><nav aria-label='Social Menu'>
    <ul><li>
        <a href='https://github.com/matsueushi' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Github account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22"/>
  
</svg>
</a>
      </li><li>
        <a href='https://twitter.com/matsue_ushi' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Open Twitter account in new tab</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"/>
  
</svg>
</a>
      </li><li>
        <a href='mailto:matsueushi@gmail.com' target='_blank' rel='noopener'>
          <span class='screen-reader-text'>Contact via Email</span><svg class='icon' viewbox='0 0 24 24' stroke-linecap='round' stroke-linejoin='round' stroke-width='2' aria-hidden='true'>
  
  <path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z"/>
  <polyline points="22,6 12,13 2,6"/>
  
</svg>
</a>
      </li></ul>
  </nav>
</section><div class='copyright'>
  <p> &copy; 2019 matsueushi </p>
</div>

        </div>
      </footer>

    </div>
  </div><script>window.__assets_js_src="/assets/js/"</script>

<script src='/assets/js/main.67d669ac.js'></script><script src='/js/custom.js'></script><link rel='stylesheet' href='//cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css'>
<script src='//cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js'></script>
<script src='//cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js'></script>

<script type='text/javascript'>
  renderMathInElement(document.querySelector('.entry-content'),{});
</script>

</body>

</html>
