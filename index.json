[
  {
    "contents": "自分用メモ\n行ったライブの記録。まだ他にもあるはず……\n日付 企画名 バンド 会場 2010/6/27 Shimokitazawa Indie Fanclub 2010 神聖かまってちゃん OGRE YOU ASSHOLE 踊ってばかりの国 住所不定無職 and more ERA, Shelter, Garden, etc 2010/9/19 窓辺で手紙を調弦っす。vermail 神聖かまってちゃん\n川本真琴\nフルカワミキ SHIBUYA-AX 2011/7/2 UNIT 7th Anniversary Wire\nFriction\nand more UNIT 2012/4/12 裏の仕業 踊ってばかりの国 下北沢SHELTER 2012/9/8 BAYCAMP2012 0.8秒と衝撃。 Czecho No Republic group_inou 快速東京\nand more 川崎市東扇島東公園 2013/2/7 My Bloody Valentine Japan Tour 2013 My Bloody Valentine Studio Coast 2013/9/11 ふぇのたすのきかく～2013ねん、なつ～ ふぇのたす\n藤岡みなみ\u0026amp;ザ・モローンズ\n椎名琴音\nTHEピンクトカレフ 代田橋FEVER 2013/9/30 My Bloody Valentine World Premium Live \u0026ldquo;New Tracks\u0026rdquo; My Bloody Valentine\n相対性理論 東京国際フォーラム ホールA 2013/10/31 Wild Nothing Japan Tour 2013 Wild Nothing 渋谷クラブクアトロ 2014/2/25 Nine Inch Nails Nine Inch Nails Studio Coast 2014/10/15 andymori ラストライブ andymori 日本武道館 2014/12/31 ふぇのたす大晦日大忘年会、でも曲は忘れないように全曲ライブ ふぇのたす 南青山Lunar 2015/7/5 JAPAN SHOEGAZER FESTIVAL 2015 Lemon\u0026rsquo;s Chair\nPlastic Girl In Closet\n少女スキップ 吉祥寺CLUB SEATA 2015/8/15 Hostess Club All-Nighter Spiritualized\nF.F.S\nBo Ningen\nand more 幕張メッセ 2015/9/19 ＜第一部＞ふぇのたす解散ライブ〜2015年、なつ〜 ふぇのたす 代田橋FEVER 2015/11/26 \u0026ldquo;Psychocandy\u0026rdquo; 30th Anniversary Japan Tour The Jesus and Mary Chain Ex Theater Roppongi 2015/12/1 『Wordplay vol. 31』 波多野浩史 (People In The Box)\n田中茉裕 渋谷La.mama 2016/5/5 〈腹痛が痛い Vol.3〉〜こどもの日もお腹が痛い〜 空中メトロ\n校庭カメラガールツヴァイ\nthe End 渋谷TSUTAYA O-west 2016/5/25 - New Order Studio Coast 2016/6/12 『カネコアヤノとさぐりあい～柴田聡子編～』 カネコアヤノ\n柴田聡子 神保町 視聴室 2016/7/2 TOKYO SWING 3MAN SP. シャンプーハッツ\nダンカンバカヤロー！\nEmily Likes Tennis 新宿Motion 2016/7/9 BULK・期末 BELLRING少女ハート\n挫・人間\nDOTAMA\n校庭カメラガールツヴァイ 渋谷TSUTAYA O-nest 2016/8/21 Hostess Club All-Nighter Deerhunter\nDinasour Jr.\nAnimal Collective\nand more 幕張メッセ 2016/10/7 NME JAPAN presents Richard Ashcroft Japan Tour 2016 Richard Ashcroft Zepp Tokyo 2016/10/28 りりぱ・わんまん \u0026ldquo;ちょおじつりょくはせんげん\u0026rdquo; 挫・人間 WWW 2017/1/16 MALTINE SEED STAGE 01 Lolica Tonica\n食品まつり Hercelot 長谷川白紙 CIRCUS Tokyo 2017/2/27 Hostess Club \u0026amp; Creativeman Presents Pixies Ex Theater Roppongi 2017/8/1 \u0026ldquo;An Evening With\u0026rdquo; Sigur Ros Sigur Ros 東京国際フォーラム ホールA 2017/8/17 Hostess Club All-Nighter Mogwai\nRide\nCigarettes After Sex\nRide\nand more 幕張メッセ 2017/9/10 EPでたよパーティー chelmico\nJabba Da Hutt Football Club Tempalay Sound Museum Vision 2017/9/13 集団行動の単独公演 集団行動 Shibuya WWW 2017/10/23 Wolf Alice Japan Tour 2017 Wolf Alice WWW X 2018/1/21 The Pains of Being Pure At Heart Japan Tour 2018 The Pains of Being Pure At Heart WWW X 2018/1/30 CY8ER 1st ALBUM『ハローニュージェネレーション』発売記念 CY8ER ヴィレッジヴァンガード渋谷 2018/2/23 Pia Fraus Japan Tour 2018 Pia Fraus\nPlastic Girl in Closet Koenji High 2018/4/13 The fin. Tour 2018 The fin. WWW X 2018/7/31 Television Television Elsewhere 2018/9/8 - Mac Demarco\nJuan Wauters Summer Stage, Central Park 2018/9/26 WFUV presents Alvvays (Night 1) Alvvays\nHatchie\nSnail Mail Warsaw Concerts 2018/9/21 - Sales\nNo Vacation\nHana Vu The Bowery Ballroom 2018/12/12 PopGun Presents Curls\nFletcher C Johnson Elsewhere 2018/12/29 Minty Boi Presents No Vacation\nPlastic Picnic\nNavy Gangs Market Hotel 2019/1/17 - Japanese Breakfast Brooklyn Steel 2019/2/16 - Interpol\nCar Seat Headrest\nSnail Mail Madison Square Garden 2019/2/27 The Bowery Presents Deerhunter Brooklyn Steel 2019/5/3 - The Feelies Rough Trade NYC 2019/5/5 - Last Dinosaurs Mercury Lounge 2019/5/20 - MGMT The Capital Theatre 2019/6/14 - Real Estate\nPalm Webstar Hall 2019/7/25 Produced by The Bowery Presents Kurt Vile and The Violators, Dinasour Jr. Cate Le Bon Summerstage, Central Park 2019/7/31 - Snail Mail, Sasami, Duster Blooklyn Steel 2019/8/6 - Mac Demarco Prospect Park Bandshell 2019/9/4 - Hatchie Rought Trade NYC 2019/9/11 - Deerhunter Dirty Projectors Webster Hall 2019/10/10 - Kero Kero Bonito Blooklyn Steel 2019/10/17 - Yung Bae Birocratic Billy Marchiafava Blooklyn Bowl 2019/11/6 - JPEGMAFIA The Bowery Ballroom 2019/11/16 - The Feelies White Eagele Hall 2019/12/14 - Plaid Elsewhere (Hall) ",
    "permalink": "https://matsueushi.github.io/other/live/",
    "tags": null,
    "title": "行ったライブの記録"
  },
  {
    "contents": "AxSxE提供曲 AxSxEが他のアーティストに提供している曲を調べました。リリース日は正確ではないかもしれません。\nリリース アーティスト\n曲名 作詞 作曲/編曲 2001.8.8 TOKIO\nカンパイ!! おちまさと\nBill Martin\nPhilip Coulter 阿瀬研一\nBill Martin\nPhilip Coulter / 船山基紀\n永見竜生 2006.7.19 MAI\n夏NATSUxxx,\nエブリボデー MAI AxSxE 2007.2.7 木村カエラ\nL.drunk 木村カエラ AxSxE / AxSxE 2008.4.2 木村カエラ\nSTARs 木村カエラ AxSxE / AxSxE 2008.9.10 木村カエラ\nマスタッシュ 木村カエラ AxSxE / AxSxE 2009.6.24 木村カエラ\nseason\n📺 木村カエラ AxSxE / AxSxE 2011.3.2 LOOP CHILD\n魔法のレシピ 柴野真理子\nカワムラユキ 柴野真理子\n篠崎哲也\nAxSxE 2012.2.22 ジェロ\n黄昏メトロ アイン AxSxE 2012.5.16 木村カエラ\nマミレル 木村カエラ AxSxE 2012.5.16 木村カエラ\nSynchronicity 木村カエラ AxSxE 2012.12.5 南波志帆\n「ありゃりゃ？」 津野米咲 AxSxE / 矢野博康 2013.12.4 後藤まりこ\nすばらしい世界。 後藤まりこ\nAxSxE AxSxE 2014.4.2 lyrical school\nbrand new day\n📺 LITTLE AxSxE / AxSxE 2014.12.17 木村カエラ\none more 木村カエラ AxSxE 2015.9.2 木村カエラ\nSHOW TIME 木村カエラ AxSxE / H ZETT M 2016.7.6 lyrical school\nサマーファンデーション\n📺 LITTLE AxSxE / AxSxE 2016.10.19 木村カエラ\nHappyな法被 木村カエラ AxSxE / AxSxE 2016.11.23 ONEPIXCEL\nTONDEKE\n📺 IMATETSU AxSxE 2017.5.10 木村カエラ\nHOLIDAYS 木村カエラ AxSxE 2018.6.6 私立恵比寿中学\n響 後藤まりこ AxSxE / 野村陽一郎 2018.10.31 近田春夫\n超冗談だから\n📺 児玉雨子 AxSxE / AxSxE 2018.11.21 木村カエラ\nCOLOR\n📺 木村カエラ AxSxE / AxSxE 2019.7.31 木村カエラ\n戦闘的ファンタジー 木村カエラ AxSxE / AxSxE 2021.11.24 アンナ・ジ・エンド\nはっぴーばーすでー アンナ・ジ・エンド AxSxE\nアンナ・ジ・エンド インタビュー 『感情的format』発売記念対談『感情的音楽談義』 (アーカイブ) 『bounce』 262号(2005/2/25) NATSUMEN (アーカイブ) 【復刻インタビュー】吉田 肇（PANICSMILE）×AxSxE（2007年5月号）- 結成15周年を迎えるPANICSMILEが提唱する素晴らしき情操教育！ - インタビュー | Rooftop (1) (アーカイブ) 【復刻インタビュー】吉田 肇（PANICSMILE）×AxSxE（2007年5月号）- 結成15周年を迎えるPANICSMILEが提唱する素晴らしき情操教育！ - インタビュー | Rooftop (2) (アーカイブ) 【復刻インタビュー】吉田 肇（PANICSMILE）×AxSxE（2007年5月号）- 結成15周年を迎えるPANICSMILEが提唱する素晴らしき情操教育！ - インタビュー | Rooftop (3) (アーカイブ) 「セカンドライン vol.1」(SL001) AxSxE独占ロングインタビュー 言いっ放しの業界覆面座談会＠某ビニールハウス～「AxSxEは●●先輩だった！」 (アーカイブ) INDIES ISSUE 58 対談・の子×AxSxE 「『つまんね』のころから、自分が表現したい神秘的な部分をうまい具合に引き出せている」 秋葉原CLUB GOODMAN\n【偏見対談】 AxSxE（NATSUMEN）編 #01 (アーカイブ) 【偏見対談】 AxSxE（NATSUMEN）編 #02 (アーカイブ) 【偏見対談】 AxSxE（NATSUMEN）編 #03 (アーカイブ) 【偏見対談】 AxSxE（NATSUMEN）編 #04 (アーカイブ) 【偏見対談】 AxSxE（NATSUMEN）編 #05 (アーカイブ) 【偏見対談】 AxSxE（NATSUMEN）編 #06 (アーカイブ) 【偏見対談】 AxSxE（NATSUMEN）編 #07 (アーカイブ) AxSxEレコーディングエンジニア参加リスト 作成中\u0026hellip;\nhttps://www.discogs.com/ja/artist/1309189-AxSxE?noanv=1\n2010年\n3rdフルアルバム「Harkitek or ta ayoro (ハルキテク オッ タ アヨロ)」2010.4.21 発売 (アーカイブ) 2011年\n住所不定無職 ジャカジャーン (アーカイブ) 2012年\n元ビークルのケイタイモ率いる豪華13人のプログレ吹奏楽バンドによる会心の初作 2014年\nうみのて1stフルアルバムは『IN RAINBOW TOKYO』、エンジニアはAxSxE (アーカイブ) 2014年\n東京カランコロン – いちろーがメイン・ボーカルとしてフィーチャーされた３曲を収めたシングル「笑うドッペルゲンガー」について、いちろー＆せんせいに話を聞く。 (アーカイブ) ご近所の個性派ミュージシャン集結バンドOishiiOishii（おいしいおいしい）デビューアルバム発売 (アーカイブ) WUJA BIN BIN 2st ALBUM (アーカイブ) 2016年\nFUCKER（谷ぐち順）1stアルバム発売、レコ発開催決定！ (アーカイブ) MUSIC FROM THE MARS、9年ぶり新作『After Midnight』より新世代ジャズ耳にも◎な“Motion”公開\u0026amp;類家心平迎えたレコ発も 2017年\n挫・人間 公式ブログ - 明日、俺はAxSxEになる……その1 (アーカイブ) 挫・人間 公式ブログ - 明日、俺はAxSxEになる……その2 (アーカイブ) 挫・人間 公式ブログ - 明日、俺はAxSxEになる……その3 (アーカイブ) 挫・人間 公式ブログ - 明日、俺はAxSxEになる……その4 (アーカイブ) bossston cruizing mania、6年振り新AL完成披露イベント開催 収録曲MVも公開 (アーカイブ) 2019年\n【OishiiOishii Country Blues Tour】 (アーカイブ) ",
    "permalink": "https://matsueushi.github.io/other/axsxe/",
    "tags": null,
    "title": "AxSxEまとめ"
  },
  {
    "contents": "アルバムの紹介にも書いたバンドBOaTの情報がインターネット上で見つかりづらいので、 関連する情報をこのページにまとめていきたいと思います。\n当初はBOaT関連の情報だけまとめようと思っていたのですが、NATSUMEN関連の情報や、自分がメモしておきたい情報も混ざってきています。\n耳寄りな情報があればコメント欄などで教えていただけるとありがたいです。\n公式サイト BOaT (Internet Archive)\nアーティスト紹介 FACTORY8 (アーカイブ) ワーナーミュージック (アーカイブ) Discography Discogs 私設 NATSUMEN データベース内のboatのページ (Internet Archive) いぬん堂: M☆N☆T 80\u0026rsquo;s 上二つには載っていない インタビュー記事、雑誌掲載など 媒体名 号数・日付 記事タイトル Archive ROCKIN’ON JAPAN 1999/8 new comer boat 恐るべし、天然記念物級の無防備ギターポップ ROCKIN’ON JAPAN 1999/8 FRUITS★Lee広告「梅雨明け宣言！夏だ！プールを占拠しろ！」 Indies Magazine 1998/8 (Vol.16) 究極の胸キュン☆パワーポップ Archive FM OSAKA EZM 1998/12/25 OA EZM2(ゲスト) Archive Web Jungle boat 1999.4 Archive bounce 1999/4 キャラや遊び心が初期サザンを彷彿とさせるBOATのポップでパンクでドリーミーな世界! ROCKIN’ON JAPAN 1999/4 沖縄レコーディングで大苦戦 ROCKIN\u0026rsquo;ON JAPAN 1999/4 BOATってこんな奴！\n連載第1回 ASE (ギター\u0026amp;ボーカル担当) ROCKIN\u0026rsquo;ON JAPAN 1999/4 Disc Review(SOUL, THRASH, TRAIN) Sound and Recording Magazine 1999/5 捨て曲も全然力は抜いてないんですよ Indies Magazine 1999/5 (Vol.23) 全人類抹殺のための宣戦布告！ Archive ROCKIN\u0026rsquo;ON JAPAN 1999/5 「楽しくやってる」風に映るのを変えたいと思った ROCKIN\u0026rsquo;ON JAPAN 1999/5 BOATってこんな奴！\n連載第2回 アイン(ボーカル\u0026amp;ミミング担当) クイック・ジャパン 1999/6 (Vol.25) 今度、作りますよ、「僕、ブルーハーツが好きだ」って曲。\u0026ldquo;BOAT\u0026quot;リーダーA.S.E氏インタビュー ROCKIN\u0026rsquo;ON JAPAN 1999/6 BOATってこんな奴！\n連載第3回 シオリ(ベース\u0026amp;ボーカル担当) ROCKIN\u0026rsquo;ON JAPAN 1999/7 BOATってこんな奴！\n連載第4回 サカイ(キーボード\u0026amp;コーラス担当) ROCKIN\u0026rsquo;ON JAPAN 1999/8 BOATってこんな奴！\n連載第5回 マユコ(ドラムス\u0026amp;コーラス担当) happy voice vol 00 side a 1999/8 お父さんとかも気に入るんやーってびっくりしましたよ(笑)。(A.S.E.) happy voice vol 00 side a 1999/8 Questionnarie (A.S.E.) B-PASS 1999/8 INDIES ATTACK! ACT4 bounce 1999/9 headstart So-net Music music club on line Brand New Artist 2000.6.22 Archive happy voice vol 03 happy voice \u0026amp; BoaT (from A.S.E.\u0026amp;アイン) 商店街でお買いもの!! 音楽と人 2000/8 メッセージを届けに Maqruee 2000/8 (Vol.26) ASE presents\u0026hellip; LIVE TRANCE UNDER THE SKY Rhythm \u0026amp; Drums magazine 2000/9 BoaTマユコ 音楽と人 2000/9 Front Issue! BOaT 音楽と人 2000/9 LISTENING SUICIDAL広告 ROCKIN\u0026rsquo;ON JAPAN 2000/9 Disc Review(LISTENING SUICIDAL) Bass magazine 2000/9 しおりインタビュー\n「新世代のミクスチャー・ポップ・ロック」 Sound \u0026amp; Recording magazine 2000/10 ファースト・テイクには何かがある その精神をアイゴンに注入されました Guitar magazine 2000/10 アセ(BOaT)インタビュー\n「今の時点でどっちに転ぶかはわからない。……沼地に行くんか青空に行くんか、どっちかわからん。」 Indies Magazine 2000/10 (Vol.40) 矛盾だらけの妄想好き？『LISTENING SUICIDAL』の真実 Archive out voice happy voice*spring2001 BOAT x 界 ROCKIN\u0026rsquo;ON JAPAN 2001/4 Disc Review (RORO) Bass magazine 2001/5 〜ベースと彼女とエトセトラ〜 ガールスクール SHIORI(BOAT) Keyboard Magazine 2001/5 坂井キヨオシインタビュー\n「同じフレーズを繰り返すことで、陶酔感みたいな効果を出したかったんです」 SNS, 配信 アメリカの同名バンドと一緒のページにまとめられている場合がある。\nlast.fm Rate Your Music MusicBrainz mixiコミュニティ BOaT（BOAT） ～2001 Apple Music 「フルーツ☆リー」「SOUL.THRASH.TRAIN」が配信されている。 2ch/5ch過去ログ BOAT (2001/4/4 - 2001/4/15) 「ｂｏａｔ」 (2001/04/19 - 2001/05/14) 今度こそ浮沈ＢＯＡＴにするスレだ！！！ (2001/10/27 - 2002/01/11) ○BOAT / NATSUMEN○ (2003/06/04 - 2004/02/16) ○NATSUMEN / BOAT○ part.xxx (2004/09/29 - 2005/03/05) ◆BOaT◆ (2005/03/29 - 2007/03/03) 【ついに】BOaT【復活？】 (2007/03/06 - ) (参考) NATSUMENスレ\nxxx　NATSUMEN　xxx (2005/03/04 - 2005/07/20) xxx　NATSUMEN　part.2　xxx (2005/07/20 - 2006/02/08) xxx　NATSUMEN part.3 xxx (2006/02/07 - 2006/08/30) xxx　NATSUMEN part.4 xxx (2006/08/30 - 2008/10/10) xxx　NATSUMEN part.5 xxx (2008/10/11 - 2008/11/16) xxx NATSUMEN pt.5 xxx (2008/12/04 - 2014/03/20) xxx　NATSUMEN part.6 xxx (2008/12/05 - 2008/12/05) xxx NATSUMEN pt.6 xxx (2014/06/23 - 2014/08/23) reddit BOaT - All [japanese post-rock] (2001) BOaT - All (Post-rock from Japan, 2001) BOAT - RORO (Stupidly underrated Japanese post-rock/alt rock album) BOaT - Roro [2001] ライブ情報、ライブレポ、感想など 公式サイトのライブのお知らせ (Internet Archive) 下北沢シェルター 1999.1.21 (アーカイブ) WEB BEA VOICE Vol.263 (Internet Archive) happy voice vol 02 side a, happy voice night 004 ライブビート 2000/7/5 (Internet Archive, 文字化け) FACTORY8 #0006 Opening Act : boat - Live (アーカイブ) onabenchinthepark - S.E.P. 2001 @Electric Lady Land\u0026amp;ell.FITS ALL (NANANINE / ハックルベリーフィン / YOGURT-pooh / HAGANE / SCREAMING SOUL HILL / 古明地洋哉 / CHOKO / KICK THE CAN CREW / BOAT / ケツメイシ / アルファ / SOUL\u0026rsquo;D OUT ) (アーカイブ) Club Cue LIVE REPORT 2001, 2001.9.28 \u0026ldquo;THE 7 WONDERS OF Que～CLUB Que 7th Anniversary～\u0026rdquo; Clingon vs BOAT (アーカイブ) Date Cource Pentagon Royal Garden @ Shibuya Quattro (22nd Sept. \u0026lsquo;01) (アーカイブ) Wouldn\u0026rsquo;t It Be Nice - BOaT : RORO (2001) (アーカイブ) その他 しもブロ 第3-1回『ぽわん』 ～ コラム：下北沢は通過点でかまわない (アーカイブ) ライブの写真が見れる サークルサウンズの輪 - boat CIRCLE SOUNDS インタビュー | 30周年を迎えたリハーサルスタジオが見てきた景色とは (アーカイブ) アルバム全曲レビュースレ（in 2ch.邦楽板）勝手にまとめサイト：BOaT ",
    "permalink": "https://matsueushi.github.io/other/boat/",
    "tags": [
      "BOAT"
    ],
    "title": "BOaTまとめ"
  },
  {
    "contents": "https://atcoder.jp/contests/abc181/tasks/abc181_f\n$r$ を動かした時に、動かす円の中心が存在できない範囲を考えてみる。 壁もしくは障害物から距離 $r$ 未満の位置に円の中心を配置することができないことを考えると、動かせない範囲は下の青色で示した領域の内部になる。\n上の壁と下の壁が図で示した青色の領域を通じて繋がっていなければ円が通過でき、繋がっていれば円が通過できない。 繋がっているか繋がっていないかはUnionFindで判定できる。\n$y=100$ と 釘 $(x_i, y_i)$ が繋がっている \u0026lt;=\u0026gt; $y_i + 2 r \u0026gt; 100$ $y=-100$ と 釘 $(x_i, y_i)$ が繋がっている \u0026lt;=\u0026gt; $y_i - 2 r \u0026lt; 100$ 釘 $(x_i, y_i)$ と 釘 $(x_j, y_j)$ が繋がっている \u0026lt;=\u0026gt; $(x_i-x_j)^2 + (y_i-y_j)^2 \u0026lt; (2r)^2$ これで $r$ が与えられたときの判定方法がわかったので、あとは $r$ を二分探索する。\nhttps://atcoder.jp/contests/abc181/submissions/34127397 (Rust, 14ms)\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc181-f/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 181 F - Silver Woods"
  },
  {
    "contents": " オーストラリアのシンガーソングライターCeleb Toogoodによるソロプロジェクト（多分）Toytown。\nゆるいベッドルーム・ポップだが曲がどれもいい。どこかふざけた感じというか捻った感じがあるのも自分にはストライク。 マック・デマルコが好きな人なら刺さるのではないでしょうか。\nかなり推したいアルバム、アーティストなのだが、悲しいことに知名度が無に近く、詳しい情報も不明です。 Spotifyの再生回数、YouTubeのMVの再生回数、Facebookのいいね数、軒並みどれも低く、謎です。\nアルバムを2019年に出して以降目立った活動が見られないですが、 どうかこのままフェードアウトせずに次の作品を聞かせてほしいです。\nbamdcamp\nYouTube\nFacebook\nInstagram\nSoundCloud\n",
    "permalink": "https://matsueushi.github.io/posts/toytown-killed-my-dog/",
    "tags": [
      "Music"
    ],
    "title": "Toytown - Killed My Dog (2019)"
  },
  {
    "contents": "vscodeでアタッチしたコンテナからコミットしようとすると、\nfatal: cannot run /usr/local/bin/gpg: No such file or directory\nというメッセージが出てコミットできない。ローカルではGPGの設定をしているのだが、コンテナ内では設定されていないので怒られている模様。\n\u0026gt; git -c user.useConfigOnly=true commit --quiet --allow-empty-message --file - -S fatal: cannot run /usr/local/bin/gpg: No such file or directory error: gpg failed to sign the data fatal: failed to write commit object https://stackoverflow.com/questions/36941533/git-hub-desktop-on-mac-error-cannot-run-gpg-no-such-file-or-directory を参考にして、\ngit config --global gpg.program \u0026#34;$(which gpg)\u0026#34; をコンテナ内で実行したら解決した。\n",
    "permalink": "https://matsueushi.github.io/posts/vscode-container-gpg/",
    "tags": [
      "Git",
      "GPG"
    ],
    "title": "Dockerコンテナ上でコミットしようとしたらGPGのエラーが出てきた"
  },
  {
    "contents": "Julia では argmin とか argmax などの関数が用意されていたのですが、 Rust で同様の処理をする方法がわからず毎回調べて時間を消耗していたので、まとめておこうと思います。\nもっと簡単な書き方があれば教えてください。\nfld, cld fldは/を単に使えば良い気もします。\nfn main(){ let a: i64 = 8; let b = 3; assert_eq!(num::Integer::div_floor(\u0026amp;a, \u0026amp;b), 2); } fn main(){ let a: i64 = 8; let b = 3; assert_eq!(num::Integer::div_ceil(\u0026amp;a, \u0026amp;b), 3); } broadcast map を使えば良い。\nfn main() { let v = [1, -2, 3, -4, 5]; let x = v.map(|x: i64| x.abs()); assert_eq!(x, [1, 2, 3, 4, 5]); } fn main() { let v = vec![1, -2, 3, -4, 5]; let x = v.iter().map(|\u0026amp;x:\u0026amp;i64| x.abs()).collect::\u0026lt;Vec\u0026lt;_\u0026gt;\u0026gt;(); assert_eq!(x, vec![1, 2, 3, 4, 5]); } findmin(itr) fn main() { let v = [1, 7, 7, 6]; let x = v.iter().enumerate().min_by_key(|\u0026amp;(_, x)| x); assert_eq!(x, Some((0, \u0026amp;1))); } (index, x) の順になる。min_by_key は最小値を達成するインデックスが複数ある場合、最初のインデックスを返すところは findmin と同じですね。\nfindmax(itr) max_by_key を使って書くと\nfn main() { let v = [1, 7, 7, 6]; let x = v.iter().enumerate().max_by_key(|\u0026amp;(_, x)| x); assert_eq!(x, Some((2, \u0026amp;7))); } (index, x) の順になる。max_by_keyは最大値が達成するインデックスが複数ある時、最後のインデックスが帰ってくるので、 最初のインデックスを返す findmax とは挙動が異なる。\nuse core::cmp::Reverse; fn main() { let v = [1, 7, 7, 6]; let x = v.iter().enumerate().min_by_key(|\u0026amp;(_, x)| Reverse(x)); assert_eq!(x, Some((1, \u0026amp;7))); } とすれば最初のインデックスを返せる。\nargmin(itr) findmin とほぼ同じ。\nfn main() { let v = [1, 7, 7, 6]; let x = v.iter().enumerate().min_by_key(|\u0026amp;(_, x)| x).map(|x| x.0); assert_eq!(x, Some(0)); } argmax(itr) findmax とほぼ同じ。最大値を取る添字が複数ある場合に最後のインデックスを返したければ、\nfn main() { let v = [1, 7, 7, 6]; let x = v.iter().enumerate().max_by_key(|\u0026amp;(_, x)| x).map(|x| x.0); assert_eq!(x, Some(2)) } 最初としたければ、\nuse core::cmp::Reverse; fn main() { let v = [1, 7, 7, 6]; let x = v .iter() .enumerate() .min_by_key(|\u0026amp;(_, x)| Reverse(x)) .map(|x| x.0); assert_eq!(x, Some(1)); } cumsum(itr) itertools_num を使ってよければ、\nuse itertools_num::ItertoolsNum; fn main() { let v = [1, 1, 1]; let x: Vec\u0026lt;i64\u0026gt; = v.iter().cumsum().collect(); assert_eq!(x, vec![1, 2, 3]); } 最初に0を入れ込みたい場合は、\nfn main() { let v = [1, 1, 1]; let mut x = vec![0]; for i in 0..v.len() { x.push(x[i] + v[i]); } assert_eq!(x, vec![0, 1, 2, 3]); } Rust の Iterator で cumsum をどう書くべきか、あるいは map の闇 cumprod(itr) fn main() { let v = [1, 2, 3]; let mut x = vec![1]; for i in 0..v.len() { x.push(x[i] * v[i]); } assert_eq!(x, vec![1, 1, 2, 6]); } sortperm fn main() { let v = [-5, 4, 1, -3, 2]; let mut x = (0..v.len()).collect::\u0026lt;Vec\u0026lt;_\u0026gt;\u0026gt;(); x.sort_by_key(|\u0026amp;i| \u0026amp;v[i]); assert_eq!(x, [0, 3, 2, 4, 1]); } sortがunstableでよければ、\nfn main() { let v = [-5, 4, 1, -3, 2]; let mut x = (0..v.len()).collect::\u0026lt;Vec\u0026lt;_\u0026gt;\u0026gt;(); x.sort_unstable_by_key(|\u0026amp;i| \u0026amp;v[i]); assert_eq!(x, [0, 3, 2, 4, 1]); } searchsortedfirst 1.52.0 以降だと partition_point が使える。\nfn main() { let v = [1, 2, 4, 5, 5, 7]; let i = v.partition_point(|\u0026amp;x| !(x \u0026gt;= 4)); assert_eq!(i, 2); let i = v.partition_point(|\u0026amp;x| !(x \u0026gt;= 5)); assert_eq!(i, 3); let i = v.partition_point(|\u0026amp;x| !(x \u0026gt;= 3)); assert_eq!(i, 2); let i = v.partition_point(|\u0026amp;x| !(x \u0026gt;= 9)); assert_eq!(i, 6); let i = v.partition_point(|\u0026amp;x| !(x \u0026gt;= 0)); assert_eq!(i, 0); } AtCoder で使える Rust 1.42.0 だと工夫して\nuse std::cmp::Ordering::{Greater, Less}; fn main() { let v = [1, 2, 4, 5, 5, 7]; let i = v .binary_search_by(|\u0026amp;x| if !(x \u0026gt;= 4) { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 2); let i = v .binary_search_by(|\u0026amp;x| if !(x \u0026gt;= 5) { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 3); let i = v .binary_search_by(|\u0026amp;x| if !(x \u0026gt;= 3) { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 2); let i = v .binary_search_by(|\u0026amp;x| if !(x \u0026gt;= 9) { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 6); let i = v .binary_search_by(|\u0026amp;x| if !(x \u0026gt;= 0) { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 0); } searchsortedlast 1.52.0 以降だと partition_point が使える。 インデックスに注意。\nfn main() { let v = [1, 2, 4, 5, 5, 7]; let i = v.partition_point(|\u0026amp;x| x \u0026lt;= 4); assert_eq!(i, 3); let i = v.partition_point(|\u0026amp;x| x \u0026lt;= 5); assert_eq!(i, 5); let i = v.partition_point(|\u0026amp;x| x \u0026lt;= 3); assert_eq!(i, 2); let i = v.partition_point(|\u0026amp;x| x \u0026lt;= 9); assert_eq!(i, 6); let i = v.partition_point(|\u0026amp;x| x \u0026lt;= 0); assert_eq!(i, 0); } use std::cmp::Ordering::{Greater, Less}; fn main() { let v = [1, 2, 4, 5, 5, 7]; let i = v .binary_search_by(|\u0026amp;x| if x \u0026lt;= 4 { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 3); let i = v .binary_search_by(|\u0026amp;x| if x \u0026lt;= 5 { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 5); let i = v .binary_search_by(|\u0026amp;x| if x \u0026lt;= 3 { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 2); let i = v .binary_search_by(|\u0026amp;x| if x \u0026lt;= 9 { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 6); let i = v .binary_search_by(|\u0026amp;x| if x \u0026lt;= 0 { Less } else { Greater }) .unwrap_or_else(|i| i); assert_eq!(i, 0); } usize で 絶対値をを取るとき (abs_diffが入っていないバージョンの時)\nfn abs_diff\u0026lt;T\u0026gt;(a: T, b: T) -\u0026gt; T where T: Sub\u0026lt;Output = T\u0026gt; + PartialOrd, { if a \u0026gt; b { a - b } else { b - a } } ",
    "permalink": "https://matsueushi.github.io/posts/julia-rust/",
    "tags": [
      "Julia",
      "Rust"
    ],
    "title": "Rustでargminやargmaxはどう書くのか"
  },
  {
    "contents": "完全に自分用です。\n調べ物 国立国会図書館オンライン リサーチ・ナビ 人文系データベース協議会 図書館関連 図書館総合展 ししょまろはんラボ 図書館で著作権処理やってた人が没年調査ソン in福井 第2回に参加して考えたこと 音楽関連 90年代シティポップ記録簿(90\u0026rsquo;s City Pop Record Book) プログラミング関連 Rustの良質な学習リソースをまとめる たまに振り返って読みたくなるもの 笑笑果茶、その半年間の軌跡 とうもろこし牛乳タピオカ再生プロジェクト ",
    "permalink": "https://matsueushi.github.io/other/bookmark/",
    "tags": null,
    "title": "Bookmark"
  },
  {
    "contents": "自分用メモ\nセグメント木 できること 完全二分木で区間を表現することで、一点更新・区間取得のクエリが処理できる。\nモノイド $S = (S, \\cdot, e)$ が定義されているとき、数列 $\\{s_i\\}_{i=1}^n$ に対して、\n代入操作: $s_i := s \\in S$ 区間取得操作: 区間 $[i, j)$ に対して $s_i \\cdot s_{i+1} \\cdots s_{j-1}$ を計算 を $O(\\log n)$ で処理する\n$\\mathbb{Z}\u0026rsquo;$ を上限と下限がある整数全体の集合とした時、 $S=(\\mathbb{Z}\u0026rsquo;, \\max(S), \\min)$ とおけば Range Minimum Query。 Fenwick Tree は、$(\\mathbb{Z}, 0, +)$ に対応。 遅延セグメント木 モチベーション 通常のセグメント木だと一点更新するだけで点を含む全ての区間の値を更新するので、区間更新の計算量が多くなってしまう。 そのためもう一つ二分木を使って区間取得操作や二度目の更新操作の時まで値の更新を遅らせたい。\nできること モノイド $S = (S, \\cdot, e_S)$ (セグメント木上に乗せるデータ) モノイド $X = (X, \\cdot, e_X)$ (遅延伝播させるデータ) $X$ の $S$ に対する 右作用 $* : S \\times X \\rightarrow S$ が与えられた時、\n区間適用操作: 区間 $[i, j)$ に対して $x \\in X$ を適用する。 $s_k := x \\cdot s_k$ 区間取得操作: 区間 $[i, j)$ に対して $s_i \\cdot s_{i+1} \\cdots s_{j-1}$ を計算 を $O(\\log n)$ で処理する\n$S$ をモノイド、 $X$ を $id_S$ と $x_t: S \\rightarrow S, s \\mapsto t, t\\in S$ からなる集合とすると、$S$ は写像の合成に関して $id_S$ を単位元とするモノイドとなる。$X$ は代入操作に対応した作用。$S=(\\mathbb{Z}\u0026rsquo;, \\max(S), \\min)$ とすると区間代入・区間取得の Range Minimum QUery 参考 セグメント木を徹底解説！0から遅延評価やモノイドまで AC Library - Lazy Segtree いかたこのたこつぼ セグメント木 ",
    "permalink": "https://matsueushi.github.io/other/segtree/",
    "tags": null,
    "title": "セグメント木"
  },
  {
    "contents": "2021年に解散したアイドルグループCY8ERの前身であるBPM15Qが唯一世に送り出したアルバムである。私はこのアルバムはアイドルという枠を超えた普遍的な名盤だと思う。criminally underrated album と言いたい。\n元BiS、元アキシブprojectメンバーの”苺りなはむ”と、クラブシーンでも活躍する”にかもきゅ”の二人により2015年5月31日に結成された、ニューエイジボカールDJユニット”BPM15Q(ビーピーエムイチゴーキュー)”待望のファースト・アルバムがリリース!ファンから音源化の要望も多かった、プティパ-petit pas!-とのコラボ曲も収録。\nファーストアルバムと書かれているが実質的には (BPM15Qとしては) ラストアルバム、ベストアルベムである。アルバムにつけられた品番が \u0026ldquo;BPM15-9\u0026rdquo; であることもBPM15Q自体の活動の集大成をこの一枚に凝縮したという意思が伝わる。\nジャンルといえばElectro Pop, (Kawaii) Future Bassといったところか。 「BPM15Q!」で始まり「GOOD LUCK」で締められる。可愛いピコピコサウンドなのだが、アルバムを通して聞いた後には 目眩く楽しい夢のような時間が気づくと終わっているような、そんな寂寥感をどこか感じさせる。\nBPM15Qから体制が変わり(改名という立て付けだったが実質的には別物だと思う)CY8ERになった後のアルバムも聞いたが、この「BPM15Q ALL SONGS」のアルバムとしての完成度は頭一つ抜けている。 CY8ERになってからこのアルバムに収録されている曲は再録されているが、うまく言葉で言い表せないが「BPM15Q ALL SONGS」に収録されているものとは自分の中では別物のように感じられる。\n参考だが、CDとストリーミングでは収録曲が少し異なっている。ストリーミングではコラボ曲「ごーしゅー」が削除され、最終曲は、「GOOD LUCK」の後の再会を予期させるような、Lolica Tonicaのヒイラギペイジによる「ゆびきり」に差し替えられている。アルバムとしての曲の並びの完成度という意味ではCDよりストリーミングの方が上だろう。\nCDは残念ながらプレミア価格となり高騰してしまっているが、幸いなことにサブスクで配信されているので聴くのは容易。是非聴いてみてほしい。\n",
    "permalink": "https://matsueushi.github.io/posts/bpm15q-all-songs/",
    "tags": [
      "Music",
      "Jpop"
    ],
    "title": "BPM15Q / BPM15Q ALL SONGS (2016)"
  },
  {
    "contents": "https://atcoder.jp/contests/tenka1-2018/tasks/tenka1_2018_c\n正の整数からなる数列 $\\{A_i\\}_i$ が与えられた時に、 数列を自由に並び替えた時の隣り合う要素の差の合計の最大値を求めよ、という問題。\n大小関係がジグザグにすれば良い、ということはなんとなくわかったが、 解説を読んでもピンと来なかったので整理しておく。\nまず、$A_i$ はソートされていると考えて良いだろう。すると、次のような問題を考えれば良いことになる。\n数直線の上に $\\{A_i\\}_i$ が並んでいる。始点と終点を異なるように選び、全ての点を一回ずつ通って進む。移動距離の最大値を求めよ。 $A_i$ と $A_{i+1}$ が作る区間を $I_i$ とし、その長さを $B_i = A_{i+1}-A_i$ とおく。 上の図だと、$A_1$ から $A_5$ まで点があり、区間が $I_1$ から $I_4$ まである。\n始点=終点の場合を考えてみる 脱線するが、最初に始点 = 終点 となる場合の変種を考える。\nそれぞれの区間を通過する最大回数を考える。 $I_1$ から順番に考えていくと、$I_1$ を通過するのは $A_1$ から出ていく時か、$A_1$ に入る時の高々2回しかない。 $I_2$ を考えると、 $I_1$ で考えた $A_1$ から出ていく矢印、 $A_1$ に戻る矢印がそのまま2を通過する場合と、 新たに $A_2$ に出入りする矢印がある場合の高々4通りである。\nこのように考え、さらに左右の対称性も考慮すると、区間 $I_i$ を通過する回数は、最大 $2\\min (i, n-i)$ 回であることがわかる。\nまた、この最大値をとるような動き方は、上の図のようにジグザグに移動することで必ず達成でき、 $2\\sum_{i=1}^{n-1} \\min (i, n-i) B_i$ が移動距離の最大値であることがわかる。\n始点と終点が異なる場合 始点と終点が異なる場合、移動距離 $2\\sum_{i=1}^{n-1} \\min (i, n-i) B_i$ は達成できない。\nしかし、上のようにジグザグに動くことを考えると、\n$n = 2m-1$, 奇数の場合 : $2\\sum_{i=1}^{n-1} \\min (i, n-i) B_i - B_{m-1}$ や $2\\sum_{i=1}^{n-1} \\min (i, n-i) B_i - B_m$ $n = 2m$, 偶数の場合 : $2\\sum_{i=1}^{n-1} \\min (i, n-i) B_i - B_m$ は達成できることがわかる。それぞれ始点、終点の位置の集合は\n$n = 2m-1$, 奇数の場合 : $\\{A_{m-1},A_m\\}$ または $\\{A_m,A_{m+1}\\}$ $n = 2m$, 偶数の場合 : $\\{A_m,A_{m+1}\\}$ と中央の位置にある場合になる。始点と終点が一致する時の通過回数の最大回数に比べ、通過回数の差は\n$n = 2m-1$, 奇数の場合 : $I_{m-1}$ または $I_m$ が1回少なく通過 $n = 2m$, 偶数の場合 : $I_m$ が1回少なく通く 区間を通過する回数を始点=終点の時と同様に考えると、それ以外の位置に始点、終点がある場合通過区間の通過した回数が少なくなることがわかる。(最適な始点・終点の位置より外側に配置すると通過できない回数が増え、上に挙げたいずれかの場合よりも距離が短くなる)\n結局、ジグザグに動く時が最適になり、\n$n = 2m-1$, 奇数の場合 : $2\\sum_{i=1}^{n-1} \\min (i, n-i) B_i - \\min (B_{m-1},B_m)$ $n = 2m$, 偶数の場合 : $2\\sum_{i=1}^{n-1} \\min (i, n-i) B_i - B_m$ が答えになることがわかる。\nhttps://atcoder.jp/contests/tenka1-2018/submissions/32590060\n",
    "permalink": "https://matsueushi.github.io/atcoder/tenka1-2018-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "Tenka1 Programmer Contest C - Align"
  },
  {
    "contents": "https://atcoder.jp/contests/nikkei2019-qual/tasks/nikkei2019_qual_c\n2人が最適な戦略を取るとき、残っている料理のうち $A_i+B_i$ が最大となるものを交互に選んでいくことになることを示す。\n3 20 10 20 20 20 30 この入力の場合を考える。\nAの立場で考えてみよう。 全部相手に料理を食べられてしまった時の自分から見た幸福度の差は、$-B_1-B_2-B_3$ である。料理 $i$ を食べると、この値が $A_i+B_i$ 改善することがわかる。そのため、Aの立場で考えると $A_i+B_i$ が大きいものを優先して食べたいことがわかる。\n次にBの立場で考えてみると、同じように $A_i+B_i$ が大きいものを優先するのが最適解であることが同様の議論でわかる。 A も B も料理 $i$ を食べるとそれぞれの立場で見た幸福度の差が $A_i+B_i$ 改善するため、$A_i+B_i$ と書かれた $N$ 個の料理を合計の数値が最大となるよう二人で交互に取り合っているのと同値な状況とみなせる。\n$A_i+B_i$ を降順にソートし、奇数番目を高橋くん、偶数番目を青木さんが選んだとして幸福度の差を計算すればOK。\nhttps://atcoder.jp/contests/nikkei2019-qual/submissions/32474436\n",
    "permalink": "https://matsueushi.github.io/atcoder/nikkei2019-qual-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "全国統一プログラミング王決定戦予選 C - Different Strokes"
  },
  {
    "contents": "https://atcoder.jp/contests/abc121/tasks/abc121_d\nビットごとの排他的論理和は二回繰り返すと元に戻り、可換で結合法則を満たすことから、\n$f(A,B)=A \\veebar A+1 \\veebar \\cdots \\veebar B = (0 \\veebar 2 \\veebar \\cdots \\veebar A-1) \\veebar (0 \\veebar 2 \\veebar \\cdots \\veebar B) = f(1,A-1) \\veebar f(1,B)$\nだから、$A=0$ の場合に帰着される。\nそれぞれの桁毎に、$0~B$ に出てくる $1$ の数が偶数個か奇数個か数えれば、$f(1,B)$ の各ビットがわかる。 $A=0$ の $1,2,3,\u0026hellip;$ のビット表示を確認すると、\n10進数 2進数 0 00000000 1 00000001 2 00000010 3 00000011 4 00000100 $1$ の位は $0 \\rightarrow 1 \\rightarrow 0 \\rightarrow 1 \\rightarrow \\cdots$ と1つごとに切り替わり、 $2$ の位は $0 \\rightarrow 0 \\rightarrow 1 \\rightarrow 1 \\rightarrow \\cdots$ と2つ毎に切り替わり、と規則的になっている。\n$2^i$ 桁目のビットを考えよう。$i=0$ の時は $B \\equiv 1 \\mod 4$ なら $1$, それ以外なら $0$ が立っている。\n$i \\ge 1$ であれば、$2^{i+1}$ 毎に $1$ が $2^i$ 個(偶数個)出てくるから、$1$ の出現数の偶奇は $(B+1) \\mod 2^{i+1}$ で考えれば良い。 $2^{i+1}$ 個ごとの $0/1$ の出現順は、最初に $0$ が $2^i$ 個続き、そのあと $1$ が $2^i$ 個続くから、 $1$ の数は、$\\max(0, ((B+1) \\mod 2^{i+1}) - 2^i)$。 この数が偶数なら $0$, 奇数なら $1$ のビットが立っている。\n(実装は結構手間取りました) https://atcoder.jp/contests/abc121/submissions/32474342\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc121-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 121 D - XOR World"
  },
  {
    "contents": "https://atcoder.jp/contests/abc147/tasks/abc147_d\nもちろん素朴に計算していては間に合わないが、ビット毎に考えれば良い。\n$z_i = 1 \\ll i$ とおくと、任意の $x$ に対して $x = \\sum_i x \\\u0026amp; z_i$ であり、 $(x \\oplus y) \\\u0026amp; z_i = (x \\\u0026amp; z_i )\\oplus (y \\\u0026amp; z_i)$ である。\n$\\sum_{i=1}^{N-1} \\sum_{j=i+1}^N (A_i \\oplus A_j) = \\sum_k \\sum_{i=1}^{N-1} \\sum_{j=i+1}^N ((A_i \\\u0026amp; z_k) \\oplus (A_j \\\u0026amp; z_k))$ であり、右のように変形すると、$A_i \\\u0026amp; z_k = 0$ または $z_k$ であるので計算が簡単にできる。\n$B_k = \\#\\{ i \\mid A_i \\\u0026amp; z_k = 0 \\}, C_k = \\#\\{ i \\mid A_i \\\u0026amp; z_k = z_k \\}$ とおくと、 $(A_i \\\u0026amp; z_k) \\oplus (A_j \\\u0026amp; z_k)$ は\n$0 \\oplus 0 = 0$ $0 \\oplus z_k = z_k$ $z_k \\oplus 0 = z_k$ $z_k \\oplus z_k = 0$ の4通りなので、 $\\sum_{i=1}^{N-1} \\sum_{j=i+1}^N ((A_i \\\u0026amp; z_k) \\oplus (A_j \\\u0026amp; z_k)) = B_k * C_k * z_k$ である。 あとはこれを $k$ について足し合わせる。\nhttps://atcoder.jp/contests/abc147/submissions/32456970\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc147-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 147 D - Xor Sum 4"
  },
  {
    "contents": "https://atcoder.jp/contests/agc023/tasks/agc023_a\n$C_j = \\sum_{k=1}^j A_k$ とおくと、 $\\sum_{k=i}^j A_k = 0 \\Leftrightarrow C_j = C_{k-1}$ であるから、 累積和を求めて $C_0=0, C_j = \\sum_{k=1}^j A_k$ とおき、 $I_x = \\{ i \\mid C_i = x\\}$ を計算して、$\\sum_x |I_x| (|I_x|-1)/2$ を求めれば良い。\nhttps://atcoder.jp/contests/agc023/submissions/32455933\n",
    "permalink": "https://matsueushi.github.io/atcoder/agc023-a/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder AGC 023 A - Zero-Sum Ranges"
  },
  {
    "contents": "https://atcoder.jp/contests/abc255/tasks/abc255_c\n$\\min_{i=0,\\ldots,n-1}|A+Di-X|$ を求めれば良い。$y=A+Dx$ と $y=X$ の交点を求め、 $x \u0026lt; 0, 1 \\le x \\le n-1 ,x \u0026gt; n-1$ の場合に応じて計算すれば良い。\n$|A+Di-X|$ が最も小さくなるのは、$x$ に最も近い $0\\le i \\le n-1$ を選んだ時である。\nhttps://atcoder.jp/contests/abc255/submissions/32387318\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc255-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 255 C - ±1 Operation 1 "
  },
  {
    "contents": "https://atcoder.jp/contests/abc255/tasks/abc255_d\n$i$ を一つ固定した時、操作の最低回数は $\\sum_{j=1}^N |A_j-X_i|$ である。\n$A_k$ の順番は関係ないので、 $A_k$ は昇順にソートしているとして良い。$A_k$ をソートするのは最初に一回だけやれば良い。\n累積和 $C_k = \\sum_{j=1}^k A_j$ を使って $S = \\sum_{j=1}^N |A_j-X|$ を次のように求める。 $l = \\max \\{ j \\mid A_j \\le X\\}$ とすると $S = (lX - C_l) + ((C_N-C_l) - (N-l)X)$ となる。\n$A = [1,2,4,5], X=3$ の時、求めたいのは下の赤と青の面積で、\n$l = 2$ で赤色の部分が $lX - C_l$, 青色の部分が $(C_N-C_l) - (N-l)X$ に対応。\n各クエリに対して2分探索するところで $O(\\log N)$ 時間かかるので、$O(Q\\log N)$ で全てのクエリを処理できる。\nhttps://atcoder.jp/contests/abc255/submissions/32393722\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc255-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 255 D - ±1 Operation 2"
  },
  {
    "contents": "https://atcoder.jp/contests/abc255/tasks/abc255_e\n$A_1 = \\alpha$ とおくと、\n$A_2 = S_1 - A_1 = S_1 - \\alpha$ $A_3 = S_2 - A_2 = S_2 - S_1 + \\alpha$ \u0026hellip; となることがわかる。 $T_1 = 0, T_k = \\sum_{i=1}^{k-1} (-1)^{i+k+1}S_k$ とおくと、どんな $A$ に対しても、 ある $\\alpha$ が存在して $A_k = T_k + (-1)^{k+1} \\alpha$ が全ての $k$ に対して成り立つことがわかる。\n$F(i,\\alpha) = |\\{ k \\mid T_k + (-1)^{k+1} \\alpha = X_i \\} |$ とする。 これは、 $i, \\alpha$ に対して、$X_i = T_k + (-1)^{k+1} \\alpha$ となる $k$ を数えていることになる。$T, X$ の条件から $F(i,\\alpha) \\neq 0$ となる $\\alpha$ は絞り込むことができる。\nあとは、$i$ を動かして $\\sum_i F(i,\\alpha)$ の最大値を取れば良い。\nhttps://atcoder.jp/contests/abc255/submissions/32403143\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc255-e/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 255 E - Lucky Numbers"
  },
  {
    "contents": "https://atcoder.jp/contests/diverta2019/tasks/diverta2019_d\n$t = \\lfloor n/m\\rfloor = n \\mod m$ とおくと $0 \\le t \u0026lt; m$であり、$n=\\alpha m + t$ とおける。 $t$ の条件から $\\alpha = \\lfloor n/m\\rfloor = t$ だから結局 $n = t(m+1)$ とかける。\n$n = t(m+1) \\ge t^2$ より、$t \\le \\sqrt{n}$ を探索すれば良い。\nhttps://atcoder.jp/contests/diverta2019/submissions/32371542\n",
    "permalink": "https://matsueushi.github.io/atcoder/diverta2019-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder diverta 2019 Programming Contest D - DivRem Number"
  },
  {
    "contents": "https://atcoder.jp/contests/apc001/tasks/apc001_b\n$c_i = a_i - b_i$ とする。\n3 1 2 3 5 2 2 であれば $c = [-4,0,1]$ となる。 目的は、全ての $i$ に対して $c_i = 0$ とすること。\n$a_i$ に $2$ を足し、$b_i$ に $1$ を足す操作は、$i=j$ であれば $c_i$ に $1$ を足し(操作1とする）、 $i \\neq j$ ならば $c_i$ に $2$ を足し、$c_j$ から $1$ を引く操作(操作2とする)に対応する。 数字を減らすのは操作2でしか行えないことに注意。\n$c_i$ を非負の部分と負の部分に分け、 $I_+ = \\{ i \\mid c_i ≥ 0\\}, I_- = \\{ i \\mid c_i \u0026lt; 0 \\}$, $S = \\sum_{i \\in I+} c_i, V = \\sum_{i \\in I-}\\lfloor |c_i|/2 \\rfloor$ とおく。\n$S$ は、操作2を行わなくてはいけない最低回数、$V$ は $0$ を超えないようにマイナスになっている $c_i$ に $2$ を足すことのできる最大回数とも考えられる。\n操作1で任意の場所の数字を任意の数だけ増やせるので、$I_+ = \\empty$ つまり $S=0$ の状態にできれば良い。\n操作1 または 操作2 で $S$ を減らすことを考える。\n操作2で、$c_i \\le -2, c_j \u0026gt; 0$ となっている $i,j$ を選んで $c_i$ に $+2$, $c_j$ に $-1$ すること(操作☆と呼ぶ)でしか $S$ は減らせないことがわかる。 この時、$S、V$ がともに1減少する。\nそれ以外のパターンを考えると、\n操作1 -\u0026gt; $c_i \\ge 0$ なら $S$ が1増加、それ以外なら $V$ が0または1減少 操作2 -\u0026gt; $+2$ する操作により、 $S$ が 1以上増加するか $V$ が1減少する。$c_j \\le 0$ の時、$-1$ する操作では $V$ を高々1しか増やせない。 上により、どう頑張っても $V$ を増やすことはできないことがわかる。\n$S ≤ V$ ならば、$c_i \\le -2, c_j \u0026gt; 0$ となっている $i,j$ を選んで操作☆を続けることで $S=0$ とできる。 それ以外ならどう頑張っても $S$ 回上のような操作ができないので、目的が達成できない。\nhttps://atcoder.jp/contests/apc001/submissions/32369370\n",
    "permalink": "https://matsueushi.github.io/atcoder/apc001-b/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder APC 001 B - Two Arrays"
  },
  {
    "contents": "https://atcoder.jp/contests/abc198/tasks/abc198_d\n覆面算を解く問題。Send More Moneyって何？と思ったのですが SEND + MORE = MONEY という覆面算が有名らしいです。\n戦略としては、\nS_1, S_2, S_3 に出てくる文字の集合を作る。10種類以上出てきたら UNSOLVABLE 先ほど文字の集合に番号をつける。順番はどうでもいい。['v', 'f', 'c'] だったら v = 1番目、f = 2番目、のような対応づけをする。 これにより、S_1, S_2, S_3 が [3,5,1], [1,4,2], [2,2,2] のような 1~10の整数の数列に変換できる。 あとは 1~10番目の文字に対して 0~9 の数字をどのように当てはめるか全探索。 全探索しても10!=3628800通りなので間に合う。 Julia だと C++ における std::next_permutaiton が標準ライブラリに無い(存在を知らない) ので自分で作る必要がありますね。 https://atcoder.jp/contests/abc198/submissions/32308692\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc198-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 198 D - Send More Money"
  },
  {
    "contents": "https://atcoder.jp/contests/abc129/tasks/abc129_d\n水平方向、垂直方向にそれぞれ見て行った時に、\u0026rsquo;#\u0026rsquo;, \u0026lsquo;.\u0026lsquo;の連続数を並べた数列を作る。\n#..#.. .....# ....#. #.#... であったら\n[ [1, 2, 1, 2], [5, 1], [4, 1, 1], [1, 1, 1, 3], ] さらにこれの累積和をとると、\n[ [1, 3, 4, 6], [5, 6], [4, 5, 6], [1, 2, 3, 6], ] となり、(3,4)に置いた光が横方向にどれくらい届くか調べたかったら、\n(3,4) が \u0026lsquo;.\u0026rsquo; であるかを調べる 3行目の累積和 [4, 5, 6]を見て、4番目を超えている場所のインデックスを探す(この場合は1番目) 累積和を取る前の [4, 1, 1] の対応する場所を見れば、横方向に連続している白マスがカウントできる。 垂直方向も同様にカウントできる。(横方向の連続数)+(縦方向の連続数)-1 を白マスで計算してmaxを取れば良い。\nhttps://atcoder.jp/contests/abc129/submissions/32307404\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc129-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 129 D - Lamp"
  },
  {
    "contents": "https://atcoder.jp/contests/abc153/tasks/abc153_e\n\\(dp[i][k]\\) = \\(i\\) 番目までの魔法からダメージが \\(k\\) 以上になるように選んだ時に消費するMPの最小値\nとすると、個数制限なしナップザック問題（の類似）に帰着される。 (参考:蟻本の2章 p.p.58 漸化式を工夫する)\n\\(dp[i+1][k] = \\min(dp[i][k], dp[i+1][k-a[i]]+b[i])\\)\nである。ここで、\\(dp[-1][k] = 0\\) と \\(dp[i][k] = 0 \\ (k \u0026lt; 0)\\) とおいた。\n答えは \\(dp[n][h]\\) であり、\\(O(nh)\\) で求められる。\nhttps://atcoder.jp/contests/abc153/submissions/32290815\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc153-e/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 153 E - Crested Ibis vs Monster"
  },
  {
    "contents": "https://atcoder.jp/contests/abc161/tasks/abc161_d\n桁数の少ないルンルン数から順に作っていけば良い。\n1桁のルンルン数 = 1,2,\u0026hellip;,9\n2桁のルンルン数 = ([1 桁のルンルン数][最後の数字に-1,0,+1のどれかを足したもの]の順に繋げた数)\n3桁のルンルン数 = ([2 桁のルンルン数][最後の数字に-1,0,+1のどれかを足したもの]の順に繋げた数)\nこのように考えていくと、自然にルンルン数が昇順に列挙できる。\nhttps://atcoder.jp/contests/abc161/submissions/32271070\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc161-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 161 D - Lunlun Number"
  },
  {
    "contents": "https://atcoder.jp/contests/code-festival-2017-qualc/tasks/code_festival_2017_qualc_c\n目標が達成可能かどうかは、s から \u0026lsquo;x\u0026rsquo; を取り除いてできる文字列が回文であるかどうかで判定できる。 以後、目標が達成可能な場合を考える。\ns の \u0026lsquo;x\u0026rsquo; でない文字列のうち左から i 番目の文字を \\(cs[i]\\) とする。(i = 1,\u0026hellip;,m とする)\n\\(ds[i]\\) を \\(cs[i]\\) と \\(cs[i+1]\\) の間にある \u0026lsquo;x\u0026rsquo; の個数とする。 \\(ds[0]\\) を \\(cs[1]\\) の前にある \u0026lsquo;x\u0026rsquo; の数、\\(ds[m]\\) を \\(cs[m]\\) の後にある \u0026lsquo;x\u0026rsquo; の数と拡張しておく。\ns = \u0026ldquo;xabxa\u0026rdquo; の時は、cs = [\u0026lsquo;a\u0026rsquo;, \u0026lsquo;b\u0026rsquo;, \u0026lsquo;a\u0026rsquo;], ds = [1,0,1,0]である。\n\u0026lsquo;x\u0026rsquo; を挿入する操作は、ds の一つの数字を +1 することに相当する。ds が左右対称となった時文字列が回文になるから、 答えは l = length(ds) として \\(\\sum_{i=1}^{\\lfloor l/2 \\rfloor}|ds[i] - ds[l-i+1]| \\) で求められる。\nhttps://atcoder.jp/contests/code-festival-2017-qualc/submissions/32267860\n",
    "permalink": "https://matsueushi.github.io/atcoder/code-festival-2017-qualc-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder CODE FESTIVAL 2017 qualC C - Inserting 'x'"
  },
  {
    "contents": "https://atcoder.jp/contests/agc034/tasks/agc034_a\nすぬけくんしかいない場合を考えると、a地点からc地点に到達できる条件は、\\([a,c]\\)の間に連続する黒マスがないこと、である。\n2人いる場合を考えると、\\(c\u0026lt;d \\) の場合は、すぬけくんとふぬけくんの順序を入れ替える必要がないから、 ふぬけくんに先にゴースさせて、すぬけくんがその後ゴールすれば良い。 よって、一人だけの場合の条件をすぬけくん、ふぬけくんでそれぞれ考える。\n\\(c \u0026gt; d \\) の場合、順序を入れ替える必要がある。順序が入れ替わるのは、\n(す)(ふ)(空)\nという状態になっている時だから、ふぬけくんの現在いる位置、またはそれより右側で、前後が白マスになっているところを探す。 つまり、三連続で白マスになっている場所を探す。\nこの時、候補の中で1番左の位置にある三連続白マスを考えれば良い。(状態が実現できなければ、それより右の三連続白マスで実現することは不可能のため)\n後は、\n(す)(ふ)(空)\nの状態に到達できるか確認して、到達できれば、順番を入れ替える必要がない\\(c \u0026lt; d \\)の場合に帰着できる。 この時、当初の目的地を飛び越えていないかもチェックする。 到達できなければ、実現不可能。\nhttps://atcoder.jp/contests/agc034/submissions/32194980\n",
    "permalink": "https://matsueushi.github.io/atcoder/agc034-a/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 034 A - Kenken Race"
  },
  {
    "contents": "https://atcoder.jp/contests/agc011/tasks/agc011_b\n\\(A_i\\) を降順にソートしても一般性を失わない。\n大きいものの方が吸収しづらいから、1番最後に\\(1\\), その前に \\(2, \\ldots, \\)を吸収したとして良い。 \\(A_1, \\ldots, A_i\\) を吸収するのに必要な最小のとなる生き物の大きさの整数値を \\(B_i\\) とする。\n\\(B_1 = \\lceil A_1 / 2\\rceil \\) である。 \\(A_i\\) が吸収でき、さらにその後 \\(i-1, \\ldots, 1\\) が吸収できる条件を考えると、 \\(B_i = \\max(\\lceil A_i / 2 \\rceil, B_{i-1}-A_i)\\) である。\n各 \\(i \\) に対し、\\(i\\) は \\(i+1\\) 以降を吸収できるから、\\( \\sum_{k=i}^n A_k \\ge B_{i-1} \\) を満たすかどうか判定すれば良い。\nhttps://atcoder.jp/contests/agc011/submissions/32165993\n",
    "permalink": "https://matsueushi.github.io/atcoder/agc011-b/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder AGC 011 B - Colorful Creatures"
  },
  {
    "contents": "https://atcoder.jp/contests/abc134/tasks/abc134_d\n条件を満たすボールの入れ方は、一意に定まる。\nn = 4 の場合、4 までに 3, 4 の倍数は一つしかないので、 | | |X|X| a_3, a_4 の情報から i = 3,4 のボールの個数が確定する。\n次に、a_2 の情報から i = 2 のボールの個数が確定する。最後に i = 1 が確定する。\nこのように考えると、第 k ステップで i ≥ floor(n/2^k) の場所のボールの個数が確定することがわかる。\nhttps://atcoder.jp/contests/abc134/submissions/32148310\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc134-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 134 D - Preparing Boxes"
  },
  {
    "contents": "https://atcoder.jp/contests/abc064/tasks/abc064_d\n先頭に\u0026quot;(\u0026quot;, 末尾に\u0026quot;)\u0026ldquo;を繋げて括弧列を作るのが辞書式最小となる。 (そのような作り方をしないと、より左の位置に\u0026rdquo;)\u0026ldquo;が出現する)\n\u0026ldquo;(\u0026rdquo; -\u0026gt; +1, \u0026ldquo;)\u0026rdquo; -\u0026gt; -1 と文字列を置き換えて累積和を取ったものを c[i] とすると、 c[i] ≥ 0 (1≤i≤n-1), c[n] = 0 が括弧列を成立させる条件である。\nhttps://atcoder.jp/contests/abc064/submissions/32131694\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc064-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 064 D - Insertion"
  },
  {
    "contents": "山 i に降った雨の量を \\(2 * x_i\\) とすると、\\(\\sum A_i = 2 \\sum x_i\\) だから、\\(x_i\\) の合計がわかる。\nNが奇数であることから \\(A_i = x_i + x_{i+1}\\) をうまく足して \\(\\sum_{i \\neq j} x_i\\) が作れ、合計から引くことで \\(x_j\\) が求められる。\nhttps://atcoder.jp/contests/abc133/submissions/32131263\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc133-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 133 D - Rain Flows into Dams"
  },
  {
    "contents": "https://atcoder.jp/contests/abc094/tasks/arc095_a\nまず、具体例で考えてみる。aがソートされている場合を考えよう。\n1,2,3,4,5\nで左からi番目の数を取り除いた中央値を考えると\n3,3,2,2,2\nとなる。\n1,2,2,3\nであれば\n2,2,2\nである。\nよって、pos = floor((l+1)/2), 取り除かれた値をxとすると、\nl が偶数の時 x ≤ a[pos] -\u0026gt; 取り除いた後は a[pos+1] が中央値 x \u0026gt; a[pos] -\u0026gt; a[pos] l が奇数の時 x \u0026lt; a[pos] -\u0026gt; a[pos] x ≥ a[pos] -\u0026gt; a[pos-1] であることがわかる。\nhttps://atcoder.jp/contests/abc094/submissions/32115333\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc094-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 094 C - Many Medians"
  },
  {
    "contents": "https://atcoder.jp/contests/abc183/tasks/abc183_e\nまず1次元で右にしか進めない場合を考える。 dp[i]=左からi番目に移動する方法 とする。\ndp[i]=2^(n-1)である。1,…,i-1それぞれで立ち止まるか通過するか選べると考えてもいいが、dp[1]=1であり、i番目にいる時、移動をそこでやめてそこで立ち止まってi+1に進むか、そのまま移動してi+1に行くかの2通りがあるので、dp[i+1]=2*dp[i]であると考えられる。\n2次元にすると、向きが変わる場合があるので\n各マスでの状態を\n右向きで進んでいる 下向きに進んでいる 斜め右下向きに進んでいる 立ち止まっている という状態も含めて考える。 dp[1,1,1]=1,dp[1,1,k]=0 (k=1,2,3)で、\ndp[i,j,1]=dp[i-1,j,1]+dp[i-1,j,4]\ndp[i,j,2]=dp[i,-1j,2]+dp[i,j-1,4]\ndp[i,j,3]=dp[i-1,j-1,3]+dp[i-1,j-1,4]\ndp[i,j,4]=dp[i-1,j,1]+dp[i,j-1,2]+dp[i-1,j-1,3] + dp[i-1,j,4]+dp[i,j-1,4]+dp[i-1,j-1,4]\n最後に(h,w)で着地する必要があるので、dp[h,w,4]が答えである。\nhttps://atcoder.jp/contests/abc183/submissions/32114608\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc183-e/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 183 E - Queen on Grid"
  },
  {
    "contents": "https://atcoder.jp/contests/abc130/tasks/abc130_c\n長方形の対角線の交点をCとする。C=(x,y)ならどのように切っても長方形の面積を二等分できる。 そうでない場合はCと(x,y)を結ぶと二等分できる。 よって最初の答えは(x,y)の位置に関係なく長方形の面積の半分。最適な切り方が複数あるかは、C=(x,y)であるかどうか。\nhttps://atcoder.jp/contests/abc130/submissions/32113015\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc130-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 130 C - Rectangle Cutting"
  },
  {
    "contents": "https://atcoder.jp/contests/ddcc2020-qual/tasks/ddcc2020_qual_c\n各行に一つ以上イチゴが乗っている場合、行ごとに分割すれば目的が達成できる。 ある行に注目したときに、\n|🍓|　|　|🍓|　|　|\nであれば\n|1|2|2|2|2|2|\nのような帯に切り分ける。これを繰り返していくとイチゴが乗っていない行以外は、 行だけで注目するとイチゴが一つだけ乗った長方形のケーキに分かれる。 後はイチゴが1つも乗っていない行の切り方をイチゴが乗っている上の行か下の行に合わせて長方形になるようにする。\nhttps://atcoder.jp/contests/ddcc2020-qual/submissions/31996005\n",
    "permalink": "https://matsueushi.github.io/atcoder/ddcc2020-qual-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder DISCO presents ディスカバリーチャンネル コードコンテスト2020 予選 C - Strawberry Cakes"
  },
  {
    "contents": "https://atcoder.jp/contests/abc137/tasks/abc137_d\n後ろから貪欲法で解ける気がする。 M-1日目を考えると、 残っている仕事のうち、 Ai=1を満たす仕事で報酬Biが最大となるものを請けるとして良いことがわかる。\n必要であれば受けた仕事の順番を入れ替えて、 M-1日目にする仕事は、全てのN件の日雇いバイトの中でAi=1を満たし報酬Biが最大となる仕事である、とできる。\n次にM-2日目を考えると、できる仕事はAi=1,2である仕事。Ai=1,Biが最大となる仕事は最終日にやることが決まっているので、 M-1日目と同様の考察により、それを除いた仕事のうち報酬が最大となるものを働けば良い。\n以下繰り返す。\nhttps://atcoder.jp/contests/abc137/submissions/31967629\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc137-d/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 137 D - Summer Vacation"
  },
  {
    "contents": "https://atcoder.jp/contests/abc117/tasks/abc117_c\n数直線上に地点X_iを配置して、コマが移動した位置を塗りつぶすことを考える。\n移動回数を最小化したいので、塗りつぶす面積を最小化することを考える。\nX_1, \u0026hellip;, X_M によって M-1 個の区間が作られる。\nN=1だったら全ての区間をぬりぶさないとM個の地点全てに到達できない。 N=2だったら一つの区間は塗りつぶさずにスキップできる。 このように考えると、最大N-1個の区間は塗りつぶさずにスキップ可能であることがわかる。 よって、塗りつぶさないといけない区間はmax(0, M-N)個。\n区間の長さをソートし、短い順にmax(0, M-N)個の区間の長さの合計を求めると答えになる。\nhttps://atcoder.jp/contests/abc117/submissions/31965997\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc117-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 117 C - Streamline"
  },
  {
    "contents": "https://atcoder.jp/contests/yahoo-procon2019-qual/tasks/yahoo_procon2019_qual_c\n円は残しておいても最終的なビスケットの枚数の最大値には寄与しない。また、使い道はビスケットB枚に交換することのみ。\nよって、Kアクション与えられた際、\n1アクション使って、ビスケットを1枚増やす 2アクション使って、ビスケットA枚をビスケットB枚に交換する この二つの選択の組み合わせでビスケットの枚数を最大化する、という問題に帰着される。\n一つ目の行動を二回繰り返すとビスケットが2枚増える、ということは B\u0026gt;A+2でないと二つ目の行動をする意味がない。\nB\u0026gt;A+2であったら二つ目の行動の方が効率が良いので、一つ目の行動でビスケットをA枚まで増やした後二つ目の行動を繰り返し、アクションが最後に1残ったら最後にもう一枚増やす B≤A+2だったら一つ目の行動を連打 で良い。後はkとaの大小関係に注意すればOK\nhttps://atcoder.jp/contests/yahoo-procon2019-qual/submissions/31952356\n",
    "permalink": "https://matsueushi.github.io/atcoder/yahoo-procon2019-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder みんなのプロコン2019 C - When I hit my pocket..."
  },
  {
    "contents": "https://atcoder.jp/contests/abc154/tasks/abc154_e\n\\(N\\) の上 \\(i\\) 桁をつなげた数を \\(N(i)\\) とする。 \\(N\\) の上から \\(i\\) 桁目を \\(N_i\\) とする。\\(N\\) の桁数を \\(l\\) とする。\n\\(dp[i,k,0] = \\{ n \\in \\mathbb{Z} \\mid n \u0026lt; N(i) ,n の 0 でない数字の数が k \\}\\) \\(dp[i,k,1] = \\{ n \\in \\mathbb{Z} \\mid n = N(i) ,n の 0 でない数字の数が k \\}\\) とすると、求めたいのは \\(dp[l,K,0] + dp[l,K,1]\\) である。\n\\(dp[i,0,0]=1, \\) (0 に対応)\n\\(dp[1,1,0] = N_1-1,\\) (1,\u0026hellip;,N1- 1に対応)\n\\(dp[1,k,0]= 0 (k \\ge 2),\\)\n\\(dp[1,k,1] = 1,\\)\n遷移を考えると\n\\(dp[i+1,k,0] = dp[i,k,0]+9\\cdot dp[i,k-1,0] (k \\ge 1, N_{i+1}=0),\\)\n\\(dp[i+1,k,0] = dp[i,k,0]+9\\cdot dp[i,k-1,0]+dp[i,k,1]+(N_{i+1}-1)dp[i,k-1,1] (k \\ge 1, N_{i+1}\\neq 0),\\)\n\\(dp[i+1,k,1] = dp[i,k,1] (N_{i+1} = 0),\\)\n\\(dp[i+1,k,1] = dp[i,k-1,1](N_{i+1} \\neq 0),\\)\nhttps://atcoder.jp/contests/abc154/submissions/31951620\n調べてみたらこういうものを桁DPというらしい。\n参考 桁DP(Digit DP) を考え方から問題例まで徹底解説！ ",
    "permalink": "https://matsueushi.github.io/atcoder/abc154-e/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 154 E - Almost Everywhere Zero"
  },
  {
    "contents": "https://atcoder.jp/contests/abc135/tasks/abc135_c\n勇者が倒せるモンスターの数を無駄にしたくないので、 他の勇者が倒せるモンスターよりも自分しか倒せないモンスターを優先して倒すようにする。\n1番目の街のモンスターは1番目の勇者しか倒せないので、1番目の勇者は優先的に1番目の街のモンスターを倒し、 余力があれば2番の街のモンスターを倒す。 2番目の勇者は残っている2番目の街ののモンスターから倒す…… と順々に考えれば良い\nhttps://atcoder.jp/contests/abc135/submissions/31950249\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc135-c/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 135 C - City Savers"
  },
  {
    "contents": "4月頭からAtCoder Beginner Contestに出ていたのですが、緑色になりました。 https://atcoder.jp/users/matsueushi\n蟻本を読みながら「競プロ典型90問」を9割ぐらい解答を見ながら解いて、その後はABCの過去問をA-D問題を中心に解いていました。 D問題で時間がかかってしまうことが多いので、AtCoder Problems の「Boot camp for Beginners」を解きまくろうと思います。\n",
    "permalink": "https://matsueushi.github.io/atcoder/green/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoderで緑色になった"
  },
  {
    "contents": "https://atcoder.jp/contests/abc250/tasks/abc250_e\nコンテスト中は解けそうで解けなかったが、シンプルな方法で解けることにあとから気づいて悔やまれた。\n\\(S_i= \\{a_1, \\ldots, a_i\\}, T_i=\\{b_i, \\ldots, b_i \\} \\)とおくと、\\( S_1 \\subseteq S_2 \\subseteq \\cdots \\subseteq S_n, T_1 \\subseteq T_2 \\subseteq \\cdots \\subseteq T_n\\)となる。\n\\(f_i= \\max \\{j \\mid T_j \\subseteq S_i \\}, g_i= \\max \\{j \\mid S_j \\subseteq T_i \\} \\) を計算する。例えば\\(f_i\\)まで計算した後に\\(f_{i+1}\\)を計算するときは、\\(b_{f_i+1}, b_{f_i+2}, \\ldots , b_j\\) が \\(S_{i+1}\\) に含まれているかをチェックしていき含まれなくなったら\\(f_{i+1}=j-1\\) とすれば良い。\n後は\\(S_i = T_j \\Leftrightarrow S_i \\subseteq T_j, T_j \\subseteq S_i \\Leftrightarrow i \\le g_j, j \\le f_i\\)でクエリを判定すれば良い。\n(Julia, 564 ms) https://atcoder.jp/contests/abc250/submissions/31571164\n",
    "permalink": "https://matsueushi.github.io/atcoder/abc250-e/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoder ABC 250 E - Prefix Equality"
  },
  {
    "contents": "Dockerでコンテナ作成\ndocker run -p 8888:8888 --name [名前] -it -v $(pwd):/home/jovyan/work [イメージ名] Rust の競技プログラミング環境作成\nコンテナは rust イメージから作る\ndocker run -p 8888:8888 --name rust -it -v $(pwd):/home/jovyan/work rust vscode 内\napt-get update apt-get install git rustup install 1.42.0 rustup component add --toolchain 1.42.0 rls rust-analysis rust-src cargo install cargo-generate cargo install cargo-compete vscode内でrust-analyzer をインストール\n",
    "permalink": "https://matsueushi.github.io/other/matsueushi-memo/",
    "tags": null,
    "title": "自分用メモ"
  },
  {
    "contents": "DiscogsというレコードやCDなど音源のデータベースかつマーケットプレイスのサイトで以前から気になっていることです。\n音楽好きなら結構知っているサイトで、自分も所持している音源について調べるときなどに使うのですが、 そこのマーケットプレイスでは、普段数千〜数万円の価格しかついていないのに、突然相場の10-100倍近く(数十万)で売買取引が成立していることがあるのです。\nそこまでレアなCDか？と思うようなものが過去に20万とか40万円で取引されていてかなり謎です(価格は右の方に表記あり)。 https://www.discogs.com/ja/release/7218654-Heather-Nova-South\nhttps://www.discogs.com/ja/release/15283232-Valerie-Carter-Midnight-Over-Honey-River\nマネーロンダリングという考察もあるようですが、真偽は不明です。誰か知っていたら教えてください。\nMoney Laundering on Discogs\nMoney Laundering?\n後で読む用のメモ\nEverything We Know About Scaramanga Silk and Choose Your Weapon https://blog.discogs.com/en/scaramanga-silk-choose-your-weapon-most-expensive-record/\nRecord by near-unknown producer sells for $41,000 to become most expensive on Discogs https://www.theguardian.com/music/2021/feb/03/record-by-near-unknown-producer-sells-for-41000-most-expensive-discogs-scaramanga-silk\n",
    "permalink": "https://matsueushi.github.io/posts/discogs-money-laundering/",
    "tags": [
      "Music",
      "Discogs",
      "CD",
      "Record"
    ],
    "title": "Discogsの高額CD, レコードの謎"
  },
  {
    "contents": "去年は色々と忙しくじっくり勉強する時間がなかったので、リハビリを兼ねて競技プログラミングの問題をJuliaで挑戦してみることにします。\nひとまず、AtCoderの競プロ典型 90 問を解いて行く予定です。 ジャッジ時にJITコンパイルが走って200~300ms程度消費してしまいますが、幸い今のところTLEでどう頑張っても通せない問題はなかったです。\n下に解答を記録していこうと思います。\nhttps://github.com/matsueushi/CompetitiveProgramming\nさてはて、いつまで続くやら。\n2022/6/7 追記 (随時更新)\nちょっとしたテクニック\n入力 parseint() = parse(Int, readline()) parseints() = parse.(Int, split(readline())) function parsepoints(n::Int) xs, ys = zeros(Int, n), zeros(Int, n) for i in 1:n xs[i], ys[i] = parseints() end xs, ys end function parsestrings(n) ss = Vector{String}(undef, n) for i in 1:n ss[i] = readline() end ss end このようなテンプレートを作っておくと便利\nパッケージのバージョンを確認する ローカルの実行環境をジャッジと合わせておかないと、予期しないエラーが起こる可能性あり。 コードテストで using Pkg println(Pkg.status()) を実行すると使われているパッケージのバージョンが分かります。\nStatus `~/.julia/environments/v1.4/Project.toml` [864edb3b] DataStructures v0.17.11 [27ebfcd6] Primes v0.4.0 nothing StringからVector{Char}への変換 cs = Vector{Char}(s) 負の数の剰余 julia\u0026gt; mod(-1, 4) 3 ",
    "permalink": "https://matsueushi.github.io/atcoder/julia-atcoder/",
    "tags": [
      "Julia",
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "JuliaでAtCoderに挑戦"
  },
  {
    "contents": "2021年は記事を更新できませんでしたが無事に生きてます。来年からはぼちぼち記事の更新を再開したいと思います。\n",
    "permalink": "https://matsueushi.github.io/posts/2021/",
    "tags": [
      "Diary"
    ],
    "title": "2021年"
  },
  {
    "contents": "最近更新が止まっておりました。あまりよく知らないアーティストが多い……\nAKC Misi - Gyémánt ft. Kisé [Official Lyric Video] (prod. YBR) ハンガリーのラッパー？詳細不明。\nFacebook, SoundCloud, Twitter, Spotify\nYANUSHI \u0026ldquo;Knife in The Hot Water\u0026rdquo; Official Music Video Jacob Tanaka \u0026ldquo;Boat\u0026quot;Official Music Video 4人組ロックバンド、家主（田中ヤコブはフロントマン）。優しく寄り添ってくれるようなグッドメロディだけれども、 同時に不思議な熱さを感じるというか。好きすぎて手に入るCD,LPは可能な限り集めたものの、\u0026ldquo;THE FOG\u0026quot;は売り切れていて見つからず。\n2月の田中ヤコブ＋家主のライブは行けなかったが、配信されていたのでそちらを見た。いずれちゃんと情報をまとめたい。\nTwitter(田中ヤコブ a.k.a 家主), Tumblr, Spotify(家主), Spotify(田中ヤコブ)\nmeat computer / freedom from the world こういう類の楽曲がCloud Rapなのだろうか？\nジャンルは置いておいて、キラキラしたビートと囁く裏声のようなボーカルにより増幅される陶酔感が非常に新鮮だった。 \u0026ldquo;I like this new generation of music\u0026rdquo;.\nGeniusによるとCanadian vocalist, songwriterとのことだが……\nSoundCloud, Instagram, Twitter\n浪味仙貝 Lonely Cookies - 愛的招待 Love Treatment [OFFICIAL MUSIC VIDEO] 中国のインディーポップバンド、浪味仙貝。なんか甘酸っぱい感じですね。NYAIっぽいというか。\nBandcamp 东湖游泳 Eastlake Swimming\nIn October of 2019 I Called a Suicide Hotline For The First Time in My Life AMV Bandcamp Twitter\nUSシカゴのEMO(ソロプロジェクト？)your arms are my cocoonのデビューEP。\nLoli in early 20s / 水中プードル\nおそらくロシアのLolicore?Breakcoreアーティスト。\nBandcamp, SoundCloud\nhàl / 人魚\n2001年リリースの「blue」はとても良質な曲揃いのJ-POP名盤だと思う。5曲目の「6階の少女」はZAZEN BOYS(の全身？)が演奏しているのだが、 正直なところ全体の流れから浮いている気がした。\n未来電波基地 / おもちを食べて\n鬱木ゆうとのソロプロジェクト、未来電波基地。「インターネットグランジバンド」とのこと。憂鬱な時に聴きたくなる。\nTwitter, Bandcamp, Tumblr, これが未来電波基地の歴史\nsunday \u0026amp; carlos / 魔法じかけの水曜日 sundayさんの1980年代アイドルソングのような温かみのある爽やかな歌声がかなり好きなのですが最近このコラボアレンジを発見しました。 もっといろいろ聴きたい。\n原曲:魔法じかけの日曜日(original-6), Twitter(sundaytube02), YouTube(sundaytube02), Soundcloud(sundaytube02)\nVOID - YAMEII\nパステルカラーに彩られたサイバースペースに誘われる。Dekoの名前がよく出てくるが、中の人なのかな？\nocean world, Instagram, SoundCloud, Twitter(OceanWorld), Twitter(Yameiionline)\nSuper VHS”Matsuri no yoru”Official Music Video\n田中ヤコブや家主からレーベル繋がり(NEW FORK)で発見した。 Twitter\n",
    "permalink": "https://matsueushi.github.io/playlist/20210228/",
    "tags": [
      "Music"
    ],
    "title": "最近聞いた曲(2021/3/1)"
  },
  {
    "contents": "Twitterで友人に勧められて聞いた福岡のバンドSACOYANS(サコヤンズ)のファーストアルバム\u0026quot;Yomosue\u0026quot;がかなり気に入ったので紹介したいと思います。\nYomosue by SACOYANS ジャンルはドリームポップやシューゲイザーに該当すると思います。\n轟音ギターと甘いメロディの融合というシューゲイザーのスタイルはしっかり踏襲しつつ、 Twitterのプロフィールには「もうほとんどスマパンなんじゃないか？の疑い色濃いバンド。」とある通りオルタナっぽさも色濃く味わえ、 椎名林檎とか大森靖子のようなJPOPっぽい聴きやすさ、口ずさみやすさも魅力的です。\n最初Spotifyで聞いていたのですが、こりゃ手元に持っておかなければと思いフィジカル(CD)もすぐに買いました。 自分は気づかずAmazonで買ってしまいましたが、これから買う人は【特典】SACOYANS / Yomosueから買った方がステッカーがついてくるようです。 （売り切れていたらすみません）\nSACOYANS | Mudiaのアーティスト紹介に\n時は2019年10月、 音楽活動を辞めていたSACOYANが突如バンドをやりたくなって家の近所で見つけたメンバーにて結成。なんと全員SACOYANファンだった。各自持ち前の個性を武器に持ち「SACOYANのバンド」ではなく「SACOYANもいるバンド」に。福岡に一つの新しい大陸が出来上がった。めでたしめでたし\n(このアーティスト説明いいですね)と書いてあるのでまだ結成して1年ほどしか経っていないというのは驚きでしたが、 ボーカルのSACOYANのYouTubeのチャンネルに ベッドルームポップ的なテイストの元曲？がアップロードされており、バンドスタイルとして再解釈してできたのはこのYomosueなのではないかと思います。\n偉大なお告げ「great revelation」SACOYAN 音楽の天才 「a genius of music」 SACOYAN わたしの窓辺 「by my window」 SACOYAN だれでもしっかり見ているよ 「everybody gaze」 SACOYAN 「食卓の間」Dining room SACOYAN デモ JK(2011)　SACOYAN ニベアは2020年8月にリリースされたという記事があるので最近の曲ですが、 「だれでもしっかり見ているよ」や「JK」はアップロード日が2011年なので結構前から原曲は存在していたようです。\n相当昔から作ってきた曲の中から選りすぐって作られたのがこのYomosueだとすれば、 ファーストアルバムにしてベストアルバムのような至極の完成度である理由にも納得がいく気がします。\n完成度やまとまりの点ではアルバムバージョンの方が一歩先に進んでいると思いますがYouTubeにアップロードされている荒削りなゲネプロやデモバージョンも好きです。\nNYAI(こちらのバンドも好きです)と福岡つながりで対バンもしていた模様。 配信もしていたようですが完全に見逃しました……\nライブの詳細決まりました！\n8/8(土) TWO MUCH\n@福岡UTERO\nOP/18:30 ST/19:00\n観覧TICKET￥2000+1drink order\n配信TICKET￥1000 【CAST】\n19:00-19:50　SACOYANS\n20:10-21:00　NYAI\n会場は30人くらいで締め切るので観に来れる方はお早めにご予約お願いします🤲https://t.co/n2hbs2kfaF\n\u0026mdash; ニャイちゃんバンド(NYAI) (@nyaiband) July 29, 2020 本当に素晴らしいアルバムなので、もっと世間に知られて欲しいと思います。\n😭 https://t.co/6EwMw9TG4i\n\u0026mdash; SACOYAN (@SACOYAN_bot) September 24, 2020 以下はリンクです。\nなかなか情報が見つかりづらく、 ミュージックマガジン(2020/Oct)には小さくディスクレビューが載っていました（これも前と同じ友人に教えてもらった）が、 他にもないかなと思っていくつか書店でパラパラ音楽雑誌をめくってみたものの言及されているのは他には見つからず残念でした。\n公式 Twitter 各種サブスクリプションサービスへのリンク Bandcamp Instagram SACOYAN(vocals, guitar) Twitter Web YouTube Soundcloud 虫さされ肩こりにSACOYAN サイコちゃん伝説　SACOYAN編 迷われレコード 33 : SACOYAN 『虎モ猫になる』 TAKEYAN/Takeshi Yamamoto(guitar) Twitter Bandcamp HARAJIRI/原尻 成二(bass) Twitter Facebook MIWAKO/みわこ(drums) Twitter miu miu その他 Rate Your Music Discogs SACOYANS、「ニベア」リリース＆リリースパーティーも開催 (BARKS, 2020.8.26 22:00) SACOYANS | Mudia 5ch過去ログ 【サイコちゃん伝説】SACOYAN広場【2ちゃんねる編】 SACOYAN広場 part.2 SACOYAN広場 part.3 ",
    "permalink": "https://matsueushi.github.io/posts/sacoyans-yomosue/",
    "tags": [
      "Music",
      "Shoegaze",
      "Dreampop",
      "Jpop"
    ],
    "title": "SACOYANS - Yomosue (2020)"
  },
  {
    "contents": "WebAPIを叩くと、レスポンスがJSON形式の文字列で返ってくることがあります。 ほとんどの場合そのまま文字列で扱うよりも、ライブラリを使ってプログラミング言語がサポートする辞書型に変換するのではないかと思います。\n単純なJSONの場合は辞書型のままで操作・抽出してもよいかもしれませんが、 複雑なJSONの場合はごちゃごちゃと辞書を弄り回すよりも自分で定義した型にデータをマッピングしたいものです。\n今回はJuliaにおけるJSON(から得られるDict )のstructへのマッピング方法について書いてみたいと思います。\nParameters.jlを利用したマッピング JuliaではネストしていないDictであればマッピングは比較的容易です。例として次のようなJSONを考えます。\n{ \u0026#34;title\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;main_window\u0026#34;, \u0026#34;width\u0026#34;: 500, \u0026#34;height\u0026#34;: 400, \u0026#34;show\u0026#34;: true } まずJSON.jlで文字列からDictに変換します。\njulia\u0026gt; s = \u0026#34;{\\r\\n \\\u0026#34;title\\\u0026#34;: \\\u0026#34;hello\\\u0026#34;,\\r\\n \\\u0026#34;name\\\u0026#34;: \\\u0026#34;main_window\\\u0026#34;,\\r\\n \\\u0026#34;width\\\u0026#34;: 500,\\r\\n \\\u0026#34;height\\\u0026#34;: 400,\\r\\n \\\u0026#34;show\\\u0026#34;: true\\r\\n}\u0026#34; julia\u0026gt; println(s) { \u0026#34;title\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;main_window\u0026#34;, \u0026#34;width\u0026#34;: 500, \u0026#34;height\u0026#34;: 400, \u0026#34;show\u0026#34;: true } julia\u0026gt; using JSON julia\u0026gt; j = JSON.parse(s) Dict{String,Any} with 5 entries: \u0026#34;name\u0026#34; =\u0026gt; \u0026#34;main_window\u0026#34; \u0026#34;height\u0026#34; =\u0026gt; 400 \u0026#34;show\u0026#34; =\u0026gt; true \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;hello\u0026#34; \u0026#34;width\u0026#34; =\u0026gt; 500 ここまではいいと思います。\nstruct Window name::String title::String show::Bool height::UInt64 width::UInt64 end 上のようなstructにマッピングするのはParameters.jlを付けば比較的容易です。 まずキーを文字列からシンボルに変換する次のような関数を作っておきます。\njulia\u0026gt; keytosymbol(x) = Dict(Symbol(k) =\u0026gt; v for (k, v) in pairs(x)) julia\u0026gt; keytosymbol(j) Dict{Symbol,Any} with 5 entries: :show =\u0026gt; true :name =\u0026gt; \u0026#34;main_window\u0026#34; :height =\u0026gt; 400 :title =\u0026gt; \u0026#34;hello\u0026#34; :width =\u0026gt; 500 Parameters.jlの@with_kwマクロを使用すると キーワードでコンストラクタが初期化できるようになります。（デフォルト値もサポートされています）\njulia\u0026gt; @with_kw struct Window name::String title::String show::Bool height::UInt64 width::UInt64 end Pythonでdict型のオブジェクトをキーワード引数としてアンパックして関数に渡すことができる( f(**kwargs) )ように、 Pythonでもキーワード引数にDict{Symbol, T}型のオブジェクトをf(;kwargs...)としてアンパックして渡すことができます。\n以上のことから、先ほどの関数を使ってDictのキーをSymbolに変換し、splat operator ...でアンパックすれば、\njulia\u0026gt; Window(;keytosymbol(j)...) Window name: String \u0026#34;main_window\u0026#34; title: String \u0026#34;hello\u0026#34; show: Bool true height: UInt64 0x0000000000000190 width: UInt64 0x00000000000001f4 と無事にマッピングできました。\nネストされている場合 しかしながら、実際にレスポンスとして帰ってくるJSONはしばしばもっと複雑です。\n{ \u0026#34;glossary\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;example glossary\u0026#34;, \u0026#34;GlossDiv\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;S\u0026#34;, \u0026#34;GlossList\u0026#34;: { \u0026#34;GlossEntry\u0026#34;: { \u0026#34;ID\u0026#34;: \u0026#34;SGML\u0026#34;, \u0026#34;SortAs\u0026#34;: \u0026#34;SGML\u0026#34;, \u0026#34;GlossTerm\u0026#34;: \u0026#34;Standard Generalized Markup Language\u0026#34;, \u0026#34;Acronym\u0026#34;: \u0026#34;SGML\u0026#34;, \u0026#34;Abbrev\u0026#34;: \u0026#34;ISO 8879:1986\u0026#34;, \u0026#34;GlossDef\u0026#34;: { \u0026#34;para\u0026#34;: \u0026#34;A meta-markup language, used to create markup languages such as DocBook.\u0026#34;, \u0026#34;GlossSeeAlso\u0026#34;: [\u0026#34;GML\u0026#34;, \u0026#34;XML\u0026#34;] }, \u0026#34;GlossSee\u0026#34;: \u0026#34;markup\u0026#34; } } } } } 上はJSON Exampleから引用したJSONの例です。\nusing Parameters @with_kw struct GlossDef para::String glossseealso::Vector{String} end @with_kw struct GlossEntry id::String sortas::String glossterm::String acronym::String abbrev::String glossdef::GlossDef glosssee::String end @with_kw struct GlossList glossentry::GlossEntry end @with_kw struct GlossDiv title::String glosslist::GlossList end @with_kw struct Glossary title::String glossdiv::GlossDiv end 上のように定義したstructにマッピングするにはどうしたらよいのでしょうか。\nもちろん真面目に構成していけばできない事はないのですが、なるべくお手軽に変換したいものです。\njulia\u0026gt; s = \u0026#34;{\\r\\n \\\u0026#34;glossary\\\u0026#34;: {\\r\\n \\\u0026#34;title\\\u0026#34;: \\\u0026#34;example glossary\\\u0026#34;,\\r\\n\\t\\t\\\u0026#34;GlossDiv\\\u0026#34;: {\\r\\n \\\u0026#34;title\\\u0026#34;: \\\u0026#34;S\\\u0026#34;,\\r\\n\\t\\t\\t\\\u0026#34;GlossList\\\u0026#34;: {\\r\\n \\\u0026#34;GlossEntry\\\u0026#34;: {\\r\\n \\\u0026#34;ID\\\u0026#34;: \\\u0026#34;SGML\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;SortAs\\\u0026#34;: \\\u0026#34;SGML\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;GlossTerm\\\u0026#34;: \\\u0026#34;Standard Generalized Markup Language\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;Acronym\\\u0026#34;: \\\u0026#34;SGML\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;Abbrev\\\u0026#34;: \\\u0026#34;ISO 8879:1986\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;GlossDef\\\u0026#34;: {\\r\\n \\\u0026#34;para\\\u0026#34;: \\\u0026#34;A meta-markup language, used to create markup languages such as DocBook.\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\t\\\u0026#34;GlossSeeAlso\\\u0026#34;: [\\\u0026#34;GML\\\u0026#34;, \\\u0026#34;XML\\\u0026#34;]\\r\\n },\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;GlossSee\\\u0026#34;: \\\u0026#34;markup\\\u0026#34;\\r\\n }\\r\\n }\\r\\n }\\r\\n }\\r\\n}\u0026#34; \u0026#34;{\\r\\n \\\u0026#34;glossary\\\u0026#34;: {\\r\\n \\\u0026#34;title\\\u0026#34;: \\\u0026#34;example glossary\\\u0026#34;,\\r\\n\\t\\t\\\u0026#34;GlossDiv\\\u0026#34;: {\\r\\n \\\u0026#34;title\\\u0026#34;: \\\u0026#34;S\\\u0026#34;,\\r\\n\\t\\t\\t\\\u0026#34;GlossList\\\u0026#34;: {\\r\\n \\\u0026#34;GlossEntry\\\u0026#34;: {\\r\\n \\\u0026#34;ID\\\u0026#34;: \\\u0026#34;SGML\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;SortAs\\\u0026#34;: \\\u0026#34;SGML\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;GlossTerm\\\u0026#34;: \\\u0026#34;Standard Generalized Markup Language\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;Acronym\\\u0026#34;: \\\u0026#34;SGML\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;Abbrev\\\u0026#34;: \\\u0026#34;ISO 8879:1986\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;GlossDef\\\u0026#34;: {\\r\\n \\\u0026#34;para\\\u0026#34;: \\\u0026#34;A meta-markup language, used to create markup languages such as DocBook.\\\u0026#34;,\\r\\n\\t\\t\\t\\t\\t\\t\\\u0026#34;GlossSeeAlso\\\u0026#34;: [\\\u0026#34;GML\\\u0026#34;, \\\u0026#34;XML\\\u0026#34;]\\r\\n },\\r\\n\\t\\t\\t\\t\\t\\\u0026#34;GlossSee\\\u0026#34;: \\\u0026#34;markup\\\u0026#34;\\r\\n }\\r\\n }\\r\\n }\\r\\n }\\r\\n}\u0026#34; julia\u0026gt; j = JSON.parse(s)[\u0026#34;glossary\u0026#34;] Dict{String,Any} with 2 entries: \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;example glossary\u0026#34; \u0026#34;GlossDiv\u0026#34; =\u0026gt; Dict{String,Any}(\u0026#34;title\u0026#34;=\u0026gt;\u0026#34;S\u0026#34;,\u0026#34;GlossList\u0026#34;=\u0026gt;Dict{String,Any}(\u0026#34;GlossEntry\u0026#34;=\u0026gt;Dict{String,Any}(\u0026#34;GlossSee\u0026#34;… キーを小文字に変換 まずJSONのキーを小文字にしましょう。再帰的に書くと次のようになります。\njulia\u0026gt; lowercasekeys(x) = x julia\u0026gt; lowercasekeys(x::AbstractDict) = Dict(lowercase(k) =\u0026gt; lowercasekeys(v) for (k, v) in pairs(x)) julia\u0026gt; j2 = lowercasekeys(j) Dict{String,Any} with 2 entries: \u0026#34;glossdiv\u0026#34; =\u0026gt; Dict{String,Any}(\u0026#34;title\u0026#34;=\u0026gt;\u0026#34;S\u0026#34;,\u0026#34;glosslist\u0026#34;=\u0026gt;Dict{String,Dict{String,Any}}(\u0026#34;glossentry\u0026#34;=\u0026gt;Dict(\u0026#34;sortas\u0026#34;=\u0026gt;\u0026#34;SGML\u0026#34;,\u0026#34;abbrev\u0026#34;=\u0026gt;\u0026#34;ISO 8879:1986\u0026#34;,\u0026#34;id\u0026#34;… \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;example glossary\u0026#34; 以前と同じような方法では、DictをGlossDivにconvertできないので失敗します。\njulia\u0026gt; Glossary(;keytosymbol(j2)...) ERROR: MethodError: Cannot `convert` an object of type Dict{String,Any} to an object of type GlossDiv Closest candidates are: convert(::Type{T}, ::T) where T at essentials.jl:171 GlossDiv(::Any, ::Any) at /root/.julia/packages/Parameters/CVyBv/src/Parameters.jl:480 Stacktrace: [1] Glossary(::String, ::Dict{String,Any}) at /root/.julia/packages/Parameters/CVyBv/src/Parameters.jl:480 [2] Glossary(; title::String, glossdiv::Dict{String,Any}) at /root/.julia/packages/Parameters/CVyBv/src/Parameters.jl:468 [3] top-level scope at REPL[31]:1 関数の形を考えてみる 変換する関数は大まかにこんな感じになるはずです。（適当）\nfunction convertdict(T::Type, d::AbstractDict) kwargs = Dict{Symbol, Any}() for (k, v) in pairs(d) symk = Symbol(k) kwargs[symk] = (変換が必要な時は変換する) end return T(;kwargs...) end 「変換が必要な時は変換する」という部分を考えましょう。\n変換先の型を判別 変換がいつ必要になるかはメンバー変数の型を見て判別することにします。 ちなみに、メンバー変数の型はCore.fieldtypeで取得できます。\njulia\u0026gt; fieldtype(GlossDef, :para) String julia\u0026gt; fieldtype(GlossDef, :glossseealso) Array{String,1} Column: fieldtype(T, k)の型, Row: vの型 としたとき、下のようにディスパッチさせることにします。\nUnion{S, Nothing} Vector{S} Dict それ以外 Vector convertdict(S, v) convertdict.(S, v) \u0026mdash; \u0026mdash; Dict convertdict(S, v) \u0026mdash; v マッピングを実施 それ以外 convertdict(S, v) \u0026mdash; \u0026mdash; v convertdictの構成 あとは先ほどの表に合わせて関数を整えていきます。\nconvertdict(::Type, x) = x convertdict(::Type{Union{T, Nothing}}, x) where T = convertdict(T, x) convertdict(::Type{Union{T, Nothing}}, d::AbstractDict) where T = convertdict(T, d) convertdict(::Type{T}, v::AbstractVector) where T \u0026lt;: AbstractVector = convertdict.(eltype(T), v) convertdict(::Type{T}, d::AbstractDict) where T \u0026lt;: AbstractDict = d function convertdict(T::Type, d::AbstractDict) kwargs = Dict{Symbol, Any}() for (k, v) in pairs(d) symk = Symbol(k) kwargs[symk] = convertdict(fieldtype(T, symk), v) end return T(;kwargs...) end 思ったよりシンプルですね。3行目の\nconvertdict(::Type{Union{T, Nothing}}, d::AbstractDict) where T = convertdict(T, d) は2行目に含まれているので必要ないように見えるかもしれませんが、これがないと convertdict(::Type{Union{T, Nothing}}, d::AbstractDict) が convertdict(::Type{Union{T, Nothing}}, x) と convertdict(T::Type, d::AbstractDict) のどちらにディスパッチしてよいか曖昧になってしまうので、必要な定義です。\nさてさて、\njulia\u0026gt; glossary = convertdict(Glossary, j2) Glossary title: String \u0026#34;example glossary\u0026#34; glossdiv: GlossDiv julia\u0026gt; glossary.glossdiv GlossDiv title: String \u0026#34;S\u0026#34; glosslist: GlossList julia\u0026gt; glossary.glossdiv.glosslist GlossList glossentry: GlossEntry julia\u0026gt; glossary.glossdiv.glosslist.glossentry GlossEntry id: String \u0026#34;SGML\u0026#34; sortas: String \u0026#34;SGML\u0026#34; glossterm: String \u0026#34;Standard Generalized Markup Language\u0026#34; acronym: String \u0026#34;SGML\u0026#34; abbrev: String \u0026#34;ISO 8879:1986\u0026#34; glossdef: GlossDef glosssee: String \u0026#34;markup\u0026#34; julia\u0026gt; glossary.glossdiv.glosslist.glossentry.glossdef GlossDef para: String \u0026#34;A meta-markup language, used to create markup languages such as DocBook.\u0026#34; glossseealso: Array{String}((2,)) julia\u0026gt; glossary.glossdiv.glosslist.glossentry.glossdef.glossseealso 2-element Array{String,1}: \u0026#34;GML\u0026#34; \u0026#34;XML\u0026#34; 一発でマッピングできました。\nもう一例やってみます。\n{\u0026#34;menu\u0026#34;: { \u0026#34;header\u0026#34;: \u0026#34;SVG Viewer\u0026#34;, \u0026#34;items\u0026#34;: [ {\u0026#34;id\u0026#34;: \u0026#34;Open\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;OpenNew\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Open New\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;ZoomIn\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Zoom In\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;ZoomOut\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Zoom Out\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;OriginalView\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Original View\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;Quality\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;Pause\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;Mute\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;Find\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Find...\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;FindAgain\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Find Again\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;Copy\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;CopyAgain\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Copy Again\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;CopySVG\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Copy SVG\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;ViewSVG\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;View SVG\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;ViewSource\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;View Source\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;SaveAs\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Save As\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;Help\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;About\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;About Adobe CVG Viewer...\u0026#34;} ] }} まずは読み込んでみます。\njulia\u0026gt; s2 = \u0026#34;{\\\u0026#34;menu\\\u0026#34;: {\\r\\n \\\u0026#34;header\\\u0026#34;: \\\u0026#34;SVG Viewer\\\u0026#34;,\\r\\n \\\u0026#34;items\\\u0026#34;: [\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;Open\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;OpenNew\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Open New\\\u0026#34;},\\r\\n null,\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;ZoomIn\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Zoom In\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;ZoomOut\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Zoom Out\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;OriginalView\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Original View\\\u0026#34;},\\r\\n null,\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;Quality\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;Pause\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;Mute\\\u0026#34;},\\r\\n null,\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;Find\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Find...\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;FindAgain\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Find Again\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;Copy\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;CopyAgain\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Copy Again\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;CopySVG\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Copy SVG\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;ViewSVG\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;View SVG\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;ViewSource\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;View Source\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;SaveAs\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;Save As\\\u0026#34;},\\r\\n null,\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;Help\\\u0026#34;},\\r\\n {\\\u0026#34;id\\\u0026#34;: \\\u0026#34;About\\\u0026#34;, \\\u0026#34;label\\\u0026#34;: \\\u0026#34;About Adobe CVG Viewer...\\\u0026#34;}\\r\\n ]\\r\\n}}\u0026#34; julia\u0026gt; println(s2) {\u0026#34;menu\u0026#34;: { \u0026#34;header\u0026#34;: \u0026#34;SVG Viewer\u0026#34;, \u0026#34;items\u0026#34;: [ {\u0026#34;id\u0026#34;: \u0026#34;Open\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;OpenNew\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Open New\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;ZoomIn\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Zoom In\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;ZoomOut\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Zoom Out\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;OriginalView\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Original View\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;Quality\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;Pause\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;Mute\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;Find\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Find...\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;FindAgain\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Find Again\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;Copy\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;CopyAgain\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Copy Again\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;CopySVG\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Copy SVG\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;ViewSVG\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;View SVG\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;ViewSource\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;View Source\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;SaveAs\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;Save As\u0026#34;}, null, {\u0026#34;id\u0026#34;: \u0026#34;Help\u0026#34;}, {\u0026#34;id\u0026#34;: \u0026#34;About\u0026#34;, \u0026#34;label\u0026#34;: \u0026#34;About Adobe CVG Viewer...\u0026#34;} ] }} julia\u0026gt; j3 = JSON.parse(s2)[\u0026#34;menu\u0026#34;] Dict{String,Any} with 2 entries: \u0026#34;items\u0026#34; =\u0026gt; Any[Dict{String,Any}(\u0026#34;id\u0026#34;=\u0026gt;\u0026#34;Open\u0026#34;), Dict{String,Any}(\u0026#34;label\u0026#34;=\u0026gt;\u0026#34;Open New\u0026#34;,\u0026#34;id\u0026#34;=\u0026gt;\u0026#34;OpenNew\u0026#34;), nothing, Dict{String,Any}(\u0026#34;label\u0026#34;=\u0026gt;\u0026#34;Zoom In\u0026#34;,\u0026#34;id\u0026#34;=… \u0026#34;header\u0026#34; =\u0026gt; \u0026#34;SVG Viewer\u0026#34; nullはnothingにマッピングされています。\njulia\u0026gt; @with_kw struct Item id::String label::Union{String, Nothing} = nothing end julia\u0026gt; @with_kw struct Menu header::String items::Vector{Union{Item, Nothing}} end 上のように定義した場合でも、\njulia\u0026gt; menu = convertdict(Menu, j3) Menu header: String \u0026#34;SVG Viewer\u0026#34; items: Array{Union{Nothing, Item}}((22,)) julia\u0026gt; menu.items 22-element Array{Union{Nothing, Item},1}: Item id: String \u0026#34;Open\u0026#34; label: Nothing nothing Item id: String \u0026#34;OpenNew\u0026#34; label: String \u0026#34;Open New\u0026#34; nothing Item id: String \u0026#34;ZoomIn\u0026#34; label: String \u0026#34;Zoom In\u0026#34; Item id: String \u0026#34;ZoomOut\u0026#34; label: String \u0026#34;Zoom Out\u0026#34; Item id: String \u0026#34;OriginalView\u0026#34; label: String \u0026#34;Original View\u0026#34; nothing Item id: String \u0026#34;Quality\u0026#34; label: Nothing nothing Item id: String \u0026#34;Pause\u0026#34; label: Nothing nothing Item id: String \u0026#34;Mute\u0026#34; label: Nothing nothing ⋮ Item id: String \u0026#34;Copy\u0026#34; label: Nothing nothing Item id: String \u0026#34;CopyAgain\u0026#34; label: String \u0026#34;Copy Again\u0026#34; Item id: String \u0026#34;CopySVG\u0026#34; label: String \u0026#34;Copy SVG\u0026#34; Item id: String \u0026#34;ViewSVG\u0026#34; label: String \u0026#34;View SVG\u0026#34; Item id: String \u0026#34;ViewSource\u0026#34; label: String \u0026#34;View Source\u0026#34; Item id: String \u0026#34;SaveAs\u0026#34; label: String \u0026#34;Save As\u0026#34; nothing Item id: String \u0026#34;Help\u0026#34; label: Nothing nothing Item id: String \u0026#34;About\u0026#34; label: String \u0026#34;About Adobe CVG Viewer...\u0026#34; 問題なくnothingやVectorとUnionの組み合わせを処理できています。\nパッケージ パッケージとするほどのものでもないかもしれませんが、一応JuliaRegistries/Generalに登録してあります。 ] add StructMapping でお使いください。\nhttps://github.com/matsueushi/StructMapping.jl\n",
    "permalink": "https://matsueushi.github.io/posts/julia-mapping-nested-dict/",
    "tags": [
      "Julia",
      "JSON",
      "struct"
    ],
    "title": "JuliaでネストしているDictをstructにマッピングする"
  },
  {
    "contents": "レコードをデジタル化する（前編）の続きです。\n今回は、レコードをデジタル化する際に障害となる楽曲メタデータの取得・入力にフォーカスしたいと思います。 Audacityでは保存する際にタグを入力する画面が表示されますが、これを一枚一枚真心を込めて手入力していたら発狂してしまいます。\nそこで、ディスコグラフィのデータベースサイトで、CD/レコード/カセットテープ等のマーケットプレイスでもあるDiscogsからデータを取得してみました。\nDiscogs API RESTful APIの説明はここで見れます。\nDiscogs API Documentation 基本的な機能を使いたいだけならば、Discogs APIを使うのに特にAPIキーは必要ありません。 サムネイル画像のURLなど、登録をしてpersonal access tokenを取得しuser_tokenとして渡さないと取得できない情報もあり、 user_tokenを渡さないとレスポンスのなかの画像のURLが空白になります。 Discogsにはアプリケーション用のConsumer KeyとConsumer Secretもあるのですが、こちらは使ったことがありません。 自分のpersonal access tokenはDiscogsのSettings -\u0026gt; Developersで確認できます。\nDiscogsのAPIを各言語で利用できるようなクライアント/Exampleはいくつかあり、APIのドキュメンテーションに書いてありますが 例えばPythonであればjesseward / discogs-oauth-exampleがあります。\n以前はPythonであれば公式が提供するdiscogs / discogs_clientがありましたが、いつの間にかdeprecatedになっていたようです。\n実は、過去discogs_clientを使ってPythonでタグをダウンロードするスクリプトを書いていたのですが、 久しぶりに使おうと思ったらdeprecatedになっていたのでJuliaで書き直しました。\nRunOut.jl Registratorには登録していないのですが気が向いたら登録しようと思います。\nhttps://github.com/matsueushi/RunOut.jl\n使い方は簡単で、レポジトリをクローンして\n$ julia --project でプロジェクトを有効化します。\nそして、ダウンロードしたいリリースのリリースIDを調べます。Discogsにはマスターリリースとリリースという概念があり、 雑に言うとマスターリリースはアルバム・シングル名、リリースはそれぞれのエディション(CD, LP, 初回限定盤、再発など)に対応しています。\nそのため、今回調べる必要があるのはマスターリリースではなくリリースのIDです。 CDとLPの収録曲の違いや、初回限定版や再発のボーナストラックなどがありますからね。\n例としてMy Bloody ValentineのLoveless のNice Price再発盤であれば、対応するリリースは\nhttps://www.discogs.com/My-Bloody-Valentine-Loveless/release/919364\nとなるので、idは919364です。\nまず、クライアントをセットアップします。\njulia\u0026gt; using RunOut julia\u0026gt; using Pkg julia\u0026gt; useragent = \u0026#34;RunOut/$(Pkg.project().version) +https://matsueushi.github.io\u0026#34; \u0026#34;RunOut/0.1.0 +https://matsueushi.github.io\u0026#34; julia\u0026gt; client = Client(useragent) Client(\u0026#34;RunOut/0.1.0 +https://matsueushi.github.io\u0026#34;, nothing) クライアントはuser_tokenを渡してinstantiateすることもできます。\nclient = Client(useragent; usertoken=\u0026#34;\u0026lt;user token\u0026gt;\u0026#34;) リリース情報を取得するのは非常に簡単です。\njulia\u0026gt; release = fetch_release(client, 919364) Release id: UInt64 0x00000000000e0744 title: String \u0026#34;Loveless\u0026#34; resource_url: String \u0026#34;https://api.discogs.com/releases/919364\u0026#34; artists: Array{Artist}((1,)) artists_sort: String \u0026#34;My Bloody Valentine\u0026#34; data_quality: String \u0026#34;Needs Vote\u0026#34; thumb: Nothing nothing community: Community companies: Array{Company}((4,)) country: String \u0026#34;Japan\u0026#34; date_added: TimeZones.ZonedDateTime date_changed: TimeZones.ZonedDateTime estimated_weight: UInt64 0x0000000000000055 extraartists: Array{Artist}((7,)) format_quantity: Int64 1 formats: Array{Format}((1,)) genres: Array{String}((1,)) identifiers: Array{Identifier}((5,)) images: Array{Image}((9,)) labels: Array{Label}((1,)) lowest_price: Float64 2.99 master_id: UInt64 0x000000000000173c master_url: String \u0026#34;https://api.discogs.com/masters/5948\u0026#34; notes: Nothing nothing num_for_sale: UInt64 0x000000000000001e released: String \u0026#34;1998-03-21\u0026#34; released_formatted: String \u0026#34;21 Mar 1998\u0026#34; series: Array{Label}((1,)) status: String \u0026#34;Accepted\u0026#34; styles: Array{String}((3,)) tracklist: Array{Track}((11,)) uri: String \u0026#34;https://www.discogs.com/My-Bloody-Valentine-Loveless/release/919364\u0026#34; videos: Array{Video}((9,)) year: UInt64 0x00000000000007ce 地道な作業により情報をstructにマッピングしたので、単なるDictより取り扱いが容易になっています。\njulia\u0026gt; release.tracklist 11-element Array{Track,1}: Track(\u0026#34;1\u0026#34;, \u0026#34;Only Shallow = オンリー・シャロウ\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;4:17\u0026#34;, nothing, nothing) Track(\u0026#34;2\u0026#34;, \u0026#34;Loomer = ルーマー\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;2:38\u0026#34;, nothing, nothing) Track(\u0026#34;3\u0026#34;, \u0026#34;Touched = タッチト\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;0:56\u0026#34;, nothing, nothing) Track(\u0026#34;4\u0026#34;, \u0026#34;To Here Knows When = トゥ・ヒア・ノウズ・ホエン\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;5:31\u0026#34;, nothing, nothing) Track(\u0026#34;5\u0026#34;, \u0026#34;When You Sleep = ホエン・ユー・スリープ\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;4:11\u0026#34;, nothing, nothing) Track(\u0026#34;6\u0026#34;, \u0026#34;I Only Said = アイ・オンリー・セッド\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;5:34\u0026#34;, nothing, nothing) Track(\u0026#34;7\u0026#34;, \u0026#34;Come In Alone = カム・イン・アローン\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;3:58\u0026#34;, nothing, nothing) Track(\u0026#34;8\u0026#34;, \u0026#34;Sometimes = サムタイムズ\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;5:19\u0026#34;, nothing, nothing) Track(\u0026#34;9\u0026#34;, \u0026#34;Blown A Wish = ブロウン・ア・ウィッシュ\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;3:36\u0026#34;, nothing, nothing) Track(\u0026#34;10\u0026#34;, \u0026#34;What You Want = ホワット・ユー・ウオント\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;5:33\u0026#34;, nothing, nothing) Track(\u0026#34;11\u0026#34;, \u0026#34;Soon = スーン\u0026#34;, \u0026#34;track\u0026#34;, \u0026#34;6:59\u0026#34;, nothing, nothing) そして\njulia\u0026gt; save_xml(release, \u0026#34;output\u0026#34;) でoutputフォルダにXMLが生成されるので、あとはXMLをAudacityのメタデータ編集画面でLoad...を押してロードすれば良いです。\nまあ、自分以外使う人がいなそうですが。。。\n以下は些細な内容ですが実際やっていて気になった点です。\nHeading 例えばRadiohaadのOK Computer のTracklistを見てみると\u0026quot;Enry\u0026quot;, \u0026ldquo;Meeny\u0026rdquo;, \u0026ldquo;Miney\u0026rdquo;, \u0026ldquo;Mo\u0026rdquo; といったHeadingの情報が存在することがわかります。 これらは曲には対応していないので、XMLを吐き出す際には無視します。 Trackのpositionがnothingになっているものを飛ばせば良いです。\n曲のナンバリング また、これはiTunes/Music.appに特有の現象かもしれませんが、 Tracklistのpositionが数字ではなく記号やアルファベットが入っている場合(\u0026ldquo;A\u0026rdquo;, \u0026ldquo;A1\u0026quot;など) は曲のpositionとして認識されないため、ナンバリングは自分で行う必要があります。\nアーティスト名 Discogsでは、同名別人・別アーティストを末尾にカッコ付き番号をつけて区別しています。 例えば、\u0026ldquo;BOAT\u0026rdquo;はアメリカのインディーロックバンド、 \u0026ldquo;Boat (2)\u0026rdquo;は日本のロックバンドといった形です。\nカッコ付き番号を除去するために、\nreplace(artist_name, r\u0026#34; \\(\\d\\)$\u0026#34; =\u0026gt; \u0026#34;\u0026#34;) を使って置き換えます。\nあとがき Windows用ですが、Mp3tagを使えば同様のことができるようです……こちらの方が簡単かもしれません。\nMp3tag + Discogsを利用したデジタルファイルのTag付け方法 ",
    "permalink": "https://matsueushi.github.io/posts/how-to-digitize-vinyl-2/",
    "tags": [
      "Music",
      "Vinyl",
      "Audacity",
      "Julia",
      "Discogs",
      "API"
    ],
    "title": "レコードをデジタル化する（後編）-Discogs APIを使ってメタデータを取得-"
  },
  {
    "contents": "アメリカ・ネブラスカ州オマハのNanorayというアーティストの二枚目？Gacha。\nGacha by NANORAY ドラムンベースとカラフルなシンセのゲームミュージックの融合といった感じで聞いていると高揚感に包まれる。 曲名にShibuya, Himeji、Subaruなどを使っているので日本文化に馴染みがあるのかもしれない。\nNANORAY · 魔法渦状Lovely You! BandCamp - NANORAY Spotify - NANORAY Twitter - Nanoray-DX Rate Your Music - Nanoray ",
    "permalink": "https://matsueushi.github.io/posts/nanoray/",
    "tags": [
      "Music"
    ],
    "title": "Nanoray - Gacha (2019)"
  },
  {
    "contents": "小ネタです。\n自分で簡単なパッケージを作っている時に、Project.toml内のversionの情報を取りたくなったので。\nプロジェクト情報はPkg.project()で取得できます。 ドキュメントにはJulia 1.4以上が必要で、この機能はexperimentalとありました。\njulia\u0026gt; using Pkg julia\u0026gt; pj = Pkg.project() Pkg.Types.ProjectInfo(\u0026#34;RunOut\u0026#34;, UUID(\u0026#34;03328d24-db5d-422f-afe8-b99de72c82b3\u0026#34;), v\u0026#34;0.1.0\u0026#34;, true, Dict{String,Base.UUID}(\u0026#34;JSON\u0026#34; =\u0026gt; UUID(\u0026#34;682c06a0-de6a-54ab-a142-c8b1cf79cde6\u0026#34;),\u0026#34;HTTP\u0026#34; =\u0026gt; UUID(\u0026#34;cd3eb016-35fb-5094-929b-558a96fad6f3\u0026#34;)), \u0026#34;/juliatmp/Project.toml\u0026#34;) バージョン取得は\njulia\u0026gt; pj.version v\u0026#34;0.1.0\u0026#34; julia\u0026gt; typeof(pj.version) VersionNumber でできて、Base.VersionNumberが返ってきます。\njulia\u0026gt; String(pj.version) ERROR: MethodError: no method matching String(::VersionNumber) Closest candidates are: String(::String) at boot.jl:321 String(::Array{UInt8,1}) at strings/string.jl:39 String(::Base.CodeUnits{UInt8,String}) at strings/string.jl:77 ... Stacktrace: [1] top-level scope at REPL[16]:1 文字列に変換するには、Stringではなく$を使えばいいのかな。\njulia\u0026gt; \u0026#34;$(pj.version)\u0026#34; \u0026#34;0.1.0\u0026#34; julia\u0026gt; typeof(\u0026#34;$(pj.version)\u0026#34;) String ",
    "permalink": "https://matsueushi.github.io/posts/julia-package-version/",
    "tags": [
      "Julia"
    ],
    "title": "Juliaのパッケージ内から自分自身のバージョンを取得する"
  },
  {
    "contents": "今回はちょっといつもとは毛色は違いますがレコードのデジタル化について書きたいと思います。\nレコードプレイヤー 私が持っているレコードプレイヤー(人生初)は、2年ほど前に買ったオーディオテクニカの AT-LP60-USBというモデルで、 正確な値段は覚えていないですが購入価格は大体15,000円だったと思います。\nUSB端子が付いているので、とりあえずこれを買っておけばアンプやスピーカーなどを購入しなくても、 パソコンにつないでレコードを再生して聞いたり録音(音声ファイル化)したりできるので私のようにちょっと試しに聞いてみたい人にとっては良いです。\nすでにAT-LP60-USBは製造中止になっているようですが、 後継のAT-LP60XUSBが出ているようです。\nレコードをデジタル化するのは面倒 プレイヤーにセットして読み込むだけで全自動で曲ごとに分割されたリッピングを行い、 アーティスト名や曲名を入力してくれるCDとは違い、レコードの場合は曲データが繋がった状態で録音され、 さらに曲情報も自動では読み込まれないのでデジタル化には手間を要します。ノイズの除去なども含めるとさらに面倒ですね。\nそんなにパソコンに取り込みたいなら最初からCDとかデジタルで買えばいいじゃん、 ストリーミングなら取り込む必要性すらないですよ、 なんでわざわざアナログ媒体で購入して手間をかけてデジタル化するんですかという耳の痛い意見もありますが、 レコードでしかプレスされておらずCDやストリーミングで聞くことができない曲をデータ化して簡単に聴けるようにしておいたり、 盤面に傷やホコリが着く前のスナップショットを保存しておいたりしたくなるんです……。\n新譜でレコード買うとダウンロードコードが付属してきたり、 Bandcamp経由でレコード買うとデジタルライブラリーにも追加されるなど、 簡単に取り込めるレコードが最近は多いですけどね。\n以後、私が所有しているAT-LP60-USBを前提にして話を進めて行きますが、 他のUSB端子があるレコードプレイヤーでも同様なのではないかと思います。\nAudacityの注意点 AT-LP60-USBではフリーでオープンソースのデジタルオーディオエディターであるAudacityでレコードをデジタル化できることが謳われています。\n基本はオーディオテクニカのウェブサイトでダウンロードできるソフトウェアマニュアル(Downloadsのところにある) を見て接続や設定をすれば良いので詳細はスキップしますが、MacOS 10.15 Catalinaを使っている場合注意する必要があります。\nAudacityをDockから起動した場合、AT-LP60-USBが認識されず、音が出ません。 これは公式のウェブサイトでも言及されている既知の問題です。\nMacOS 10.15 (Catalina) does not support Audacity 2.3.2\n私の場合は上のworkaroundに従い、Terminalから\nopen /Applications/Audacity.app/Contents/MacOS/Audacity と打ち込んでAudacityを起動すると無事に音が再生できるようになりました。\n録音 録音自体はそれほど大変ではなく、通常の再生時と同じように右上のClick to Start Monitoringを押して赤色の丸の録音ボタンを押すだけです。\n$n$倍速 $(n \u0026gt; 1)$で読み込むことができるCDとは違い等速の録音になりますが、ゆっくり曲を聴きながら待ちましょう。\nノイズの除去 録音した楽曲データにはレコードの傷、ホコリや汚れによりノイズが含まれています。 録音前に注意深くホコリを取り除いたとしても多少は入るもので、自分はそこまで神経質になってはいないのですが、 ノイズが気になる時はEffect -\u0026gt; Noise Reductionでバックグラウンドノイズを除去しています。\nノイズの除去～Audacityエフェクト解説 プチプチノイズ（クリックノイズ）も除去できますがあまり使ってません。個人的にはそこまで一生懸命加工しなくても良いのではないかと思っています。\nクリックノイズの除去～Audacityエフェクト解説 曲の分割 次は曲の分割です。\nまず、先頭と末尾の無音部分を選択して削除します。次に、波形を全選択してAnalyze -\u0026gt; Silence Finder\u0026hellip;で無音部分にラベルを付けます。\n上のようにラベルトラックが追加されてラベルが設定されるので、曲間ではないものを削除します。 Tabキーで一つずつ進みながら消していくのが手っ取り早いです。この時にラベル名も編集して、\u0026ldquo;1\u0026rdquo;, \u0026ldquo;2\u0026rdquo;, \u0026ldquo;3\u0026rdquo;\u0026hellip;と番号をつけておきます。\n書き出し File -\u0026gt; Export -\u0026gt; Export Multipleでファイルをラベルの位置で分割して保存できます。 アーティストや曲名などのメタデータを入力します。\nこれで終わりで、あとはiTunesにインポートするだけです。\n最後のメタデータをチマチマ手で入力するのはしんどいので、次回は手を抜く方法を書きたいと思います。\n次-\u0026gt;レコードをデジタル化する（後編）\n",
    "permalink": "https://matsueushi.github.io/posts/how-to-digitize-vinyl-1/",
    "tags": [
      "Music",
      "Vinyl",
      "Audacity"
    ],
    "title": "レコードをデジタル化する（前編）"
  },
  {
    "contents": " MATLAB–Python–Julia cheatsheet The Fast Track to A quick and dirty overview of Julia 1.0 Julia % julia _ _ _ _(_)_ | Documentation: https://docs.julialang.org (_) | (_) (_) | _ _ _| |_ __ _ | Type \u0026#34;?\u0026#34; for help, \u0026#34;]?\u0026#34; for Pkg help. | | | | | | |/ _` | | | | |_| | | | (_| | | Version 1.5.1 (2020-08-25) _/ |\\__\u0026#39;_|_|_|\\__\u0026#39;_| | Official https://julialang.org/ release |__/ | Python % python Python 3.8.5 (default, Aug 5 2020, 08:22:02) [GCC 8.3.0] on linux Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. Get the list of all files Julia: Base.Filesystem.readdir julia\u0026gt; readdir() 20-element Array{String,1}: \u0026#34;.dockerenv\u0026#34; \u0026#34;bin\u0026#34; \u0026#34;boot\u0026#34; \u0026#34;dev\u0026#34; \u0026#34;etc\u0026#34; \u0026#34;home\u0026#34; \u0026#34;lib\u0026#34; \u0026#34;lib64\u0026#34; \u0026#34;media\u0026#34; ⋮ \u0026#34;root\u0026#34; \u0026#34;run\u0026#34; \u0026#34;sbin\u0026#34; \u0026#34;srv\u0026#34; \u0026#34;sys\u0026#34; \u0026#34;tmp\u0026#34; \u0026#34;usr\u0026#34; \u0026#34;var\u0026#34; Python: os.listdir \u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; os.listdir() [\u0026#39;lib\u0026#39;, \u0026#39;home\u0026#39;, \u0026#39;etc\u0026#39;, \u0026#39;media\u0026#39;, \u0026#39;var\u0026#39;, \u0026#39;srv\u0026#39;, \u0026#39;sys\u0026#39;, \u0026#39;bin\u0026#39;, \u0026#39;usr\u0026#39;, \u0026#39;root\u0026#39;, \u0026#39;boot\u0026#39;, \u0026#39;tmp\u0026#39;, \u0026#39;dev\u0026#39;, \u0026#39;opt\u0026#39;, \u0026#39;mnt\u0026#39;, \u0026#39;lib64\u0026#39;, \u0026#39;proc\u0026#39;, \u0026#39;run\u0026#39;, \u0026#39;sbin\u0026#39;, \u0026#39;.dockerenv\u0026#39;] Join path components Julia: Base.Filesystem.joinpath julia\u0026gt; joinpath(\u0026#34;/home\u0026#34;, \u0026#34;file.txt\u0026#34;) \u0026#34;/home/file.txt\u0026#34; Python: os.path.join \u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; os.path.join(\u0026#39;/home\u0026#39;, \u0026#39;file.txt\u0026#39;) \u0026#39;/home/file.txt\u0026#39; Get the current working directory Julia: Base.@__DIR__ julia\u0026gt; @__DIR__ \u0026#34;/\u0026#34; Python: os.getcwd \u0026gt;\u0026gt;\u0026gt; import os \u0026gt;\u0026gt;\u0026gt; os.getcwd() \u0026#39;/\u0026#39; Get the running file path Julia: Base.@__FILE__ Python: __path__ Return an array of zeros with the same shape Julia: Base.zero julia\u0026gt; x = 1:6 1:6 julia\u0026gt; x = reshape(x, 2, 3) 2×3 reshape(::UnitRange{Int64}, 2, 3) with eltype Int64: 1 3 5 2 4 6 julia\u0026gt; zero(x) 2×3 Array{Int64,2}: 0 0 0 0 0 0 Python: numpy.zeros_like \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; x = np.arange(6) \u0026gt;\u0026gt;\u0026gt; x = x.reshape((2, 3)) \u0026gt;\u0026gt;\u0026gt; x array([[0, 1, 2], [3, 4, 5]]) \u0026gt;\u0026gt;\u0026gt; np.zeros_like(x) array([[0, 0, 0], [0, 0, 0]]) Return an array of ones with the same shape Julia: Base.fill! + Base.similar julia\u0026gt; x = 1:6 1:6 julia\u0026gt; x = reshape(x, 2, 3) 2×3 reshape(::UnitRange{Int64}, 2, 3) with eltype Int64: 1 3 5 2 4 6 julia\u0026gt; x = collect(x) 2×3 Array{Int64,2}: 1 3 5 2 4 6 julia\u0026gt; fill!(similar(x), 1) 2×3 Array{Int64,2}: 1 1 1 1 1 1 Python: numpy.ones_like \u0026gt;\u0026gt;\u0026gt; import numpy as np \u0026gt;\u0026gt;\u0026gt; x = np.arange(6) \u0026gt;\u0026gt;\u0026gt; x = x.reshape((2, 3)) \u0026gt;\u0026gt;\u0026gt; x array([[0, 1, 2], [3, 4, 5]]) \u0026gt;\u0026gt;\u0026gt; np.ones_like(x) array([[1, 1, 1], [1, 1, 1]]) Get the value for the given key if key is in dictionary, and return the default value if the key is not found Julia: Base.get julia\u0026gt; d = Dict(\u0026#34;a\u0026#34;=\u0026gt;1, \u0026#34;b\u0026#34;=\u0026gt;2) Dict{String,Int64} with 2 entries: \u0026#34;b\u0026#34; =\u0026gt; 2 \u0026#34;a\u0026#34; =\u0026gt; 1 julia\u0026gt; get(d, \u0026#34;a\u0026#34;, 0) 1 julia\u0026gt; get(d, \u0026#34;c\u0026#34;, 0) 0 Python: dict.get \u0026gt;\u0026gt;\u0026gt; d = {\u0026#39;a\u0026#39;: 1, \u0026#39;b\u0026#39;: 2} \u0026gt;\u0026gt;\u0026gt; d.get(\u0026#39;a\u0026#39;, 0) 1 \u0026gt;\u0026gt;\u0026gt; d.get(\u0026#39;c\u0026#39;, 0) 0 ",
    "permalink": "https://matsueushi.github.io/posts/julia-python-cheatsheet/",
    "tags": [
      "Julia",
      "Python"
    ],
    "title": "Julia vs Python Cheatsheet"
  },
  {
    "contents": "アメリカ、ニュージャージー州のCarl Strumのソロプロジェクトと思われるmochitsukiのEPで、ジャンルはMath Rockでしょうか。\n日本語の餅つきから取っているんじゃないかと思っているんですが、bandcampのアーティスト欄に書かれている、\u0026ldquo;MOE CHEAT SUE KEY\u0026quot;から来ているんですかね。\nSpotifyでたまたま見つけて、メロディがポップでグイグイ展開していくところが結構いいなと思ったので記しておきます。\nNET NEW RESOURCES by MOCHITSUKI リードトラックのAre You Madは悪夢めいたMVも作られています。 Alt77 Alternative music blog の レビュー: https://alt77.com/mochitsuki-are-you-mad-review/\nArtist.link: https://artist.link/mochi\nTwitter: https://twitter.com/carlstrum\nInstagram: https://www.instagram.com/carlstrum/?hl=en\n",
    "permalink": "https://matsueushi.github.io/posts/mochitsuki-net-new-resources/",
    "tags": [
      "Music"
    ],
    "title": "Mochitsuki - Net New Resources (2020)"
  },
  {
    "contents": "下を参考にしてページを検索できるようにしました。左にSearch項目を追加しました。\nClient side searching for Hugo.io with Fuse.js Hugo製ブログに検索ページを追加してみた Hugo + Lunrによる日本語全文検索 なんか微妙に検索結果がおかしい時もありますが、いったん置いておきます。\nあとはフォルダ構成をいろいろいじりました。\n",
    "permalink": "https://matsueushi.github.io/posts/hugo-search/",
    "tags": [
      "Hugo"
    ],
    "title": "Hugoのページを検索できるようにした"
  },
  {
    "contents": "音楽が好きな人であればShazamというアプリはご存知かと思います。\n街中で気になった曲をスマートフォンに聞かせると、 相当マイナーな曲でない限り大抵の場合10秒程度聞かせると曲名やアーティスト名を教えてくれて、 しかも多少雑音が混じってしまっていても大丈夫という非常に便利なアプリです。\n仕組みが気になったので、調べて一部をJuliaで実装してみました。\nJuliaのバージョンは1.5.0です。\n_ _ _ _(_)_ | Documentation: https://docs.julialang.org (_) | (_) (_) | _ _ _| |_ __ _ | Type \u0026#34;?\u0026#34; for help, \u0026#34;]?\u0026#34; for Pkg help. | | | | | | |/ _` | | | | |_| | | | (_| | | Version 1.5.0 (2020-08-01) _/ |\\__\u0026#39;_|_|_|\\__\u0026#39;_| | Official https://julialang.org/ release |__/ | 意外と単純な基本原理 最初、ディープラーニング的なテクニックを使っているのかと思ったのですが、調べてみると意外と手法自体はシンプルなものでした。\n曲を認識させるにあたり、原曲の曲データの特徴量を以下の方法でフィンガープリント (Audio fingerprint/Acoustic fingerprint) します。\n\u00081. 曲データのスペクトログラムを作成する (スペクトログラムに関しては、前 にやりましたのでそちらを参照してください)\n2. スペクトログラムのピークを探す。これは、適当な大きさの最大値フィルターをかけて元の画像と一致したらピークとします。 3. スペクトログラムのピークからペアを作る。と言っても全ての組み合わせのペアを考えるのではなく、二点が近いペアのみを考えます。 4. ペアからハッシュを生成する。ピークを(時間, 周波数)のペアで表した時に、前項で見つけたペアが $((t_1, f_1), (t_2, f_2)), t_1 \u0026lt; t_2$ であるとします。 この時、ハッシュテーブルに登録するキーと値はそれぞれ $[f_1:f_2:\\Delta t]$ と $t_1$ になります。ここで、$\\Delta t = t_2 - t_1$です。\nという方法で曲から特徴量を抽出して曲のフィンガープリンティングを行います。\n曲データにノイズが加わっていたとしても（全く同じではないですが、一致していることが確認するには十分に）似たようなハッシュデータが得られるようになっているのがポイントです。\nマッチングの方法 Shazamを使ったことがある人ならわかると思うのですが、Shazamを使って曲名を認識させる際には、 曲を全部聞かせる必要はなく、途中から一部分を聞かせるだけで十分です。\nハッシュが Hash:time = $[f_1:f_2:\\Delta t]:t_1$ であることがキーポイントで、 原曲と聞かせた曲の一部分では曲のスタート位置が当然違うわけですが、$[f_1:f_2:\\Delta t]$ はスタート位置とは関係ないので双方に出てくるので、それぞれ対応する時間を$t_1$と$t^\\prime_1$として、 時間のオフセット$t_1 - t^\\prime_1$を計算すると、原曲と聞かせた曲のスタート位置の差である定数になるはずです。\nハッシュが一致した時に、原曲と聞かせた曲で見つかった時間のプロットを見たほうが早いと思います。\n曲が一致している場合は上のようにマッチしたハッシュが傾き1の直線の上に並びます。 線から外れている点は、間違ってマッチングしてしまった点です。\n逆に曲が一致していない場合であれば、間違ってハッシュがマッチングしてしまったとしても時間の差はランダムに分布することが予想されます。\nあとで具体例を見せますが、時間のオフセットをヒストグラムにすると、マッチングしている場合は単一のピークが出現します。 理屈としては単純ですが鮮やかな手法で、これを最初に考えた人は頭いいですね。\nもっと詳しく知りたくなった方は原論文 A.WangのAn Industrial-Strength Audio Search Algorithm を読んでください。\nJuliaで実装 本格的にShazamのようなマッチングを実現しようとすれば、 大量の楽曲データをfingerprintして、ハッシュデータをデータベースに格納して、 曲の認識の際はデータベースからの検索を行ってスコアリングし、最も類似度が高い曲を提示する、という処理が必要になると思います。\n今回は、基本原理を調べて実装する段階で力尽きてしまったので、核となるfingerprintとマッチングできた場合・出来なかった場合のシグナルの可視化に絞って行いたいと思います。\nコードは(Pythonですが)、worldveil/dejavuのfingerprint.pyを参考にしました。\nWAVファイル WAVファイルの読み込みは WAV.jl を使います。 詳細はここ を見てください。\njulia\u0026gt; using WAV julia\u0026gt; ys, fs, _, _ = wavread(\u0026#34;test/data/original.wav\u0026#34;) ([-0.44181646168401134 -0.40189825128940704; -0.43061616870632036 -0.3761101107821894; … ; 0.17578661458174383 -0.04297006134220405; 0.1151768547624134 -0.1497848445081942], 44100.0f0, 0x0010, WAVChunk[WAVChunk(Symbol(\u0026#34;fmt \u0026#34;), UInt8[0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x02, 0x00, 0x44, 0xac, 0x00, 0x00, 0x10, 0xb1, 0x02, 0x00, 0x04, 0x00, 0x10, 0x00])]) スペクトログラム 今回は簡単のため、スペクトログラムは DSP.jl を使って作りましょう。\nDSP.Periodograms.spectrogramのドキュメンテーション はかなり簡素なので matplotlib.mlab.specgram や scipy.signal.spectrogram も参照したりしていました。\nspectrogram が返す Spectrogram オブジェクトからスペクトログラムの2次元配列を取得するには .power でアクセスすれば良いです。\nusing DSP function songspectrogram(samples, n, fs) spec = spectrogram(samples, n; fs = fs, window = DSP.Windows.hanning).power normspec = log10.(spec) return normspec end julia\u0026gt; n = 4096 4096 julia\u0026gt; songspectrogram(ys[:, 1], n, fs) 2049×284 Array{Float64,2}: -9.70616 -9.07873 -9.17428 -7.92614 -7.63062 -8.47055 … -9.40998 -8.13383 -7.47217 -9.79269 -9.69248 -9.65601 -8.32769 -8.22531 -6.85743 -6.56021 -6.97262 -7.67239 -7.66505 -6.78739 -6.7776 -7.62074 -7.43576 -8.01717 -8.03 -7.558 -5.53623 -5.9818 -6.17798 -7.68783 -6.94568 -5.43333 -5.61844 -6.74417 -8.42553 -7.95556 -5.43267 -5.78585 -4.39696 -4.4776 -5.94032 -5.69941 -6.9579 -4.4222 -4.48091 -7.12551 -6.49895 -6.33804 -4.77574 -4.66916 -3.62902 -4.67299 -4.92199 -4.97365 -5.47771 -3.91721 -3.9714 -5.75402 -5.86911 -6.84826 -4.4678 -4.45818 -3.10731 -3.27021 -4.21703 -4.90298 … -4.07139 -4.17006 -4.64172 -5.11589 -5.22632 -4.74766 -3.58357 -3.90762 -2.7872 -3.43402 -4.40083 -5.44588 -3.23751 -3.09109 -3.55516 -3.60761 -3.69366 -3.61307 -3.80939 -4.70587 -2.69206 -4.20379 -4.66742 -6.45696 -3.87312 -3.02429 -3.4179 -3.71929 -3.72232 -3.55507 -3.26219 -3.08835 -2.81918 -3.87016 -4.02507 -4.6202 -3.44302 -3.35965 -4.34106 -4.80432 -5.04157 -4.25322 ⋮ ⋮ ⋱ ⋮ -12.6353 -12.9023 -10.7465 -12.6273 -15.0526 -11.7402 -11.5892 -12.8856 -11.8646 -11.332 -12.3234 -12.8574 -13.0681 -12.2647 -10.8669 -12.1085 -12.4588 -11.9597 -13.332 -13.1384 -11.9654 -12.3453 -11.8526 -14.436 -12.4502 -12.5558 -10.7107 -12.4894 -11.7158 -11.8924 -11.7527 -12.745 -12.8113 -12.007 -13.0835 -12.283 -11.849 -11.9355 -10.6198 -11.6698 -11.7177 -11.8629 -11.4374 -12.7903 -12.5631 -12.7018 -11.7313 -12.4594 -11.8144 -12.0432 -10.7412 -11.8539 -13.1211 -12.3507 … -11.5013 -11.6661 -12.4602 -12.5109 -11.4371 -12.5457 -11.9763 -11.1635 -10.687 -13.7323 -12.827 -11.7099 -11.7457 -12.372 -12.088 -12.1428 -11.8306 -12.9932 -11.5124 -11.445 -10.5719 -11.9994 -11.9061 -11.9427 -11.5007 -12.151 -13.2719 -11.2705 -12.2111 -12.879 -12.8636 -14.4831 -10.7474 -12.3807 -12.008 -13.2068 -11.5433 -12.7996 -13.0267 -11.3213 -12.6664 -13.6277 最大値フィルター Scipyのscipy.ndimage.maximum_filter に該当するフィルターが見つからなかったので、下のように最大値フィルターを構成します。\nfunction maxfilter(matrix, filtersize) temp, result = zero(matrix), zero(matrix) n1, n2 = size(matrix) for i in 1:n1 imin = max(i - filtersize, 1) imax = min(i + filtersize, n1) temp[i, :] = maximum(view(matrix, imin:imax, :), dims=1) end for j in 1:n2 jmin = max(j - filtersize, 1) jmax = min(j + filtersize, n2) result[:, j] = maximum(view(temp, :, jmin:jmax), dims=2) end return result end julia\u0026gt; x = [0.94 0.54 0.67 0.48 0.10; 0.77 0.98 0.54 0.63 0.32; 0.83 0.54 0.57 0.96 0.50; 0.56 0.40 0.79 0.69 0.43; 0.47 0.61 0.10 0.18 0.88] 5×5 Array{Float64,2}: 0.94 0.54 0.67 0.48 0.1 0.77 0.98 0.54 0.63 0.32 0.83 0.54 0.57 0.96 0.5 0.56 0.4 0.79 0.69 0.43 0.47 0.61 0.1 0.18 0.88 julia\u0026gt; maxfilter(x, 1) 5×5 Array{Float64,2}: 0.98 0.98 0.98 0.67 0.63 0.98 0.98 0.98 0.96 0.96 0.98 0.98 0.98 0.96 0.96 0.83 0.83 0.96 0.96 0.96 0.61 0.79 0.79 0.88 0.88 julia\u0026gt; maxfilter(x, 2) 5×5 Array{Float64,2}: 0.98 0.98 0.98 0.98 0.96 0.98 0.98 0.98 0.98 0.96 0.98 0.98 0.98 0.98 0.96 0.98 0.98 0.98 0.98 0.96 0.83 0.96 0.96 0.96 0.96 ピークを探す 次にmaxfilterをかけて得られた行列からピーク(実際には局所的なピークなわけですが)を取得します。 ピークを求めるときに背景部分は排除しています。\nfunction getmaskindex(mask) maskindex = getindex.(findall(mask), [1 2]) freqs = maskindex[:, 1] times = maskindex[:, 2] return collect(zip(times, freqs)) end function findpeaks(matrix, filtersize) maxmatrix = maxfilter(matrix, filtersize) maxmask = maxmatrix .== matrix nobackground = matrix .!= minimum(matrix) return getmaskindex(maxmask .* nobackground) end julia\u0026gt; findpeaks(x, 1) 3-element Array{Tuple{Int64,Int64},1}: (2, 2) (4, 3) (5, 5) julia\u0026gt; y = zeros(5, 6); y[2, 2] = 1; y 5×6 Array{Float64,2}: 0.0 0.0 0.0 0.0 0.0 0.0 0.0 1.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 julia\u0026gt; findpeaks(y, 1) 1-element Array{Tuple{Int64,Int64},1}: (2, 2) dejavuではピークに出現させたくない箇所のマスクを作成する際に、背景を抽出した後 scipy.ndimage.binary_erosion を使って領域の内部を取得して作成、と言う手順を取っているのですが、このようにする意味はよくわかりませんでした。\n余談ですがこのようなMathematical morphologyの操作は JuliaではImageMorphology.jlを使うとできます。 Scipyのscipy.ndimage.generate_binary_structureみたいに近傍の構造を指定する機能はなさそうです。\nハッシュを生成 次にピークの集合のペアリングを行った後、ハッシュを作成します。 全ての組み合わせてペアを作ると大変なので、各ピークに対してfanvalue個先までのピークをチェックし、 時間、周波数の位置の差分がそれぞれtimerange, freqrange(これらはPair{Int64}の元とします)に入っていたらペアリングすることにしましょう。\nハッシュは標準ライブラリSHAで生成出来ます。\nusing SHA function paringpeaks(peaks, fanvalue, timerange, freqrange) data = Vector{NTuple{4, Int64}}() ntimes = Base.length(peaks) # println(peaks) mintdelta, maxtdelta = timerange minfdelta, maxfdelta = freqrange for (i1, (t1, f1)) in pairs(IndexLinear(), peaks) for i in 1:fanvalue i2 = i1 + i i2 \u0026gt; ntimes \u0026amp;\u0026amp; break t2, f2 = peaks[i2] dt = t2 - t1 df = f2 - f1 (mintdelta \u0026lt;= dt \u0026amp;\u0026amp; dt \u0026lt;= maxtdelta \u0026amp;\u0026amp; minfdelta \u0026lt;= df \u0026amp;\u0026amp; df \u0026lt;= maxfdelta) || continue push!(data, (f1, f2, dt, t1)) end end return data end function hashpeaks(peaks, fanvalue, timerange, freqrange) hashdict = Dict{String, Int64}() pairs = paringpeaks(peaks, fanvalue, timerange, freqrange) for (f1, f2, dt, t1) in pairs info = \u0026#34;$f1|$f2|$dt\u0026#34; hash = bytes2hex(sha256(info)) hashdict[hash] = t1 # println(\u0026#34;($t1, $f1) - ($t2, $f2), $info [$hash] -\u0026gt; $t1\u0026#34;) end return hashdict end julia\u0026gt; peaks = [(1, 5), (2, 3), (2, 4), (3, 2), (4, 2), (4, 4), (6, 4)] 7-element Array{Tuple{Int64,Int64},1}: (1, 5) (2, 3) (2, 4) (3, 2) (4, 2) (4, 4) (6, 4) julia\u0026gt; fanvalue = 2 2 julia\u0026gt; timerange = 0 =\u0026gt; 1 0 =\u0026gt; 1 julia\u0026gt; freqrange = -3 =\u0026gt; 3 -3 =\u0026gt; 3 julia\u0026gt; hashdict = hashpeaks(peaks, fanvalue, timerange, freqrange) Dict{String,Int64} with 8 entries: \u0026#34;db724d0a500003163dce50a08d4cb5199d837df32ff9bea778229f6f89e0ec49\u0026#34; =\u0026gt; 2 \u0026#34;9fc7745cc33e507d9ad28f16e9bd8d717b0de72ed078424da70292feb19248e4\u0026#34; =\u0026gt; 1 \u0026#34;3533f2977e2cb6bb57e7135baff39dbb15e418fa6e7841216ebb6979110a5da4\u0026#34; =\u0026gt; 2 \u0026#34;fe812d99d40bccea0f739ed5716d6f77af15b68fc73190b56bd11d579b7ed5d7\u0026#34; =\u0026gt; 2 \u0026#34;798fb293c5fce0ad4b6c4405d361322ada948757accfbfb43c79b094702c419f\u0026#34; =\u0026gt; 1 \u0026#34;8b0bbed14dafb6086bf675ee4fe2ab1e3a33a79bcc45f990918ba5cb24f12089\u0026#34; =\u0026gt; 3 \u0026#34;1c22c9113f4f50934e03ac63bf365ddebfb220f6af556f6dd31ee9c8be4eb619\u0026#34; =\u0026gt; 3 \u0026#34;c241ae9f10dd86f58a0c97363f4de1f08d10e3b0dae3cf139efd6027f2c75482\u0026#34; =\u0026gt; 4 曲をフィンガープリント 今までの準備で部品は揃ったので、あとはつなげていくだけです。 今回は左右それぞれのチャンネルで独立にフィンガープリントして合体させています。 フィンガープリントの結果を可視化したくなったので、fingerprint_songに関連するコードが入っています。 長い時間の曲データのフィンガープリントの結果を可視化するのには時間がかかるのでご注意ください。\nusing Plots function fingerprint(samples, n, fs, filtersize, fanvalue, timerange, freqrange) spec = songspectrogram(samples, n, fs) peaks = findpeaks(spec, filtersize) hashdict = hashpeaks(peaks, fanvalue, timerange, freqrange) return hashdict end function fingerprint_song(ys, fs, n, filtersize, fanvalue, timerange, freqrange; path = nothing) hashdict = Dict{String, Int64}() for i in 1:size(ys, 2) samples = view(ys, :, i) if !isnothing(path) spec = songspectrogram(samples, n, fs) peaks = findpeaks(spec, filtersize) pairs = Hanauta.paringpeaks(peaks, fanvalue, timerange, freqrange) heatmap(spec) for (f1, f2, dt, t1) in pairs plot!([t1, t1 + dt], [f1, f2], label=\u0026#34;\u0026#34;, linecolor=:blue) end scatter!(peaks, label=\u0026#34;\u0026#34;) output = path * \u0026#34;_ch$i.png\u0026#34; savefig(output) end newdict = fingerprint(samples, n, fs, filtersize, fanvalue, timerange, freqrange) merge!(hashdict, newdict) end return hashdict end マッチングさせてみる 以上でWAVファイルからフィンガープリントを作成することができるようになったので、実際にマッチングできることを確かめてみます。 元のWAVにホワイトノイズを加えたデータや、スピーカーで曲を再生したものをiPhoneのボイスメモで録音してWAVファイルに変換したものでマッチングできることを確認します。\nサンプル曲として、Windows 95のCD-ROMにビデオが収録されていたことでも知られる WeezerのBlue Albumに収録されている Buddy Hollyを使うことにします。 原曲データは本当はCDからWAVファイルとしてリッピングした方が良いと思うのですが、 再度リッピングするのが面倒だったので以前リッピングしたAACファイルをiTunesでWAV形式に変換して原曲データとしました。まあ大丈夫でしょう。\n「聞かせた」時のデータですが、今回は2種類を試してみました。一つは原曲データにホワイトノイズを加えたもの(編集にはAudacityを使いました)と、 もう一つはより実践的なサンプルとして、原曲データをスピーカーで再生し、iPhoneのボイスメモ機能を使って録音し、 コンピューターに転送してMP4からWAVファイルに変換したものです。時間は13秒程度です。\nノイズを加える際は、Amplitudeが0.4と普通に聞いてかなり邪魔に感じるレベルのノイズを加えました。 以下のコードで原曲とオリジナル曲のハッシュのマッチング結果の図示を行います。\nusing Plots using Measures function plot_fingerprint(input, n, filtersize, fanvalue, timerange, freqrange) ys, fs, _, _ = wavread(input) # ysview = view(ys, 100000:300000, :) ysview = ys path, _ = splitext(input) return fingerprint_song(ysview, fs, n, filtersize, fanvalue, timerange, freqrange; path = path) end function hashmatching(hash1, hash2) i = 0 ts1 = Vector{Int64}() ts2 = Vector{Int64}() for h in keys(hash2) if haskey(hash1, h) t1, t2 = hash1[h], hash2[h] push!(ts1, t1) push!(ts2, t2) i += 1 end end println(\u0026#34;Match: $i\u0026#34;) if i \u0026gt; 0 scatter(ts1, ts2, label=\u0026#34;\u0026#34;, margin=5mm) savefig(joinpath(@__DIR__, \u0026#34;output/scatter.png\u0026#34;)) tsdiff = ts1 .- ts2 histogram(tsdiff, label=\u0026#34;\u0026#34;, bins=50, margin=5mm) savefig(joinpath(@__DIR__, \u0026#34;output/hist.png\u0026#34;)) end end n = 4096 filtersize = 10 fanvalue = 50 timerange = 1 =\u0026gt; 20 freqrange = -200 =\u0026gt; 200 input1 = joinpath(@__DIR__, \u0026#34;data/04 Buddy Holly.wav\u0026#34;) input2 = joinpath(@__DIR__, \u0026#34;data/noise_added.wav\u0026#34;) hash1 = plot_fingerprint(input1, n, filtersize, fanvalue, timerange, freqrange) hash2 = plot_fingerprint(input2, n, filtersize, fanvalue, timerange, freqrange) hashmatching(hash1, hash2) まずはWAVファイルにノイズを加えたものの比較結果を見ましょう。横軸は原曲ファイルの時間、縦軸は比較対象ファイルの時間です。 点を画面に納める都合上アスペクト比率は1ではないです。 時間のオフセットのヒストグラムも見てみましょう。 ノイズの影響は受けつつもヒストグラムに単一のピークが認められました。\n次にスピーカーから流した音をiPhoneで録音して試したところ、こちらはなぜかうまくいきませんでした。 何が原因なのか分からずかなり時間を使ってしまったのですが、ピークをプロットした点の画像を重ねてやっと原因がわかりました。\n原因はサンプリング周波数の差で、音楽CDのサンプリング周波数は44.1kHzであるため、 CDからリッピングしたWAVファイルのサンプリング周波数も同じく44.1kHzになりますが、 iPhoneのボイスメモで録音したサウンドのサンプリング周波数は48kHzだったのが原因でした。\n録音した音声ファイルを、Audacityでサンプリング周波数を変えてもう一度試してみます。\n今度は上手く出来ました。\n念のため全然関係ない曲だとマッチングできないことも確かめておきましょう。 本当は大量の曲を予め解析しておいて、実際に検索できることを確かめる必要があると思いますので手抜きです。\nなお、曲は適当に15秒程度にトリミングしています。\nBlue Album一曲目のMy Name Is Jonas\nCandy ClawsのPangaea Girls (Magic Feeling)\nシュガー・ベイブの DOWN TOWN\n誤ってマッチングしているハッシュが思いの外多いですが、ヒストグラムを見ると時間のオフセットはばらつきがあり特徴的な単一のピークはありません。\nハイパーパラメーターを調整して無駄なマッチ数を減らす、バックグラウンドを上手に除去するなど、 改良の余地はまだまだありそうですが、今回はここまでとします。\nあまり綺麗ではないですが、コードは下に置いておきます。\nhttps://github.com/matsueushi/AudioFingerprinting\n参考 Wang, A. (2003, October). An industrial strength audio search algorithm. In Ismir (Vol. 2003, pp. 7-13). Acoustic fingerprint (Wikipedia, The Free Encyclopedia.) The Basics of Audio Fingerprinting Audio Fingerprinting with Python and Numpy Shazamのしくみをちょっと理解してみる worldveil/dejavu JuliaDSP/DSP.jl 【Audacity】サンプリングレートを変換する方法 ",
    "permalink": "https://matsueushi.github.io/posts/audiofingerprinting/",
    "tags": [
      "Julia",
      "Shazam",
      "Spectrogram",
      "AudioFingerprinting"
    ],
    "title": "JuliaでAudio Fingerprintingを実装 - Shazamの仕組みを理解する"
  },
  {
    "contents": "NANORAY / DOGWALK2000\nTILT by NANORAY tamanaramen- angelnumber Tempalay - 革命前夜\nvalknee + ANTIC - 人生最高のSSS (MV) NENAIKO DAREDA - 夏の星座にぶら下がってぇ\nNENAIKO DAREDA · 夏の星座にぶら下がってぇ kaho_ss - マヨナカテンション(Midnight High)\nkaho_ss · マヨナカテンション(Midnight High) 全てわたしの所為です。 - †\n全てわたしの所為です。 · † Toccoyaki - Toccoyaki \u0026amp; minasea - きみと逃げる\nToccoyaki · Toccoyaki \u0026amp; minasea - きみと逃げる Yxngxr1 - RockStore Midnight Tokyo 東京の真夜中 \u0026ndash; *°:⋆ₓₒ Deko Menace無 - Ms.Jealousy\nS亜TOH - ガバじゃなきゃ (feat. Ken truths) 豆異℃ - 寒天基地 水中、それは苦しい「保育園落ちた、吉田死ね」MV ",
    "permalink": "https://matsueushi.github.io/playlist/20200801/",
    "tags": [
      "Music"
    ],
    "title": "最近聞いた曲(2020/8/1)"
  },
  {
    "contents": "Array から条件を満たすインデックスを取得する時は、findall を使う。\njulia\u0026gt; ar = collect(1:10).^2 10-element Array{Int64,1}: 1 4 9 16 25 36 49 64 81 100 julia\u0026gt; findall(x -\u0026gt; x % 2 == 0, ar) 5-element Array{Int64,1}: 2 4 6 8 10 2次元の場合\njulia\u0026gt; ar = Bool[0 0 0 0 0; 0 1 0 0 0; 0 0 0 1 0; 0 0 0 0 0; 0 0 0 0 0] 5×5 Array{Bool,2}: 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 julia\u0026gt; findall(ar) 2-element Array{CartesianIndex{2},1}: CartesianIndex(2, 2) CartesianIndex(3, 4) getindex と組み合わせると良い。\njulia\u0026gt; getindex.(findall(ar), [1 2]) 2×2 Array{Int64,2}: 2 2 3 4 ",
    "permalink": "https://matsueushi.github.io/posts/getindex/",
    "tags": [
      "Julia"
    ],
    "title": "numpy.whereのようなことをJuliaでやりたい"
  },
  {
    "contents": "White Ring / Ixc999\nPEOPLE 1 \u0026ldquo;フロップニク\u0026rdquo; （Official Video） 約嗎 - Kimberley Chen 陳芳語 X 薩麥爾 SMY (Prod. 製作俠 Tower da Funkmasta)｜Official Music Video Kanako Wada / SUNDAY BRUNCH\nEmoCosine / Give You My World 【from Lanota】\nEmoCosine · Give You My World 【from Lanota】 ruruna / 이달의 소녀 오드아이써클 (LOONA/ODD EYE CIRCLE) - Girl Front [ruruna edit]\nruruna · 이달의 소녀 오드아이써클 (LOONA/ODD EYE CIRCLE) - Girl Front [ruruna edit] SNA GERE / 悲しき砂漠の罪人　ヒップホップ　ボカロラップ emamouse / でかい人と小さい人\nShin Sakiura, AAAMYYY - NIGHT RUNNING\ndavid prost / 東京2017年新年\ndavid prost · 東京2017年新年 sky - 301G - 亲吻自己在镜子里死去 / Kiss Yourself In The Mirror and Die Crystal Castles - Kept\n",
    "permalink": "https://matsueushi.github.io/playlist/20200714/",
    "tags": [
      "Music"
    ],
    "title": "最近聞いた曲(2020/7/14) "
  },
  {
    "contents": "C.H.O.C.O · Sakura Tange, Kyoko Hikami\nBLACK RHYME MOLLUCAN - KENAPA GANAS ? FT BRAM DJITMAU X ROMO ( OFFICIAL MUSIC VIDEO ) The Mirraz - ダガー(Official Music Video) Earth to G San (feat. Tetsuya Hikita) 夏時間／ゴムバンド Alfa San - waiting for you ♡ilyTOMMY♡ - Cutie\n♡ilyTOMMY♡ · Cutie *ON ITUNES AND SPOTIFY* MAMANG KESBOR - AMER BOaT / Mr.Crowly On The Beach BOaT / Don\u0026rsquo;t You Ever Leave Me\n",
    "permalink": "https://matsueushi.github.io/playlist/20200709/",
    "tags": [
      "Music"
    ],
    "title": "最近聞いた曲(2020/7/8)"
  },
  {
    "contents": "QT - Hey QT CONTACT LENS / 2 THA DAWN KOTO/ことりっぷ 【スペシャルMV】VHSver burbank / Sorry, I Like You HaroinFather - Cutie (prod.coffv) Die Moulinettes / Der Letzte Spieltag\npowaramiu - ドキドキ、ういるす / 生類哀れみの令\npowaramiu · ドキドキ、ういるす / 生類哀れみの令 aminome あみのめ - まぶたを閉じて\naminome あみのめ · まぶたを閉じて 乆 / 盆\n乆 · 盆 ⌘ / wip\n⌘ · wip Nice Guys / Yot Club - Spiral Stairs\nNice Guys · Yot Club - Spiral Stairs 𝐤𝐰𝐰𝐮𝐧𝐝𝐨! / on four wheels.\n𝐤𝐰𝐰𝐮𝐧𝐝𝐨! · on four wheels.",
    "permalink": "https://matsueushi.github.io/playlist/20200703/",
    "tags": [
      "Music"
    ],
    "title": "最近聞いた曲(2020/7/3)"
  },
  {
    "contents": "Aphex Twin のシングル Windowlicker は印象的なジャケット\nやクリスカニンガムのPVが有名ですが、2曲目に収録されている $\\Delta M_i^{-1} = - \\alpha \\sum_{n=1}^N D_i \\left[ n \\right] \\left[ \\sum_{j \\in C \\left[ i \\right]}^{} F_{ji} \\left[ n -1 \\right] + Fext_i \\left[ n^{-1} \\right] \\right]$ (通称 \u0026ldquo;Formula\u0026rdquo;) の楽曲データにRichard J James自身の顔が埋め込まれているということもよく知られた話だと思います。(顔が出てくるのは5:30~)\n上の動画を見ればどんな画像が出てくるかわかるのですが、それでは面白くないので、今回は、CDからリッピングしたWAVファイルからJuliaを使って埋め込まれた顔を抽出してみたいと思います。\nJuliaを含めてサウンドデータを扱ったことがあまりなかったので、今回はその練習も兼ねています。\nJuliaの環境とインストールパッケージは下の通りです。\nroot@801256b1df16:/temp_julia# julia --project _ _ _ _(_)_ | Documentation: https://docs.julialang.org (_) | (_) (_) | _ _ _| |_ __ _ | Type \u0026#34;?\u0026#34; for help, \u0026#34;]?\u0026#34; for Pkg help. | | | | | | |/ _` | | | | |_| | | | (_| | | Version 1.4.2 (2020-05-23) _/ |\\__\u0026#39;_|_|_|\\__\u0026#39;_| | Official https://julialang.org/ release |__/ | (Hanauta) pkg\u0026gt; st Project Hanauta v0.1.0 Status `/temp_julia/Project.toml` [7a1cc6ca] FFTW v1.2.2 [82e4d734] ImageIO v0.2.0 [6218d12a] ImageMagick v1.1.5 [442fdcdd] Measures v0.3.1 [91a5bcdd] Plots v1.4.4 [8149f6b0] WAV v1.0.3 楽曲データは、所有しているCDをWAV形式でリッピングしたものを使います。\nWAVファイルの読み込み まずはデータを読み込んでみます。WAV形式のファイルフォーマットは WAV.jl で読み書きできます。\nusing WAV # load wav y, Fs, nbits, opt = wavread(\u0026#34;wav/02 ΔMi-1=-a ΣDi[n][ΣF ij[n-1]+Fexti[n-1]].wav\u0026#34;) 返り値は4つあり、最初のものはサンプリングデータです。2次元目のサイズが2なのはチャンネル数が二つあることに対応しています。\njulia\u0026gt; y 15302700×2 Array{Float64,2}: -9.15555e-5 -6.1037e-5 3.05185e-5 0.0 0.0 0.000183111 0.0 -0.000152593 -9.15555e-5 0.00021363 0.0 -6.1037e-5 -9.15555e-5 9.15555e-5 3.05185e-5 -3.05185e-5 ⋮ -6.1037e-5 6.1037e-5 -3.05185e-5 -3.05185e-5 -6.1037e-5 3.05185e-5 -6.1037e-5 0.0 3.05185e-5 0.0 -0.000122074 3.05185e-5 9.15555e-5 0.0 -0.000152593 -3.05185e-5 2つ目はサンプリング周波数です。1秒あたりの標本化数を表しており、 サンプリングデータの長さをサンプリング周波数で割ると曲の長さ(6分47秒)になっています。\njulia\u0026gt; Fs 44100.0f0 julia\u0026gt; size(y)[1] ÷ Fs 347.0f0 3つ目はサンプリングビット数を表しており、16ビットで量子化されていることがわかります。\njulia\u0026gt; nbits 0x0010 julia\u0026gt; Int(nbits) 16 4つ目には WAVChank というデータが入っているようなのですが、使い方はよくわかりませんでした。\njulia\u0026gt; opt 1-element Array{WAVChunk,1}: WAVChunk(Symbol(\u0026#34;fmt \u0026#34;), UInt8[0x10, 0x00, 0x00, 0x00, 0x01, 0x00, 0x02, 0x00, 0x44, 0xac, 0x00, 0x00, 0x10, 0xb1, 0x02, 0x00, 0x04, 0x00, 0x10, 0x00]) 音楽CDの規格であるCD-DA では16ビット、44.1KHzでサンプリングされた2チャンネルのデータがCDには記録されていることになっているので、 先ほどリッピングしたWAVファイルのデータを読み込んだ時の情報と一致していますね。\nデータの可視化 Plots.jlを使って各チャンネルを可視化します。\nusing Plots # channel 1 plot(y[1:1000:end, 1], title=\u0026#34;ch1\u0026#34;, label=\u0026#34;\u0026#34;) savefig(\u0026#34;ch1.png\u0026#34;) # channel 2 plot(y[1:1000:end, 2], title=\u0026#34;ch2\u0026#34;, label=\u0026#34;\u0026#34;) savefig(\u0026#34;ch2.png\u0026#34;) 見ただけだと左右のチャンネルのズレはよくわからないですね。\n縦波と横波 そもそもこの波形が何を表しているか分からなくなってしまったのですが、色々調べて 音は空気の密度の変化が振動して伝わっていくことによる縦波で、 縦波は可視化するのが難しいので、基準点からの媒質のずれを用いて横波に変換して表しているということを思い出しました。小学校か中学校で習いましたね。\nxs = -2π:0.2:2π plot(xs, sin.(xs), lw=2, label=\u0026#34;y = sinx(x)\u0026#34;) plot!(xs .+ sin.(xs), lw=1, seriestype=\u0026#34;vline\u0026#34;, label=\u0026#34;\u0026#34;) サイン波の場合、縦波 (オレンジ) と横波 (青) の関係を表すと上のようになり、 横波で値が0になっている点が縦波(疎密波)の疎と密になっている部分に対応しています。\n離散フーリエ変換 離散フーリエ変換は標本点$\\{ x = 0, \\ldots, N-1 \\}$に対し、関数$f(x)$を $$ \\begin{aligned} F(t) = \\sum_{x=0}^{N-1} f(x) \\exp \\left(-i \\frac{2\\pi t x}{N} \\right) \\end{aligned} $$ に写す変換です。\nまずFFTW.jlを利用して $f(x) = \\sin(50 \\cdot 2\\pi \\cdot x) + 0.5 \\sin(80 \\cdot 2\\pi \\cdot x)$ の離散フーリエ変換を求めてみます。scipy.fftのFourier Transformsのチュートリアルを参考にしています。\n# Fourier transform # https://docs.scipy.org/doc/scipy/reference/tutorial/fft.html using FFTW n_sample = 600 spacing = 1.0 / 800.0 xs = range(0.0, n_sample * spacing, length=n_sample) ys = @. sin(50.0 * 2π * xs) + 0.5 * sin(80.0 * 2π * xs) plot(xs, ys) savefig(\u0026#34;twosines.png\u0026#34;) # fft yf = fft(ys) xf = range(0.0, 1.0 / spacing, length=n_sample) plot(xf, 2.0 / n_sample * abs.(yf), title=\u0026#34;fft\u0026#34;, label=\u0026#34;\u0026#34;) savefig(\u0026#34;twosines_fft.png\u0026#34;) # rfft yf = rfft(ys) xf = range(0.0, 1.0 / (2 * spacing), length=(n_sample ÷ 2)) plot(xf, 2.0 / n_sample * abs.(yf[1:end-1]), title=\u0026#34;rfft\u0026#34;, label=\u0026#34;\u0026#34;) savefig(\u0026#34;twosines_rfft.png\u0026#34;) fftとrfftの違いですが、実数関数の高速フーリエ変換を行う場合は、得られる結果は複素共役になっているので fftの最初の$N/2+1$個の要素だけ取り出したのがrfftです。今後はrfftを使っていきます。\njulia\u0026gt; fft(ys) 1025-element Array{Complex{Float64},1}: -0.021546067690054016 + 0.0im -0.009144822218747824 + 0.019494434496893802im -0.011255889003925152 - 0.0037747442427530035im 0.00021303373272217927 + 6.540910469289888e-6im 0.008011104229857957 - 0.004944446609708943im -0.0027504905105466913 - 0.008521501761826233im 0.006452083992530002 - 0.002329259327304883im 0.0012487142795432917 - 0.00400665047994312im ⋮ 0.0018973158062596494 - 0.0015495945378345682im 0.001248714279543291 + 0.0040066504799431205im 0.006452083992530002 + 0.0023292593273048835im -0.0027504905105466965 + 0.008521501761826231im 0.008011104229857955 + 0.0049444466097089395im 0.00021303373272217938 - 6.540910469289725e-6im -0.011255889003925153 + 0.0037747442427530026im -0.009144822218747822 - 0.019494434496893802im julia\u0026gt; rfft(ys) 513-element Array{Complex{Float64},1}: -0.021546067690054016 + 0.0im -0.009144822218747822 + 0.019494434496893802im -0.011255889003925152 - 0.0037747442427530004im 0.00021303373272217986 + 6.54091046929146e-6im 0.008011104229857957 - 0.004944446609708941im -0.002750490510546692 - 0.008521501761826231im 0.006452083992530001 - 0.0023292593273048826im 0.0012487142795432919 - 0.00400665047994312im ⋮ 0.0005688670923895223 - 0.001286209219029025im -0.00010711318682722653 - 0.00023560706166791262im 3.781279114026053e-5 - 0.00021509339265025993im 0.00045924223521861597 + 0.0002559596431659331im 3.076053805043007e-5 - 0.0003691736809030828im 0.0004897414415673067 + 0.00019917744535980088im 0.00020016708413113154 + 0.00021927127231187687im 5.662713730124005e-5 + 6.958061643819614e-5im ハン関数 スペクトログラムを作成する際には、短時間フーリエ変換を行います。 楽曲の周波数の分析をする時には、楽曲データをオーバーラップさせながら一定の区間で区切り、取り出した区間をフーリエ変換します。\nこの際、区切った区間の値が周期的に繰り返されると仮定してフーリエ変換を行うのですが、勝手に選んだwindowの境界で繋がることは期待できないので、周囲で滑らかに0になるような関数をかけて境界で滑らかに繋がるようにします。\n今回はハン関数(Hann function)を使うことにします。 サンプル数が $N + 1$ のとき、ハン関数は $$ \\begin{aligned} w[n] = \\frac{1}{2}\\left[1 - \\cos \\left(\\frac{2\\pi n}{N}\\right) \\right] \\end{aligned} $$ で与えられます。\nusing Statistics # Hann function function hann(n_window) ns = 0:n_window xs_hann = @. 0.5 * (1 - cos(2π * ns / n_window)) xs_hann end plot(0:64, hann(64), title=\u0026#34;Hann function (N=64)\u0026#34;, label=\u0026#34;\u0026#34;) savefig(\u0026#34;hann_function.png\u0026#34;) 切り出したサンプルに対して適用してみるとこんな感じです。\nwindow_size = 1024 xs = 1:window_size+1 signal = mean(y, dims=2) ys = signal[xs] ys_hann = hann(window_size) .* ys plot(xs, ys, label=\u0026#34;Original\u0026#34;) plot!(xs, ys_hann, label=\u0026#34;Filtered\u0026#34;) savefig(\u0026#34;filtered.png\u0026#34;) 適用する前と後で得られるスペクトラムを比較すると、\nxf = 1:(window_size ÷ 2 + 1) yf = rfft(ys) yf_hann = rfft(ys_hann) plot(xf, 2.0 / window_size * abs.(yf), label=\u0026#34;Original\u0026#34;) plot!(xf, 2.0 / window_size * abs.(yf_hann), label=\u0026#34;Filtered\u0026#34;) savefig(\u0026#34;rfft_hann.png\u0026#34;) ハン関数を適用した方が全体的にノイズが低減されているように見えます。\nいよいよスペクトログラムを描く # spectrogram using Measures function spectrogram(window_size, signal) overlap = window_size ÷ 2 data = [] hann_window = hann(window_size) for idx in 1:(window_size - overlap):Base.length(signal) if idx + window_size \u0026gt; Base.length(signal) break end rfft_result = rfft(hann_window .* signal[idx:idx + window_size]) rfft_log = abs.(rfft_result) .^ 2 push!(data, rfft_log) end hcat(data...) end data = spectrogram(window_size, signal) heatmap_data = log.(data[:, end-2000:end-800]) heatmap(heatmap_data, margin=5mm) savefig(\u0026#34;spectrogram_formula.png\u0026#34;) うーん、なんか見た目が微妙ですね。y軸を対数軸にすると\nheatmap(heatmap_data, margin=5mm, yaxis=:log) savefig(\u0026#34;spectrogram_formula_log.png\u0026#34;) となりようやく「顔」に対面できました。\nついでに1曲目のWindowlickerに隠されている螺旋模様も見ましょう。\n# windowlicker y, Fs, nbits, opt = wavread(\u0026#34;wav/01 Windowlicker.wav\u0026#34;) signal = mean(y, dims=2) data = spectrogram(window_size, signal) heatmap_data = log.(data[:, end-900:end-200]) heatmap(heatmap_data, margin=5mm, yaxis=:log) savefig(\u0026#34;windowlicker_log.png\u0026#34;) 今回は以上です。\n参考 横波と縦波 離散フーリエ変換 窓関数を用いる理由 np.fft.fftとnp.fft.rfft Understanding Audio data, Fourier Transform, FFT and Spectrogram features for a Speech Recognition System Implement the Spectrogram from scratch in python What is a Spectrogram? numpyでスペクトログラムによる音楽信号の可視化 The Aphex Face ",
    "permalink": "https://matsueushi.github.io/posts/spectrogram/",
    "tags": [
      "Julia",
      "Spectrogram",
      "FFT",
      "Plots",
      "AphexTwin"
    ],
    "title": "スペクトログラムを作成する"
  },
  {
    "contents": "Planet 1999 - Party (Official Video) Sparkling Tropicana.mp3 (TOBYNOH - Tropicana Sparkling [Seasquid rework] 惑星アブノーマル PV「月夜海水浴」 Lucie,Too - Lucky (Official Music Video) YOASOBI \u0026ldquo;Racing into the Night\u0026rdquo; Official Music Video George Clanton \u0026amp; Nick Hexum - Aurora Summer [Official Audio] Easycome / 夢中にならないで\nEasycome · 夢中にならないで user310895502 / [2015 M3 - 秋] カシワープ[たのちい人生 シ-07a]\nuser310895502 · [2015 M3 - 秋] カシワープ[たのちい人生 シ-07a] INTERNET ORDER / 自動ＡＵＴＯＭＡＴＩＣ\nINTERNET ORDER · 自動ＡＵＴＯＭＡＴＩＣ sundaytube02 / 今夜はフェアリーテール(山瀬まみ)cover\nsundaytube02 · 今夜はフェアリーテール(山瀬まみ)cover バナナムール Bananamour — Matagiki Travel\nバナナムール Bananamour · Matagiki Travel VideoGirl / DC Shoes\nnyankobrq / twinkle night\nデュア・リパ / Good In Bed\n",
    "permalink": "https://matsueushi.github.io/playlist/20200626/",
    "tags": [
      "Music"
    ],
    "title": "最近聞いた曲(2020/6/26)"
  },
  {
    "contents": "パソコンを新調して、再度ウェブサイトを更新しようと思ったらhugoのテーマと新しいバージョンのhugoの相性が悪いのか、更新がうまくいかなくなってしまったのでテーマを変更しました。\nまた更新を再開したいです。\n",
    "permalink": "https://matsueushi.github.io/posts/tokiwa/",
    "tags": [
      "Hugo"
    ],
    "title": "サイトのデザインを変えました"
  },
  {
    "contents": "メモ用です。\n2020/4/14 おぴょうさ - つちのこ饅頭のうた ariom verma - जीने का सही ढंग metro trip - CANDY LOVE 2020/4/6 tamao ninomiya - lonely waves https://tamaoninomiya.bandcamp.com/album/--5\n2020/4/4 Toytown - Not My Chuckadoo https://www.facebook.com/toytowntunes/\nmimippiii - 地雷ちゃん Conditioning Drive - ///　Ｒｅｂｏｏｔ (WINDOWSWAVE) ㄩㄥㄒ尺卂 山卂ᐯ乇 - ｄ　ａ　ｔ　ｉ　ｎ　ｇ　ｇ　ｏ Dynamic Frequency - Daydream (波のスタイルwavestyle96 Remix)\n",
    "permalink": "https://matsueushi.github.io/playlist/20200404/",
    "tags": [
      "Music"
    ],
    "title": "最近聞いた曲(2020/4/4)"
  },
  {
    "contents": "Juliaで丸めモードを指定して浮動小数点数の計算をする(したい) で色々とJuliaの丸めモードについて調べていましたが、今回はその続きです。\nやはりどうしてもJuliaの Float32 や Float64 に対して上付き丸め、下付き丸めを可能な限り正確に安定して行いたくなったので、 「最近点丸めによる方向付き丸めのエミュレート」を参考に、デフォルトの丸めモードのみを使って上付き丸め、下付き丸めをエミュレートするJuliaのパッケージを作成しました。\nRoundingEmulator.jl https://github.com/matsueushi/RoundingEmulator.jl\nRegistratorにも登録したので、\n] add RoundingEmulator でインストールして使えます。\n定義されているのは add, sub, mul, div, sqrt に対して上付き丸め _up と下付き丸め _down と2つと非常なシンプルなものです。\njulia\u0026gt; using RoundingEmulator julia\u0026gt; add_up(0.1, 0.2) 0.30000000000000004 julia\u0026gt; add_down(0.1, 0.2) 0.3 julia\u0026gt; sub_up(-0.1, 0.2) -0.3 julia\u0026gt; sub_down(-0.1, 0.2) -0.30000000000000004 julia\u0026gt; mul_up(0.1, 0.2) 0.020000000000000004 julia\u0026gt; mul_down(0.1, 0.2) 0.02 julia\u0026gt; div_up(1.0, 3.0) 0.33333333333333337 julia\u0026gt; div_up(1.0, 3.0) 0.33333333333333337 julia\u0026gt; sqrt_up(2.0) 1.4142135623730951 julia\u0026gt; sqrt_down(2.0) 1.414213562373095 https://github.com/JeffreySarnoff/FastRounding.jl/blob/03ff386d36aa7de101f22ca740748a31e57942c0/src/FastRounding.jl#L187-L194 の例も正しく計算できていました。\njulia\u0026gt; sqrt_up(3.9036066558023176e-154) 1.9757547053726885e-77 julia\u0026gt; sqrt_down(3.9036066558023176e-154) 1.975754705372688e-77 詳細はレポジトリや ドキュメンテーション を参照して下さい。 Issueやプルリクは大歓迎です。\n基本的には「最近点丸めのみによる方向付き丸めのエミュレート」に沿った実装なので、 エミュレートのロジックについてはそちらを参照してください。\nこれで、上付き丸めや下付き丸めができるようになったので、当初やろうと思っていた区間演算にもチャレンジしてみたいです。\n以下は作成していて気づいた点です。\nadd12, mul12 エクスポートされていない関数ですが、Julia の base/twiceprecision.jl には 加算、乗算のエラーフリー変換の関数 add12 と mul12 が定義されています。 前回言及したオーバーフロー対策もなされていました。\njulia\u0026gt; using Base: add12, mul12 julia\u0026gt; a = 3.5630624444874539e+307 3.563062444487454e307 julia\u0026gt; b = -1.7976931348623157e+308 -1.7976931348623157e308 julia\u0026gt; add12(a, b) (-1.4413868904135704e308, 9.9792015476736e291) julia\u0026gt; add12(b, a) (-1.4413868904135704e308, 9.9792015476736e291) julia\u0026gt; a = 6.929001713869936e+236 6.929001713869936e236 julia\u0026gt; b = 2.5944475251952003e+71 2.5944475251952003e71 julia\u0026gt; mul12(a, b) (1.7976931348623157e308, -1.0027614963959625e291) julia\u0026gt; mul12(b, a) (1.7976931348623157e308, -1.0027614963959625e291) setrounding_raw deprecatedになった setrounding は、強引に\njulia\u0026gt; using Base.Rounding: setrounding_raw, to_fenv julia\u0026gt; 0.1 + 0.2 0.30000000000000004 julia\u0026gt; setrounding_raw(Float64, to_fenv(RoundDown)) 0 julia\u0026gt; 0.1 + 0.2 0.3 julia\u0026gt; setrounding_raw(Float64, to_fenv(RoundUp)) 0 julia\u0026gt; 0.1 + 0.2 0.30000000000000004 julia\u0026gt; setrounding_raw(Float64, to_fenv(RoundNearest)) 0 と呼び出せば使えて、確実に動くことが保証されていないですが、テストを行うにあたっては、Windows, MacOS, LinuxのCIで 自分で計算した値と、setrounding_raw で丸めモードを変更した時の値が等しくなることを特殊な値 (zero(T), floatmax(T), flaotmin(T) など)とランダムにサンプリングした値に対して確かめる、 という方法を現在は取っています。\n確実に正しいことがわかっている入力と出力のペアからテストを作成するのが一番良いと思うのですが、今回はそこまでやっていません。\nSigned zero 符号付きゼロもの符号も含めて正確に再現する場合、下付き丸めによる加算の定義で注意する必要があります。 上付き丸めによる加算は\nfunction add_up(a, b) x, y = add12(a, b) if isinf(x) ifelse(x == typemin(x) \u0026amp;\u0026amp; isfinite(a) \u0026amp;\u0026amp; isfinite(b), -floatmax(x), x) else y \u0026gt; zero(y) ? nextfloat(x) : x end end と定義できますが、下付きの丸めに関しては、0どうしの計算を行った際に符号を変える必要があります。 これは和の合計が0になる計算 (exact zero sum) の挙動が下付き丸めとそれ以外で異なるためです。 IEEE 754の6.3章に下付き丸め(roundTowardNegative)の時のみ、exact zero sumは-0になると書いてあります。 ただ、\\(x + x\\) の符号は \\(x\\) の符号と同じになると定められているので、表にすると、\nRounding \\((+0)+(+0)\\) \\((-0)+(+0)\\) \\((+0)+(-0)\\) \\((-0)+(-0)\\) roundTiesToEven (RoundNearest) \\(+0\\) \\(+0\\) \\(+0\\) \\(-0\\) roundTowardPositive (RoundUp) \\(+0\\) \\(+0\\) \\(+0\\) \\(-0\\) roundTowardNegative (RoundDown) \\(+0\\) \\(-0\\) \\(-0\\) \\(-0\\) このようになります。よって、下のように修正することでゼロの符号を調整しています。\nfunction add_down(a, b) x, y = add12(a, b) if isinf(x) ifelse(x == typemax(x) \u0026amp;\u0026amp; isfinite(a) \u0026amp;\u0026amp; isfinite(b), floatmax(x), x) elseif y \u0026lt; zero(y) prevfloat(x) else ifelse(iszero(x) \u0026amp;\u0026amp; (signbit(a) || signbit(b)), -zero(x), x) end end 計算結果:\njulia\u0026gt; add_up(-0.0, 0.0) 0.0 julia\u0026gt; add_down(-0.0, 0.0) -0.0 julia\u0026gt; add_up(0.0, 0.0) 0.0 julia\u0026gt; add_down(0.0, 0.0) 0.0 julia\u0026gt; add_up(-0.0, -0.0) -0.0 julia\u0026gt; add_down(-0.0, -0.0) -0.0 浮動小数点数をランダムにサンプリングする 全ての浮動小数点数から一様にサンプリングしたい時、rand を普通に呼び出すと \\([0, 1)\\) から一様にサンプリングされます。\nhttps://docs.julialang.org/en/v1/stdlib/Random/index.html#Random-Numbers-1\njulia\u0026gt; rand(Float64, 10) 10-element Array{Float64,1}: 0.6021596191997549 0.8268352152178551 0.22765811638234856 0.3813150107932535 0.49112818878735265 0.6424070543287013 0.27970019663531676 0.7316980433063847 0.5721143543965341 0.24735574564535145 Int64 用の rand を使って乱数を発生させ、reinterpret で Float64 に変換すれば良いです。\njulia\u0026gt; x = rand(Int64) 7738226609100433883 julia\u0026gt; bitstring(x) \u0026#34;0110101101100011101101000001101000100010111010000010100111011011\u0026#34; julia\u0026gt; y = reinterpret(Float64, x) 2.0242815034259582e209 julia\u0026gt; bitstring(y) \u0026#34;0110101101100011101101000001101000100010111010000010100111011011\u0026#34; 細かいことを言うと NaN, Inf なども含まれてしまいますが、今回は特別扱いはせずそのまま使っています。\n== vs isequal Julia でユニットテストを書くとき、\n@test f(x) == 1.0 のように書くことが多いのですが、浮動小数点数のテストの際、NaN や符号付きゼロなどをテストしたい場合は注意が必要です。まず、\njulia\u0026gt; NaN == NaN false です。また、IEEE 754で定められている符号付きゼロ -0.0 と 0.0 は\njulia\u0026gt; bitstring(0.0) \u0026#34;0000000000000000000000000000000000000000000000000000000000000000\u0026#34; julia\u0026gt; bitstring(-0.0) \u0026#34;1000000000000000000000000000000000000000000000000000000000000000\u0026#34; と異なるビット列が対応していますが、== では\njulia\u0026gt; 0.0 == -0.0 true となるのでこの二つの違いは判別できません。 そのため、setrounding をエミュレートできているかをテストする際には、isequal を使いました。\njulia\u0026gt; isequal(1.0, 3.0) false julia\u0026gt; isequal(1.0, 1.0) true julia\u0026gt; isequal(0.0, 0.0) true julia\u0026gt; isequal(0.0, -0.0) false julia\u0026gt; isequal(-0.0, -0.0) true julia\u0026gt; isequal(NaN, NaN) true set_zero_subnormals なかなか変更することは少ないとは思われますが、Juliaには非正規化数が0に変換されることを許容することで計算を高速化する(かもしれない)設定が存在します。\nBase.Rounding.set_zero_subnormals\nBase.Rounding.get_zero_subnormals\n上付き丸め、下付き丸めが必要となっている今回のような状況では当然オフになっている必要があります。\n",
    "permalink": "https://matsueushi.github.io/posts/rounding-emulator/",
    "tags": [
      "Julia",
      "Rounding"
    ],
    "title": "デフォルトの丸めモードで上付き丸め、下付き丸めをエミュレートする(Julia)"
  },
  {
    "contents": "2020/4/14追記 丸めモードについては、デフォルトの丸めモードで上付き丸め、下付き丸めをエミュレートする(Julia) も参照してください。 IntervalArithmeitc.jl のデフォルト丸めモードは、#370 で FastRounding.jl を利用しなくなった (v0.17.0以降) ので、 IntervalArithmeitc.jl に関して以下に書いてある情報は古いです。\n最近、 数値計算を 区間演算 を使って誤差の評価を伴って実施する 精度保証付き数値計算 に興味が出てきて、 Warwich Tucker の Validated Numeric という本を購入し、少しつづ読んでいます。\n浮動小数点数のシステムなど初歩的なことから説明されていて私にとっては非常にありがたく、異常な計算例も多く載せられていて楽しく読めています。 実際に手を動かして理解するために、本文内の MATLAB で書かれた区間演算のプログラムを Julia で実装しようとしていますが、 丸めモードを指定した計算を行うところでつまづいてしまいました。\n今回は、頭の整理を兼ね、具体的な例からスタートし、なぜ丸めモードを指定した計算が必要となるか説明するとともに、 Julia における丸めの制御について調べた内容を書いておきたいと思います。 私はこの分野の専門家ではないので、間違っている場所があれば教えていただけると助かります。\n使用している Julia のバージョンは 1.3.0 です。将来的に丸めの扱いが変更される可能性があるので注意してください。\n_ _ _ _(_)_ | Documentation: https://docs.julialang.org (_) | (_) (_) | _ _ _| |_ __ _ | Type \u0026#34;?\u0026#34; for help, \u0026#34;]?\u0026#34; for Pkg help. | | | | | | |/ _` | | | | |_| | | | (_| | | Version 1.3.0 (2019-11-26) _/ |\\__\u0026#39;_|_|_|\\__\u0026#39;_| | Official https://julialang.org/ release |__/ | 0.1 * 3.0 を計算してみる \\( \\mathbb{F}^* \\) を浮動小数点全体の集合 (今回はFloat64 としておきます)、 \\( \\mathbb{F} \\) を\\( \\mathbb{F}^* \\)から -Inf, +Inf を除いた有限な浮動小数点全体の集合、 \\( \\mathbb{R} \\) を実数全体の集合、\\( \\mathbb{R}^* \\) を \\( \\mathbb{R} \\) に正と負の無限大を付け加えた集合とします (無限大が関係してくる細かい説明は今回は省略します)。 \\( \\mathbb{F} \\) は \\( \\mathbb{R} \\)、 \\( \\mathbb{F}^* \\) は \\( \\mathbb{R}^* \\) の有限部分集合です。\n例として、 \\(0.1 \\in \\mathbb{R} \\) と \\(3.0 \\in \\mathbb{R}\\) の積を (浮動小数点上で) 評価したいとします。 言うまでもなく真の値は \\( 0.3 \\in \\mathbb{R} \\) です。 一方、REPL 上で 0.1 * 3.0 と 0.3 を比較すると、\njulia\u0026gt; 0.1 * 3.0 == 0.3 false となりイコールにはなりません。@printf マクロを使って小数点以下17桁まで表示すると、確かに違います。\njulia\u0026gt; using Printf julia\u0026gt; @printf(\u0026#34;%17.17f\u0026#34;, 0.1 * 3.0) 0.30000000000000004 julia\u0026gt; @printf(\u0026#34;%17.17f\u0026#34;, 0.3) 0.29999999999999999 Base.bitstring を使ってビット表現を確かめても、\njulia\u0026gt; bitstring(0.1 * 3.0) \u0026#34;0011111111010011001100110011001100110011001100110011001100110100\u0026#34; julia\u0026gt; bitstring(0.3) \u0026#34;0011111111010011001100110011001100110011001100110011001100110011\u0026#34; 最後の3桁が違いますね。なぜこのようなことが起こるのでしょうか？\n丸め 証明は省略しますが、\\( 1/3 \\) が有限桁の10進数小数で表現できないのと同様、 \\( 0.1 \\) は有限桁の(2進)浮動小数点数では表せません。\\( 0.3 \\) も同様です。\nそのため、\\( 0.1 \\in \\mathbb{R} \\) はコンピューターで扱うために \\( \\mathbb{F} \\) の元で近似されることになります。 この近似の方法を定めるのが丸め (Rounding) で、書き方は違いますが本の中で次のように定義されています。\n定義 「丸め」 とは、写像 \\( \\bigcirc : \\mathbb{R}^* \\rightarrow \\mathbb{F}^* \\) で、\n(R1) \\( \\bigcirc \\) は \\( \\mathbb{F}^* \\) 上では恒等写像。つまり、任意の \\( x \\in \\mathbb{F}^* \\) に対して \\( \\bigcirc (x) = x \\)\n(R2) \\( \\bigcirc \\) は大小関係を保存する。つまり、\\( x, y \\in \\mathbb{R}^* \\) が \\( x \\le y \\) を満たすなら \\( \\bigcirc(x) \\le \\bigcirc(y) \\) が成立する\nの二つの条件を満たすものである。\n一つ目の条件は \\( \\mathbb{F}^* \\) でもともと表せる数に関しては余計な操作を行わないことを意味し、 二つ目の条件は近似した時に大小関係が入れかわらないことを保証するもので、どちらも非常に自然な要請です。\n丸めにはいくつか種類がありここでは全て紹介できませんが、いくつか基本的な丸めを挙げます。\n$$ \\begin{aligned} \\triangledown (x) = \\max \\{ y \\in \\mathbb{F}^* \\mid y \\le x \\}, \\end{aligned} $$\n$$ \\begin{aligned} \\triangle (x) = \\min \\{ y \\in \\mathbb{F}^* \\mid y \\ge x \\} \\end{aligned} $$ はそれぞれ下付き丸め (Rounded down), 上付き丸め (Rounded up) と呼ばれます。\nこれらは勿論先ほどの丸めの定義を満たし、 $$ \\begin{aligned} \\triangledown (x) \\le x \\le \\triangle (x) \\end{aligned} $$\nが常に成立しています。これと条件 (R1), (R2) を組み合わせることにより、任意の丸め \\( \\bigcirc \\) に対して $$ \\begin{aligned} \\triangledown (x) \\le \\bigcirc (x) \\le \\triangle (x) \\end{aligned} $$\nが成立することがわかります。また、\\( x \\in \\mathbb{F}^* \\) であれば、 \\( \\bigcirc (x) = x = \\triangledown (x) = \\triangle(x) \\) ですし、 \\( x \\notin \\mathbb{F}^* \\) であれば、\\( \\triangledown(x) \u0026lt; x \u0026lt; \\triangle (x) \\) が成り立つとともに \\( \\bigcirc (x) = \\triangledown(x)\\) または \\( \\bigcirc (x) = \\triangle(x)\\) となることも示せます。 つまり、丸めとは、浮動小数点数で表せないそれぞれの数に対して切り上げるか切り下げるかを条件 (R2) を守るように定めることと同じです。\n浮動小数点数で表現できない数に対する Julia のデフォルト丸めモードは RoundNearest で、 最も近い浮動小数に丸めると言うものです。 ちょうど中間になった時が気になりますが、切り上げた時と切り下げた時のうち、最後の桁が偶数 (つまり0) になるものを選びます。 そのためこの丸めモードはNearest Evenと呼ばれることもあります。 なぜ偶数に丸めるかについての説明は省略しますが本には載っているので気になる方は参照してください。\n今後、このデフォルトの丸めを \\( \\square \\) で表すことにします。0.1, 3.0, 0.3 は、 実態はそれぞれ \\( \\square(0.1), \\square(3.0) = 3.0, \\square(0.3) \\in \\mathbb{F}^* \\) だったということになります。\n浮動小数点数同士の演算 次に \\( \\mathbb{R}^* \\) 上の二項演算 \\( +, -, \\times, /, \\sqrt{} \\) とそれに対応する \\( \\mathbb{F}^* \\) 上の二項演算 \\( \\oplus, \\ominus, \\otimes, \\oslash, \\odot \\) の違いを考えます。 本当は四角の囲み文字を使いたかったのですが、ご勘弁ください。ルートの丸文字も出せませんでした。\n問題は \\( +, -, \\times, /, \\sqrt{} \\) を \\( \\mathbb{F}^* \\) に制限しても結果が \\( \\mathbb{F}^* \\) になるとは限らないと言うことです。 例えば、\\( 2^{100}, 1 \\in \\mathbb{F}^* \\) ですが、\\( 2^{100} + 1 \\notin \\mathbb{F}^* \\) です。 Julia には直前、直後の浮動小数点数を計算する関数 prevfloat, nextfloat が存在しますので \\( 2^{100} \\)の次の数を計算してみましょう。\njulia\u0026gt; x = 2.0^100 1.2676506002282294e30 julia\u0026gt; @printf(\u0026#34;%17.17f\u0026#34;, x) 1267650600228229401496703205376.00000000000000000 julia\u0026gt; @printf(\u0026#34;%17.17f\u0026#34;, nextfloat(x)) 1267650600228229682971679916032.00000000000000000 なので、\\( 2^{100} + 1 \\) は確かにこの二つの隙間に落ちてしまっているので表現不能です。計算すると、\njulia\u0026gt; x + 1.0 1.2676506002282294e30 julia\u0026gt; x + 1.0 == x true となって元々の値と同じになっています。\nつまりは計算した結果も丸められているわけですが、ここで丸める前と丸めた後の関係が気になります。 Juliaの Rounding modes を見ると丸めモードは IEEE754 standard に従っていると言うことなので、 規格を本来は参照すべきだと思いますが、ノンメンバーだとPDFを購入するのに$100かかるようなので、断念しました。\n書かれたのは1997年と古いようですが、IEEE 754の策定に携わったKahanのレクチャーノート Lecture Notes on the Status of IEEE Standard 754 for Binary Floating-Point Arithmetic を読むと、四則演算や平方根丸め無しの場合に計算した結果を Nearest Even で丸めるという内容のことが書かれています。 別の本「精度保証付き数値計算の基礎」（これも勢いで購入）にも同様のことが書いてあった (p.p. 17) ので、信じることにします。\nよって、 $$ \\begin{aligned} x, y \\in \\mathbb{F}^*, * \\in \\{ +, -, \\times, /, \\sqrt{} \\} \\end{aligned} $$\nの時に\n$$ \\begin{aligned} x \\circledast y = \\square (x * y) \\end{aligned} $$\nということになります。\n長々と書いてしまいましたが、0.1 * 3.0 \\( = \\square(\\square(0.1) \\times \\square(3.0)) \\), 0.3 \\( = \\square(0.3) \\) なので、0.1 * 3.0 と 0.3 は近い値にはなるものの、\\(\\square(0.1) \\times \\square(3.0) \\neq 0.3\\) でそれぞれ別の数に丸められてしまうということでした。\n区間演算 次に、同様の計算を区間計算で (正確な定義はスキップして) 行ってみます。 まず、\\( 0.1 \\) を含む、端点が共に \\( \\mathbb{F} \\) の元で幅がなるべく小さい区間を探します。\n0.1 と書いた時点で浮動小数点数に変換されてしまうので、別の方法で \\( 0.1 \\) を表現する必要があります。 入力を文字列 \u0026quot;0.1\u0026quot; にしてパースする方法もありますが、 幸いなことに有理数型と丸め方向つきの浮動小数点数コンストラクタが利用できます。\njulia\u0026gt; x_down, x_up = Float64(1//10, RoundDown), Float64(1//10, RoundUp); julia\u0026gt; @printf(\u0026#34;[%17.17f, %17.17f]\u0026#34;, x_down, x_up) [0.09999999999999999, 0.10000000000000001] \\( 3.0 \\) は浮動小数点数として誤差なく表現できるので、幅0 (thin) の区間として表わせます。\njulia\u0026gt; Float64(3//1, RoundDown) == Float64(3//1, RoundUp) true こうして \\( 0.1 \\) と \\(3.0\\) がそれぞれ含まれる区間 [x_down, x_up], [3.0, 3.0] が得られたので答えが取り得る範囲を考えて、真の数が含まれる区間の計算結果を [x_down * 3.0, x_up * 3.0] ……とやると(一般的には)まずいです。\n今回はたまたま\njulia\u0026gt; @printf(\u0026#34;[%17.17f, %17.17f]\u0026#34;, x_down * 3.0, x_up * 3.0) [0.29999999999999999, 0.30000000000000004] となってうまくいきましたが、例えば、 \\( 1.0 \\in \\mathbb{F}, 2^{-54} \\in \\mathbb{F} \\) に対し、 \\( 1.0 + 2^{-54} \\) を意図して同様の区間演算 [1.0, 1.0] + [2^-54, 2^-54] を先ほどと同様に単純に行うと、\njulia\u0026gt; @printf(\u0026#34;%17.17f\u0026#34;, 1.0 + 2^-54) 1.00000000000000000 julia\u0026gt; 1.0 + 2^-54 == 1.0 true と \\( 2^{-54} \\) が \\( 1 \\) に対して小さすぎて桁落ちが発生し、 得られる区間は [1.0, 1.0] となってしまい正しい答えである \\( 1.0 + 2^{-54} \\) は含まれません。\nつまり、今までに定義した記号を使って表すと、\n$$ \\begin{aligned} [x, y] + [x\u0026rsquo;, y\u0026rsquo;] = [x \\oplus x\u0026rsquo;, y \\oplus y\u0026rsquo;] \\end{aligned} $$\nと定義してしまってはダメで、\n$$ \\begin{aligned} [x, y] + [x\u0026rsquo;, y\u0026rsquo;] = [\\triangledown (x + x\u0026rsquo;), \\triangle (y + y\u0026rsquo;)] \\end{aligned} $$\nと計算して答えが確実に含まれるようにする必要があります。ここで必要となるのは、デフォルトの丸めモードとは異なる丸めモードを用いた加算です。\n非常に長くなってしまいましたが、この計算をやりたいがために丸めモードを変えたいわけです。\nJulia における方向丸め付き演算のサポート 「さあ、いよいよ Julia で方向丸め付き演算をやっていくか、C++だと丸めモードの変更は面倒な感じがする が、 Julia には Base.Rounding.setrounding という関数が用意されていて楽すぎる。Julia最強！」\n……とはならないのが人生の辛い所です。\nsetrounding の説明をよく読むと、T == BigFloat しかサポートされていないと書かれています。 実は昔は Float32, Float64 に対しても使えていたようなのですが、 色々と問題があり(最後のリンク参照)、 experimentalと言う但し書きがドキュメントに書かれるようになり、 最終的に廃止されたようです。\nそのためブログの記事や Twitter の投稿で「Juliaでは浮動小数点の方向丸め付き演算がサポートされている」と書かれているものは、おそらく、 Float32, Float64 に対する setrounding が使えるようになっていた時のものでしょう。\nサポートされていない理由については、どうもLLVMで浮動小数点の丸めの制御ができないため、と言うことらしいです(未確認)。\nJulia で利用できるパッケージ 一方、Juliaには区間演算のライブラリ IntervalArithmetic.jl があり、頻繁にアップデートされています。 丸めは FastRounding.jl の機能を使っているようでした。\n他にも DirectedRoundings.jl や SetRounding.jl を発見しましたが、あまりメンテされていないようでした。\n最近点丸めによる方向付き丸め演算のエミュレート 言語でサポートされていない方向付き丸めがパッケージを使えばできるということで意味がわからなくなってしまったのですが、 FastRounding.jl は、ErrorfreeArithmetic.jl で実装されているエラーフリー変換と言うものを用いて、 デフォルトの丸めモードの演算のみを利用して方向付き丸めをエミュレートしているようです。\nエミュレートの基本原理に関しては、 最近点丸めによる方向付き丸めのエミュレート に詳細に書いてあるのですが、 ここでは簡単に加算に関して FastRounding.jl が行っているエラーフリー変換とエミュレートについて説明してみたいと思います。\n加算のエラーフリー変換は、別名 twosum とも呼ばれるアルゴリズムで、\\(a, b \\in \\mathbb{F}\\) に対して, ペア \\( (x, y) = \\text{twosum}(a, b) \\) を返し、\n$$ \\begin{aligned} x \u0026amp;= a \\oplus b, \\\\ a + b \u0026amp;= x + y \\end{aligned} $$ が厳密に成立するとされるものです。\nJuliaで書くとほぼ「最近点丸めによる方向付き丸めのエミュレート」に書かれている Python のコードと変わらず、\nfunction twosum(a, b) x = a + b tmp = x - a y = (a - (x - tmp)) + (b - tmp) x, y end となります。 私が確認したタイミングでは、ErrorfreeArithmetic.jl の two_sum の定義も同様になっていました。\n今まで出てきた例の場合も含めて何通りか例を計算してみると\njulia\u0026gt; twosum(0.1, 0.2) (0.30000000000000004, -2.7755575615628914e-17) julia\u0026gt; 2.0^100 1.2676506002282294e30 julia\u0026gt; twosum(2.0^100, 1.0) (1.2676506002282294e30, 1.0) julia\u0026gt; 2^-54 5.551115123125783e-17 julia\u0026gt; twosum(1.0, 2^-54) (1.0, 5.551115123125783e-17) となって正しく分解されています。\n\\(a, b \\) の絶対値について条件を課したアルゴリズム fasttwosum について、 オーバーフローが発生しない場合に等式が成立することが「精度保証付き数値計算の基礎」に定理2.5として証明されていました。\ntwosum を用いた方向付き丸め演算のエミューレートは、上付き丸めと下付き丸めを\nfunction add_up(a, b) x, y = twosum(a, b) ifelse(y \u0026gt; 0, nextfloat(x), x) end function add_down(a, b) x, y = twosum(a, b) ifelse(y \u0026lt; 0, prevfloat(x), x) end と定義するもので、FastRounding.jlの対応箇所はここです。\njulia\u0026gt; add_up(2.0^100, 1.0) 1.2676506002282297e30 julia\u0026gt; add_down(2.0^100, 1.0) 1.2676506002282294e30 julia\u0026gt; add_up(1.0, 2^-54) 1.0000000000000002 julia\u0026gt; add_down(1.0, 2^-54) 1.0 見た感じ、良さそうです。FastRounding.jl の関数も呼び出してみます。\njulia\u0026gt; using FastRounding julia\u0026gt; add_round(2.0^100, 1.0, RoundUp) 1.2676506002282297e30 julia\u0026gt; add_round(2.0^100, 1.0, RoundDown) 1.2676506002282294e30 julia\u0026gt; add_round(1.0, 2^-54, RoundUp) 1.0000000000000002 julia\u0026gt; add_round(1.0, 2^-54, RoundDown) 1.0 しかし、これで全て安心とはならず、救われない命があるようなのです……\nエミュレーションにおける問題 Error Free Transformation (EFT) is NOT error-free という記事に、 エラーフリー変換においてオーバーフローやアンダーフローが発生する例や、twosum の乗算バージョンの twoproduct に関して誤差が生じる例が書かれていました。\n気になったので、先ほどの twosum に対して記事に書かれている例を試してみると\njulia\u0026gt; a = 3.5630624444874539e+307 3.563062444487454e307 julia\u0026gt; b = -1.7976931348623157e+308 -1.7976931348623157e308 julia\u0026gt; twosum(a, b) (-1.4413868904135704e308, NaN) となってやはり正しく計算されませんでした。\n「最近点丸めによる方向付き丸めのエミュレート」にはこれを回避する方法が書いてあったので、実装してみます。\nfunction new_twosum(a, b) x = a + b if abs(a) \u0026gt; abs(b) tmp = x - a return x, b - tmp else tmp = x - b return x, a - tmp end end function new_add_up(a, b) x, y = new_twosum(a, b) ifelse(y \u0026gt; 0, nextfloat(x), x) end function new_add_down(a, b) x, y = new_twosum(a, b) ifelse(y \u0026lt; 0, prevfloat(x), x) end 実行結果は、もちろん今まで計算できていたものは同じ結果になり、\njulia\u0026gt; new_twosum(0.1, 0.2) (0.30000000000000004, -2.7755575615628914e-17) julia\u0026gt; new_twosum(2.0^100, 1.0) (1.2676506002282294e30, 1.0) julia\u0026gt; new_twosum(1.0, 2^-54) (1.0, 5.551115123125783e-17) julia\u0026gt; new_add_up(2.0^100, 1.0) 1.2676506002282297e30 julia\u0026gt; new_add_down(2.0^100, 1.0) 1.2676506002282294e30 julia\u0026gt; new_add_up(1.0, 2^-54) 1.0000000000000002 julia\u0026gt; new_add_down(1.0, 2^-54) 1.0 先ほど計算できなかった例が、\njulia\u0026gt; new_twosum(a, b) (-1.4413868904135704e308, 9.9792015476736e291) julia\u0026gt; new_add_up(a, b) -1.4413868904135702e308 julia\u0026gt; new_add_down(a, b) -1.4413868904135704e308 と計算できるようになりました。\nしかしながら ErrorfreeArithmetic.jl の実装も残念ながらオーバーフローが考慮されていないので、\njulia\u0026gt; using ErrorfreeArithmetic julia\u0026gt; two_sum(a, b) (-1.4413868904135704e308, NaN) となり、従ってそれを利用した丸めも\njulia\u0026gt; using FastRounding julia\u0026gt; add_round(a, b, RoundUp) -1.4413868904135704e308 julia\u0026gt; add_round(a, b, RoundDown) -1.4413868904135704e308 と丸めが正しく行われていません。記事に載っていた例については加算しか確認していませんが、他にも似たような現象が発生している可能性があるので利用には注意が必要だと思います。 (ライブラリの作者の方々には申し訳ないですが)\n基本的な演算に関してのエミュレートを行うだけでもかなり気を使う必要があり、漏れなく実装するのは容易ではないようです。\nしかしながら、デフォルトの丸めモードだけを使って方向付き丸めのエミュレートを行う発想自体は非常に面白く感じたので、時間のある時に他の演算に関しても実装してみたいです。 (パッケージとして通用するレベルで厳密な実装やテストを書くのは大変そうですが……)\n結論(2020/3時点) Julia で方向付き丸めを指定した浮動小数点数計算はコア言語としては廃止されているが、エミュレートにより丸めを行うパッケージ FastRounding.jl が存在します。\nしかしながら FastRounding.jl は極端な入力を与えた場合に正しい答えを返さない可能性があり、利用の際には注意が必要、と言う結論になりました。\n長くなりましたが最後に参考資料を載せておきます。\n参考資料、リンク 精度保証付数値計算\nTucker, W. Validated Numerics: A Short Introduction to Rigorous Computations, Princeton University Press, 2011 大石 新一. 精度保証付き数値計算の基礎, コロナ社, 2018 Wikipedia. 精度保証付き数値計算 JuliaIntervals / ValidatedNumerics.jl JuliaIntervals / ValidatedNumerics.jl / Julia rounding problem #165 IEEE 754\nKahan, W. Lecture Notes on the Status of IEEE Standard 754 for Binary Floating-Point Arithmetic Wikipedia. IEEE 754 ”Validated Numerics\u0026quot; の 1.5章 IEEE Computer Society. 754-2019 - IEEE Standard for Floating-Point Arithmetic Julia言語の丸めモード\nIntegers and Floating-Point Numbers \u0026gt; Rounding modes Base.Rounding.setrounding Base.Rounding.RoundingMode JuliaLang / julia / setrounding regression for 0.5.0-rc1 #17926 JuliaLang / julia / what to do with setrounding? #26935 JuliaLang / julia / Deprecate setrounding #27166 o108minmin. JuliaのFloatとRoundingの奇妙な挙動[追記] 方向付き丸めのエミュレート, Error Free Transformation\n柏木 雅英. 最近点丸めによる方向付き丸めのエミュレート 柏木 雅英. 最近点丸めのみによる方向付き丸めのエミュレート Takeshi O, Siegfried R, and Shin\u0026rsquo;ichi O, Accurate Sum and Dot Product, SIAM J. Sci. Comput., 26(6), 1955–1988 (http://www.oishi.info.waseda.ac.jp/%7Eoishi/papers/OgRuOi05.pdf でプレプリントが読める) 「精度保証付き数値計算」の 2.2 章 柏木 雅英. Error Free Transformation (EFT) is NOT error-free JeffreySarnoff / FastRounding.jl JeffreySarnoff / ErrorfreeArithmetic.jl 方向つき丸めのJuliaパッケージ(未調査)\nJeffreySarnoff / DirectedRoundings.jl JuliaIntervals / SetRounding.jl 区間演算\nValidated Numerics の 2章 柏木 雅英. 区間演算の実装について(1) 柏木 雅英. 区間演算の実装について(2) @mod_poppo. 週刊 代数的実数を作る #5 区間演算と計算可能実数 JuliaIntervals / IntervalArithmetic.jl JuliaIntervals / IntervalArithmetic.jl / Bugs with tiny numbers #215 ",
    "permalink": "https://matsueushi.github.io/posts/julia-rounding/",
    "tags": [
      "Julia",
      "Rounding",
      "Float"
    ],
    "title": "Juliaで丸めモードを指定して浮動小数点数の計算をする(したい)"
  },
  {
    "contents": "今回は、Juliaの機械学習フレームワークFlux.jlでSinGAN(一部)を実装して、1枚のアルバムジャケット画像からアニメーションを作成します。結構長いです。\nきっかけは、この紹介記事です。\n【SinGAN】たった１枚の画像から多様な画像生成タスクが可能に\n実はDCGANをFlux.jlで実装したあと、MNISTの画像では味気ないので自分でデータセットを作成して画像の自動生成を試みていましたが、 ダブりなく大量の画像を収集してデータセットを整備するのは骨が折れ、今一つの結果しか出なかったのでお蔵入りにしていました。\nしかしながら、SinGAN記事に関する読んでみると驚いたことにSinGANではたった1枚の画像から超解像化やアニメーション生成が行え、 ハイスペックのGPUを回さなくても結果が得られるということで実装に挑戦したくなりました。\n一部実装を簡略化したので、論文の著者による実装を完全に再現できたわけではないのでご了承ください。 間違っている点・改善すべき点はご指摘頂けると幸いです。\n環境 実行環境はJulia v1.3.0 + Flux.jl v0.10.0 で、GCPのGPU環境(K80)です。\n前回と同様、Dockerによる環境構築ですが、JuliaのパッケージもDockerfileに含めてしまっていた前回と違い、 今回はDockerファイルはcudaのベースイメージ+Juliaのシンプルな構成として、Juliaのパッケージ管理はJuliaのプロジェクト機能を用いました。\n参考にしたのは主に下記のページです。\nJulia でのパッケージの作り方\nJulia v1.0 でユニットテスト\nSinGANのモデルの概略 理論的な部分の詳細は、論文 SinGAN: Learning a Generative Model from a Single Natural Image や 解説記事 に詳しいのでそちらを見ていただきたいのですが、モデルの概要を簡単に説明しておきます。\n論文とは別に公開されている Supplementary Material はハイパーパラメーターや画像のパディング、アニメーションのノイズマップの作り方などが掲載されていて参考になります。\nSinGAN’s multi-scale pipeline, retrieved from SinGAN: Learning a Generative Model from a Single Natural Image\nSinGANの学習は、ピラミッド型の構造になっていて、下のステージから順々に学習を行います。 最初は、小さい画像サイズで全体の構造を学習し、ステージを上がっていくごとに画像サイズを拡大していき、微細な構造を学習します。 各ステージでは通常のGANのようにGeneratorとDiscriminatorを並行して学習させていきます。\nGeneratorやDiscriminatorのネットワークは、特段難しい構成をしているわけではなく、 Conv(3x3)-BatchNorm-LeakyLeRU(0.2) を5層重ねて最後の活性化関数を Generator だったら tanh, Discriminator だったら identity に変えたConvolutional netがベースとなります。 Discriminator はこれで完成で、Generator はもう一手間必要です。\nSingle Scale Generation, retrieved from SinGAN: Learning a Generative Model from a Single Natural Image\nGeneratorの場合、入力には下層のステップで生成された画像+ノイズを与え、 Convolutional net で生成された結果にもう一度下層の生成画像を加えて出力とします。\n論文では Generator \\( G_n \\) は \\(z_n \\) をノイズ、\\(\\tilde{x}_n\\) を第 \\(n\\) 段階の出力画像, \\( \\uparrow^r\\) をスケール \\(r\\) 倍の画像拡大とした時に、\n$$ \\begin{aligned} \\tilde{x}_N \u0026amp;= G_N(z_N), \\\\ \\tilde{x}_n \u0026amp;= G_n(z_n, (\\tilde{x}_{n+1})\\uparrow^r), n \u0026lt; N \\end{aligned} $$ で、Fully convolutional net を \\(\\psi\\) とした時に、\n$$ \\begin{aligned} G(x, z) = (x)\\uparrow^r + \\psi(z + (x)\\uparrow^r) \\end{aligned} $$\nと言っています。実際は一段階前の画像に0パディングを行う(こともある)のでもう少し複雑になりますがあとで説明します。\n損失関数ですが、各ステージで $$ \\begin{aligned} \\min_{G_n} \\min_{D_n} ( \\mathcal{L}{\\text{adv}}(G_n, D_n) + \\alpha \\mathcal{L}{\\text{rec}}(G_n) ) \\end{aligned} $$ を考えるのですが、\\(\\mathcal{L}{\\text{adv}}\\) が Adversarial loss と呼ばれている通常の GAN の損失関数で、 計算するときは全てのステージでノイズを加えながら生成します。 \\(\\mathcal{L}{\\text{rec}}\\) は Reconstruction loss で、最初以外は全てゼロとなる特定のノイズ $$ \\begin{aligned} z^{\\text{rec}} = \\{z_N^{\\text{rec}}, z_{N-1}^{\\text{rec}}, \\ldots, z_0^{\\text{rec}}\\} = \\{z^, 0, \\ldots, 0 \\} \\end{aligned} $$ を一つ学習を通して固定し、縮小した元画像との二乗誤差 $$ \\begin{aligned} \\mathcal{L}_{\\text{rec}, N} \u0026amp;= || G_N(z^) - x_N ||^2, \\\\ \\mathcal{L}{\\text{rec}, n} \u0026amp;= || G_n(0, (\\tilde{x}{n+1}^{\\text{rec}})\\uparrow^r) - x_n ||^2, n\u0026lt;N \\end{aligned} $$ を損失関数とするものです。\n読んでいて一つ疑問に思ったのが出力データの値域です。 モデルでは、画像データを各数値が \\( [-1,1] \\) の範囲に収まる Array として表現しているのですが、 Convolutional Netで tanh を適用した段階では \\( [-1,1] \\) の範囲に収まるものの、 そのあと元の画像を足したらはみ出ることはあり得ます。 ロス関数による制約条件があるため大丈夫なのかもしれませんが……\n実装開始 公式実装の tamarott/SinGAN をベースに、他の実装 FriedRonaldo/SinGAN も時たま参考にしながらやっていきます。\n全部説明するのは大変なので、ポイントに絞って説明します。パッケージは先に色々インポートしておきます。\nusing Adapt using BSON: @load, @save using CuArrays using Flux using Flux: mse, pullback, glorot_normal using Flux.Optimise: update! using JSON using OrderedCollections using Random using Statistics 配列の0、乱数埋め 役立つ関数をいくつか定義しておきます。\nConvolutional Layerに対するFlux.jlの入力データは WHCN の順の array であり、 今回はカラー画像を使うのでチャンネル数は3(アルファチャンネルがないものを今回は使います), バッチサイズは1なので、画像サイズから array のサイズを計算する関数 expand_dim を下のように定義します。\nあとは与えた配列と同じ型 (CPU 環境だったら Array, GPU 環境だと CuArray) で0や乱数で埋めた配列が欲しくなることがあるので、そのための関数も用意します。\nexpand_dim(dim...) = (dim..., 3, 1) zeros_like(T::Type, dims...) = fill!(similar(T, dims...), 0f0) zeros_like(xs::AbstractArray, dims...) = fill!(similar(xs, dims...), 0f0) randn_like(T::Type, dims...) = randn!(similar(T, dims...)) randn_like(xs::AbstractArray, dims...) = randn!(similar(xs, dims...)) Flux.jl では gpu という関数が定義されていて、この関数は CUDA 環境が有効な時に限り オブジェクト (Array など) を CUDA 用のオブジェクト (CuArray など) にコンバートします。(CUDA 環境が有効でない時は何もしません)。逆に Array に変換を行う cpu という関数も存在します。\n普通に zeros や randn を使って gpu で変換してもいいのですが、 Juliaだと関数は型安定である方がいいと言われているので、出力の型が環境に応じて変化する gpu を毎回使うのを防ぐために zeros_like と randn_like を定義しました。\n気になって変換方法について色々試してみたのですが、やはり similar! を使うのが良いのではないかと思います。 https://gist.github.com/matsueushi/be3071f6b6be040dd7ae9e51cf74b1e5\n画像サイズの計算 最下層の画像のサイズ min_size からスタートして、サイズを縦横 scale 倍することを繰り返して最終的なサイズ image_size に拡大していく関数を作ります。 100層も学習することはないと思うので下のような形になっています。\nfunction size_pyramid(scale, min_size, image_size) current_size = min_size pyramid = Vector{Tuple{Int64,Int64}}() for i in 1:100 push!(pyramid, current_size) current_size == image_size \u0026amp;\u0026amp; break current_size = @. floor(Int64, min_size * scale^i) current_size = min.(current_size, image_size) end return pyramid end 中間の Conv 層のチャンネル数は 32 からスタートしてピラミッドを 4 階上がるごとに 2 倍になりますが、128でキャップをかけておきます。\nchannel_pyramid(n_stage) = min.(map(s-\u0026gt;32 * 2^(floor(Int64, s / 4)), 1:n_stage), 128) 画像の拡大、パディング 画像を image_shape の大きさに拡大したあと、周囲を padded_shape の大きさになるまで0で埋める関数を作ります。\nSupplimental Material の \u0026ldquo;Boundary conditions and the effect of padding\u0026rdquo; を見ると Conv 層における0埋めにより画像の四隅の多様性が失われるが、Generator に入力するノイズの周辺をノイズでパディングする (つまり、ノイズ画像の方を大きくする)と軽減されるということなので、今回アニメーションをさせることを考えて0埋めをすることにしました。\nそのため $$ \\begin{aligned} G(x, z) = (x)\\uparrow^r + \\psi(z + (x)\\uparrow^r) \\end{aligned} $$ は少し修正が必要になります。\\(z\\) は \\((x)\\uparrow^r\\) よりも 四方が幅 \\(d\\) だけ大きいように毎回取るようにして、 \\(\\langle \\rangle_d\\) を幅 \\(d\\) の0パディング, \\(\\rangle \\langle_d\\) を幅 \\(d\\) のトリミングとすると、実際にやることは\n$$ \\begin{aligned} G(x, z) \u0026amp;= \\rangle(\\bar{x} + \\psi(z + \\bar{x}))\\langle_d, \\\\ \\bar{x} \u0026amp;= \\langle(x)\\uparrow^r\\rangle_d \\end{aligned} $$ です。定義するのは \\(\\langle(\\cdot)\\uparrow^r\\rangle_d\\) の部分です。\nfunction resize_and_padding(x::Array{Float32,4}, image_shape::Tuple{Int64,Int64}, padded_shape::Tuple{Int64,Int64}) # println(size(x), image_shape, padded_shape) x_large = imresize(view(x, :, :, :, 1), image_shape...) xx = zeros(Float32, expand_dim(padded_shape...)) pad1, pad2 = (@. (padded_shape - image_shape) ÷ 2)[1:2] xx[1 + pad1:image_shape[1] + pad1, 1 + pad2:image_shape[2] + pad2, : , 1] = x_large return xx end function resize_and_padding(x::CuArray{Float32,4}, image_shape::Tuple{Int64,Int64}, padded_shape::Tuple{Int64,Int64}) return cu(resize_and_padding(adapt(Array{Float32}, x), image_shape, padded_shape)) end 関数を Array と CuArray で分けているのは、 画像を拡大するImages.jlの imresize を使うと GPU arrays のスカラー操作が極めて遅いと警告が出るためです。 https://github.com/JuliaGPU/GPUArrays.jl/blob/master/src/indexing.jl#L16 CuArray の場合は一旦 Array に変換して拡大とパディングを行い、 CuArray に戻していますが効果のほどは不明です。\nあとあと各ステージの画像サイズに合わせて元画像を縮小した \\( x_n \\) が必要になります。これを一気に作れる関数を用意します。\nfunction build_image_pyramid(img::AbstractArray, image_shapes::Vector{Tuple{Int64,Int64}}, noise_shapes::Vector{Tuple{Int64,Int64}}) return map((is, ns)-\u0026gt;resize_and_padding(img, is, ns), image_shapes, noise_shapes) end ノイズの作成 Adversarial loss と Reconstuction loss を計算する時に使うノイズ \\(z^{\\text{adv}}, z^{\\text{rec}}\\) をそれぞれ計算する関数 build_noise_pyramid と build_rec_pyramid を生成します。\n学習の状況に応じてステージごとにノイズの分散は変化するので、調節が行えるようにします。\nfunction build_zero_pyramid(xs::AbstractArray, shapes::Vector{Tuple{Int64,Int64}}) return map(s-\u0026gt;zeros_like(xs, expand_dim(s...)), shapes) end function build_noise_pyramid(xs::AbstractArray, shapes::Vector{Tuple{Int64,Int64}}, amplifiers::Vector{Float32}) return map((s, a)-\u0026gt;a * randn_like(xs, expand_dim(s...)), shapes, amplifiers) end function build_rec_pyramid(xs::AbstractArray, shapes::Vector{Tuple{Int64,Int64}}, amplifier::Float32) v = build_zero_pyramid(xs, shapes) randn!(v[1]) v[1] *= amplifier return v end Convolutional block Discriminator, Generator の準備として、Convolutional block \\(\\psi\\) から作っていきます。\nこのような感じで Discriminator, Generator のどちらも使える build_layers を定義しておきます。\n# Re-define leakyrelu function # https://github.com/FluxML/Flux.jl/issues/963 myleakyrelu(x::Real, a = oftype(x / one(x), 0.01)) = max(a * x, x / one(x)) conv_block(in, out) = [ Conv((3, 3), in =\u0026gt; out; init = glorot_normal, pad = (1, 1)), BatchNorm(out), x-\u0026gt;myleakyrelu.(x, 0.2f0) ] function build_layers(n_layers, in_chs, conv_chs, out_chs, σ) layers = conv_block(in_chs, conv_chs) for _ in 1:n_layers - 2 push!(layers, conv_block(conv_chs, conv_chs)...) end tail_layer = Conv((3, 3), conv_chs =\u0026gt; out_chs, σ; init = glorot_normal, pad = (1, 1)) push!(layers, tail_layer) return Chain(layers...) end leakyrelu は NNlib.jl で定義されているので Flux.jl で使えますが、 Float32 の数値における (Zygote.jlの) 微分が Float64 になってしまうので自分で定義します。\nhttps://github.com/FluxML/Flux.jl/issues/963\nhttps://github.com/FluxML/Flux.jl/issues/979\nNNlib.jlに投げたこのプルリクがマージされたら定義し直す必要がなくなる予定です。(CuArrays.jl も修正する必要があるかもしれませんが……) https://github.com/FluxML/NNlib.jl/pull/149\nDiscriminator, Generator いよいよ Discriminator, Generator の定義です。 簡単な Discriminator から作ります。DiscriminatorPyramid に関しては、単に Discriminator を複数個集めて来ただけです。\n\u0026#34;\u0026#34;\u0026#34; DiscriminatorPyramid \u0026#34;\u0026#34;\u0026#34; mutable struct DiscriminatorPyramid{T \u0026lt;: Tuple} chains::T DiscriminatorPyramid(xs...) = new{typeof(xs)}(xs) end build_single_discriminator(n_layers, conv_chs) = build_layers(n_layers, 3, conv_chs, 1, identity) function DiscriminatorPyramid(n_stage::Integer, n_layers::Integer) ds = build_single_discriminator.(n_layers, channel_pyramid(n_stage)) return DiscriminatorPyramid(gpu.(ds)...) end function DiscriminatorPyramid(image_shapes::Vector{Tuple{Int64,Int64}}, n_layers::Integer) DiscriminatorPyramid(Base.length(image_shapes), n_layers) end function Base.show(io::IO, d::DiscriminatorPyramid) print(io, \u0026#34;DiscriminatorPyramid(\u0026#34;) join(io, d.chains, \u0026#34;, \\n\u0026#34;) print(io, \u0026#34;)\u0026#34;) end ノイズ画像を足してレイヤーに通し、出力結果にオリジナルの画像を加えて周囲をトリミングする NoiseConnection (名前は適当)を作ります。 $$ \\begin{aligned} G(x, z) \u0026amp;= \\rangle(\\bar{x} + \\psi(z + \\bar{x}))\\langle_d, \\\\ \\bar{x} \u0026amp;= \\langle(x)\\uparrow^r\\rangle_d \\end{aligned} $$ 上の式で言えば $$ \\begin{aligned} N(\\bar{x}, z) \u0026amp;= \\rangle(\\bar{x} + \\psi(z + \\bar{x}))\\langle_d \\end{aligned} $$\nを計算するレイヤーです。pad は周囲でノイズパディングを行うサイズ \\(d\\) です。 basic.jl の SkipConnection の実装を参考にしました。 https://github.com/FluxML/Flux.jl/blob/e92da0cf850a982c425b83c92d6274174e52b02c/src/layers/basic.jl#L197\n\u0026#34;\u0026#34;\u0026#34; NoiseConnection \u0026#34;\u0026#34;\u0026#34; mutable struct NoiseConnection layers pad::Int64 end @Flux.functor NoiseConnection function (nc::NoiseConnection)(prev::T, noise::T) where {T \u0026lt;: AbstractArray{Float32,4}} pad = nc.pad raw_output = nc.layers(noise + prev)::T + prev return raw_output[1 + pad:end - pad, 1 + pad:end - pad, :, :] end function Base.show(io::IO, nc::NoiseConnection) print(io, \u0026#34;NoiseConnection(\u0026#34;, nc.layers, \u0026#34;, \u0026#34;, nc.pad, \u0026#34;)\u0026#34;) end いよいよ GeneratorPyramid の定義です。\n\u0026#34;\u0026#34;\u0026#34; GeneratorPyramid \u0026#34;\u0026#34;\u0026#34; mutable struct GeneratorPyramid{T \u0026lt;: Tuple} image_shapes::Vector{Tuple{Int64,Int64}} noise_shapes::Vector{Tuple{Int64,Int64}} pad::Int64 chains::T GeneratorPyramid(image_shapes, noise_shapes, pad, xs...) = new{typeof(xs)}(image_shapes, noise_shapes, pad, xs) end build_single_gen_layers(n_layers, conv_chs) = build_layers(n_layers, 3, conv_chs, 3, tanh) build_single_generator(n_layers, conv_chs, pad) = NoiseConnection(build_single_gen_layers(n_layers, conv_chs), pad) function GeneratorPyramid(image_shapes::Vector{Tuple{Int64,Int64}}, n_layers::Integer, pad::Integer = 5) n_stage = Base.length(image_shapes) # receptive field = 11, floor(11/2) = 5 noise_shapes = [2 * pad .+ s for s in image_shapes] ds = build_single_generator.(n_layers, channel_pyramid(n_stage), pad) return GeneratorPyramid(image_shapes, noise_shapes, pad, gpu.(ds)...) end function Base.show(io::IO, d::GeneratorPyramid) print(io, \u0026#34;GeneratorPyramid(\u0026#34;) print(io, d.image_shapes, \u0026#34;, \u0026#34;) print(io, d.noise_shapes, \u0026#34;, \u0026#34;) println(io, d.pad, \u0026#34;, \u0026#34;) join(io, d.chains, \u0026#34;, \\n\u0026#34;) print(io, \u0026#34;)\u0026#34;) end function (genp::GeneratorPyramid)(xs::AbstractVector{T}, st::Integer, resize::Bool) where {T \u0026lt;: AbstractArray{Float32,4}} if st == 0 zeros_shape = resize ? first(genp.noise_shapes) : first(genp.image_shapes) return zeros_like(T, expand_dim(zeros_shape...)) end prev = genp(xs, st - 1, true) out = genp.chains[st](prev, xs[st]) return resize ? resize_and_padding(out, genp.image_shapes[st + 1], genp.noise_shapes[st + 1]) : out end 最後の関数が画像を生成する関数で、xs が与えるノイズ、st が到達したいステージ、resize が生成した後に拡大したいかどうかです。 ステージの添字の数え方は論文とは上下が逆で下から上の順に大きくなっているので注意です。\n損失関数 次に損失関数を定義します。SinGAN のオリジナルの実装では GAN には WGAN-GP を使っているのですが、残念なが自分のスキルでは Gradientを損失条件の中に入れられなかった (損失関数の中にGradientの計算関数を入れると、損失関数の微分が取れなかった) ので、泣く泣く LSGAN に置き換えています。\nfunction discriminator_loss(d_real::AbstractArray, d_g_fake_adv::AbstractArray) real_loss = mse(1f0, mean(d_real; dims = (1, 2))) fake_loss = mse(0f0, mean(d_g_fake_adv; dims = (1, 2))) return real_loss + fake_loss end generator_adv_loss(d_g_fake_adv::AbstractArray) = mse(1f0, mean(d_g_fake_adv; dims = (1, 2))) generator_rec_loss(real_img::AbstractArray, g_fake_rec::AbstractArray) = mse(real_img, g_fake_rec) いちいち0や1をベクトルに直す必要はありません。シンプルに書けていいですね。\nDiscriminator, Generator の更新 損失関数の値を計算し、Discriminator, Generator のパラメーターに関する微分を取ってパラメーターを更新する関数を書きます。\nfunction update_discriminator!(opt, dscr, real_img, g_fake_adv) @eval Flux.istraining() = true ps = params(dscr) grad = gradient(ps) do discriminator_loss(dscr(real_img), dscr(g_fake_adv)) end update!(opt, ps, grad) @eval Flux.istraining() = false end function update_generator!(opt, dscr, gen, real_img, prev_rec, prev_adv, noise_rec, noise_adv, alpha) @eval Flux.istraining() = true ps = params(gen) grad = gradient(ps) do g_fake_rec = gen(prev_rec, noise_rec) d_g_fake_adv = dscr(gen(prev_adv, noise_adv)) generator_adv_loss(d_g_fake_adv) + alpha * generator_rec_loss(real_img, g_fake_rec) end update!(opt, ps, grad) @eval Flux.istraining() = false end ここで、\ngrad = gradient(ps) do discriminator_loss(dscr(real_img), dscr(g_fake_adv)) end この部分はこれと一緒です。(https://docs.julialang.org/en/v1/manual/functions/index.html#man-anonymous-functions-1)\ngrad = gradient(() -\u0026gt; discriminator_loss(dscr(real_img), dscr(g_fake_adv)), ps) gradient の代わりに pullback を使うと微分と同時に関数の値も取得できます。(https://fluxml.ai/Zygote.jl/latest/adjoints/#Pullbacks-1)\nパラメーターの更新後に損失関数の値を返したい場合、例えばこのように書けばOKです。\nfunction update_discriminator!(opt, dscr, real_img, g_fake_adv) @eval Flux.istraining() = true ps = params(dscr) loss, back = pullback(ps) do discriminator_loss(dscr(real_img), dscr(g_fake_adv)) end grad = back(Zygote.sensitivity(loss)) update!(opt, ps, grad) @eval Flux.istraining() = false return loss end 学習 1エポックの学習は次のようになります。 改めて損失関数の値を計算しているので少し無駄になっている気もしますが気にしないでおきます。\nfunction train_epoch!(opt_dscr, opt_gen, st, loop_dscr, loop_gen, dscr, genp, prev_rec, noise_rec, real_img, amplifiers, alpha) # discriminator foreach(1:loop_dscr) do _ noise_adv = build_noise_pyramid(prev_rec, genp.noise_shapes[1:st], amplifiers) g_fake_adv = genp(noise_adv, st, false) update_discriminator!(opt_dscr, dscr, real_img, g_fake_adv) end # generator foreach(1:loop_gen) do _ noise_adv = build_noise_pyramid(prev_rec, genp.noise_shapes[1:st], amplifiers) prev_adv = genp(noise_adv, st - 1, true) update_generator!(opt_gen, dscr, genp.chains[st], real_img, prev_rec, prev_adv, noise_rec, last(noise_adv), alpha) end noise_adv = build_noise_pyramid(prev_rec, genp.noise_shapes[1:st], amplifiers) g_fake_adv = genp(noise_adv, st, false) loss_dscr = discriminator_loss(dscr(real_img), dscr(g_fake_adv)) d_g_fake_adv = dscr(g_fake_adv) loss_gen_adv = generator_adv_loss(d_g_fake_adv) g_fake_rec = genp.chains[st](prev_rec, noise_rec) loss_gen_rec = generator_rec_loss(real_img, g_fake_rec) return loss_dscr, loss_gen_adv, loss_gen_rec end ハイパーパラメーターを入れておく箱を用意して、\nmutable struct HyperParams scale::Float64 # progression scale, \u0026gt; 1 min_size_x::Int64 # minimal image width min_size_y::Int64 # minimal image height img_size_x::Int64 # output image width img_size_y::Int64 # output image height n_layers::Int64 # number of conv layers max_epoch::Int64 # training epochs reduce_lr_epoch::Int64 # reduce learining rate after training `redule_lr_epoch` epochs save_image_every_epoch::Int64 # save generated image every `save_image_every_epoch` epoch save_loss_every_epoch::Int64 # save loss every `save_loss_every_epoch` epoch loop_dscr::Int64 # training steps par descriminator training epoch loop_gen::Int64 # training steps par generator training epoch lr_dscr::Float64 # discriminator learining rate lr_gen::Float64 # generator learning rate alpha::Float32 # rec loss coefficient amplifier_init::Float32 # noise amplifier HyperParams() = new(4/3, 25, 25, 128, 128, 5, 2000, 1600, 500, 100, 3, 3, 5e-4, 5e-4, 50f0, 1f0) end show_dict(hp::HyperParams) = OrderedDict(string(nm) =\u0026gt; getfield(hp, nm) for nm in fieldnames(HyperParams)) image_shapes(hp::HyperParams) = size_pyramid(hp.scale, (hp.min_size_x, hp.min_size_y), (hp.img_size_x, hp.img_size_y)) function setup_models(hp::HyperParams) img_shapes = image_shapes(hp) dscrp = DiscriminatorPyramid(img_shapes, hp.n_layers) |\u0026gt; gpu genp = GeneratorPyramid(img_shapes, hp.n_layers) |\u0026gt; gpu return dscrp, genp end ようやく最終的な train 関数の完成です。(画像を出力するところなどは省いています)。 estimate_noise_amplifier は、一段階前の画像と元画像からノイズの分散を調節する関数です。\nfunction estimate_noise_amplifier(prev_rec::AbstractArray{Float32,4}, real_img::AbstractArray{Float32,4}, pad::Integer, amplifier_init::Float32) prev_rec_crop = @view prev_rec[1 + pad:end - pad, 1 + pad:end - pad, :, :] rmse = sqrt(mse(real_img, prev_rec_crop)) return rmse * amplifier_init end function train!(dscrp::DiscriminatorPyramid, genp::GeneratorPyramid, real_img_p::Vector{T}, hp::HyperParams) where {T \u0026lt;: AbstractArray{Float32,4}} stages = Base.length(genp.image_shapes) amplifiers = Float32[] # fixed noise for rec fixed_noise_rec = build_rec_pyramid(first(real_img_p), genp.noise_shapes, 1f0) fixed_noise_adv = similar(fixed_noise_rec) for st in 1:stages @info \u0026#34;Step $(st)\u0026#34; # reset optimizer opt_dscr = ADAM(hp.lr_dscr, (0.5, 0.999)) opt_gen = ADAM(hp.lr_gen, (0.5, 0.999)) # calculate noise amplifier prev_rec = genp(fixed_noise_rec, st - 1, true) # padded amp = st == 1 ? 1f0 : estimate_noise_amplifier(prev_rec, real_img_p[st], genp.pad, hp.amplifier_init) push!(amplifiers, amp) # add noise for adv fixed_noise_adv[st] = amp * randn_like(prev_rec, expand_dim(genp.noise_shapes[st]...)) save_noise_amplifiers(st, amp) @info \u0026#34;Noise amplifier = $(amp)\u0026#34; @time for ep in 1:hp.max_epoch # reduce learnint rate if ep == hp.reduce_lr_epoch @info \u0026#34;Reduce learning rate\u0026#34; opt_dscr.eta /= 10 opt_gen.eta /= 10 end loss_dscr, loss_gen_adv, loss_gen_rec = train_epoch!(opt_dscr, opt_gen, st, hp.loop_dscr, hp.loop_gen, dscrp.chains[st], genp, prev_rec, fixed_noise_rec[st], real_img_p[st], amplifiers, hp.alpha) end end end アニメーション結果 一応トレーニング関数まで到達したので、具体的な実行方法などは一番最後に載せたレポジトリを見てもらうこととして、とりあえずアニメーションの結果を見せたいと思います。 公式実装のアニメーションで使われている画像を強引に 64x64 にリサイズしたものを使いました。 無理やり 256x256 に引き伸ばすとこんな感じです。 25x25 のサイズからスタートして、64x64 で終了させたのですが、GCP の n1-standard-8 + K80 で一時間弱で学習が終わりました。 今回は Julia サイドで画像だけ吐き出して、アニメーション GIF は ImageMagick で作成しました。\n$ convert -delay 10 -loop 0 img*.png fluxjl-singan_lightning.gif 実際の画像はかなり小さいので、256x256 に拡大するとこんな感じです。 もっと時間をかけて大きい画像まで学習すれば高精細な結果が得られると思います。 アルバムのジャケットをアニメーションさせた結果です。\nまだまだ実装の改良の余地がありそうですが、一応一枚の画像だけを使ってアニメーション画像を作成するモデルを Flux.jl で実装できました。\n詳細な部分も含めた全コードはこちらです。 matsueushi/SinGAN\n",
    "permalink": "https://matsueushi.github.io/posts/fluxjl-singan/",
    "tags": [
      "Julia",
      "DeepLearning",
      "Flux",
      "SinGAN",
      "GAN"
    ],
    "title": "Flux.jlでSinGANを実装する"
  },
  {
    "contents": "2020/3/8 追記: model-zoo(https://github.com/FluxML/model-zoo) にDCGANのモデルが入りました。\n2019/11/29にJuliaの機械学習ライブラリFlux.jlのv0.10.0がリリースされた。 もともとv0.9.0でDCGANのMNISTデータセットから手書き文字画像生成モデルを作成して、今回の変更に合わせてv0.10.0で動かしたのだが、 ここに至るまで色々と苦戦したので、v0.10.0の主な変更点や、自分がつまづいた点を書いておく。\n実装はGitHubのリポジトリ matsueushi/fluxjl-gan を見てほしい。\n環境はGCPのn1-standard-8 + 1 x NVIDIA Tesla K80で、Ubuntu 18.04, Juliaのバージョンは1.3.0を利用。\nDockerで環境構築(GPU) GPUが使えるJuliaのオフィシャルなDocker imageは 現在(2019/12/1)存在しないと思われる。 配布されているようです\n(ひっそり CUDA と Julia が同梱されたコンテナイメージも配布されていたりします…… https://t.co/LE1ducHlWE )(姑息な宣伝) https://t.co/VbS7xcYTTV\n\u0026mdash; やまさき (@yama_k_1101) December 2, 2019 このあたり、GPUのDockerイメージ が利用できるTensorflowが羨ましく感じられる部分ではある。\nJuliaGPUのDockerイメージ JuliaGPU/docker はメンテナンスされていないので、nvidia/cuda のイメージをベースに、Juliaのインストール部分は docker-library/julia を参考にDockerfileを作成。\n# Dockerfile Julia 1.3.0 + CUDA for Flux.jl ARG CUDA=10.0 ARG UBUNTU_VERSION=18.04 FROM nvidia/cuda:${CUDA}-cudnn7-devel-ubuntu${UBUNTU_VERSION} ENV JULIA_PATH=/usr/local/julia ENV PATH=$JULIA_PATH/bin:$PATH ENV JULIA_TAR_ARCH=x86_64 ENV JULIA_DIR_ARCH=x64 ENV JULIA_GPG=3673DF529D9049477F76B37566E3C7DC03D6E495 ENV JULIA_VERSION=1.3.0 ENV JULIA_SHA256=9ec9e8076f65bef9ba1fb3c58037743c5abb3b53d845b827e44a37e7bcacffe8 # Based on https://github.com/docker-library/julia # Copyright (c) 2014 Docker, Inc. # Released under the MIT license # https://opensource.org/licenses/mit-license.php RUN set -eux; \\ apt-get update; \\ apt-get install -y --no-install-recommends curl gnupg dirmngr; \\ rm -rf /var/lib/apt/lists/*; \\ \\ folder=\u0026#34;$(echo \u0026#34;$JULIA_VERSION\u0026#34; | cut -d. -f1-2)\u0026#34;; \\ julia_tar_url=\u0026#34;https://julialang-s3.julialang.org/bin/linux/${JULIA_DIR_ARCH}/${folder}/julia-${JULIA_VERSION}-linux-${JULIA_TAR_ARCH}.tar.gz\u0026#34;; \\ curl -fL -o julia.tar.gz.asc \u0026#34;${julia_tar_url}.asc\u0026#34;; \\ curl -fL -o julia.tar.gz \u0026#34;${julia_tar_url}\u0026#34;; \\ \\ echo \u0026#34;${JULIA_SHA256} *julia.tar.gz\u0026#34; | sha256sum -c -; \\ \\ export GNUPGHOME=\u0026#34;$(mktemp -d)\u0026#34;; \\ gpg --batch --keyserver ha.pool.sks-keyservers.net --recv-keys \u0026#34;$JULIA_GPG\u0026#34;; \\ gpg --batch --verify julia.tar.gz.asc julia.tar.gz; \\ command -v gpgconf \u0026gt; /dev/null \u0026amp;\u0026amp; gpgconf --kill all; \\ rm -rf \u0026#34;$GNUPGHOME\u0026#34; julia.tar.gz.asc; \\ \\ mkdir \u0026#34;$JULIA_PATH\u0026#34;; \\ tar -xzf julia.tar.gz -C \u0026#34;$JULIA_PATH\u0026#34; --strip-components 1; \\ rm julia.tar.gz; \\ \\ # smoke test julia --version # install packages RUN julia -e \u0026#39;import Pkg; \\ Pkg.add([ \\ \u0026#34;BSON\u0026#34;, \\ \u0026#34;Distributions\u0026#34;, \\ \u0026#34;HDF5\u0026#34;, \\ \u0026#34;JLD\u0026#34;, \\ \u0026#34;FileIO\u0026#34;, \\ \u0026#34;ImageMagick\u0026#34;, \\ \u0026#34;Images\u0026#34;, \\ ]); \\ Pkg.add([ \\ Pkg.PackageSpec(name=\u0026#34;Flux\u0026#34;, version=\u0026#34;0.10\u0026#34;), \\ ]); \\ using BSON, Distributions, HDF5, JLD, FileIO, ImageMagick, Images, Flux\u0026#39; CMD [\u0026#34;julia\u0026#34;] CUDAが動く Julia の深層学習フレームワーク Flux.jl の環境構築をDockerで行う． でもっと丁寧に説明されていた(こっちだとソースからビルドしている)。\nv0.9.0ではLoadError: LoadError: UndefVarError: libcudnn not defined #918 などのエラーが発生しCuArrays.jlをv1.3に下げる必要があったのだが、v0.10.0ではそのような心配はないのでいいですね。\nDCGANのモデル作成 GANの仕組み自体の説明は\nはじめてのGAN,\nGANについて概念から実装まで　～DCGANによるキルミーベイベー生成～,\n今さら聞けないGAN（1）　基本構造の理解,\nなどを参照してほしい。(自分も勉強中です……)\nFluxには FluxML/model-zoo という実装を集めたレポジトリが存在し、 v0.9.0で実装する際にはGANに関係したプルリクエスト GAN models #47, Added Condtional GAN and DCGAN tutorial #111 が非常に有用だった。\nしかしながら、後にも触れるが、v0.10.0で、デフォルトの自動微分エンジンをTrackerからZygote.jlに変える大きな変更 がマージされたので、 そのままコピペしただけでは動かないと思われるため要注意。\nネットワーク、ロス関数の構成は TensorflowのDCGANチュートリアル を参考にした。\nnoise_dim = 100 channels = 1 generator = Chain( Dense(noise_dim, 7 * 7 * 256; initW = glorot_normal), BatchNorm(7 * 7 * 256, relu), x-\u0026gt;reshape(x, 7, 7, 256, :), ConvTranspose((5, 5), 256 =\u0026gt; 128; init = glorot_normal, stride = 1, pad = 2), BatchNorm(128, relu), ConvTranspose((4, 4), 128 =\u0026gt; 64; init = glorot_normal, stride = 2, pad = 1), BatchNorm(64, relu), ConvTranspose((4, 4), 64 =\u0026gt; channels, tanh; init = glorot_normal, stride = 2, pad = 1), ) |\u0026gt; gpu discriminator = Chain( Conv((4, 4), channels =\u0026gt; 64, leakyrelu; init = glorot_normal, stride = 2, pad = 1), Dropout(0.25), Conv((4, 4), 64 =\u0026gt; 128, leakyrelu; init = glorot_normal, stride = 2, pad = 1), Dropout(0.25), x-\u0026gt;reshape(x, 7 * 7 * 128, :), Dense(7 * 7 * 128, 1; initW = glorot_normal)) |\u0026gt; gpu function generator_loss(fake_output) loss = mean(logitbinarycrossentropy.(fake_output, 1f0)) return loss end function discriminator_loss(real_output, fake_output) real_loss = mean(logitbinarycrossentropy.(real_output, 1f0)) fake_loss = mean(logitbinarycrossentropy.(fake_output, 0f0)) loss = 0.5f0 * (real_loss + fake_loss) return loss end GANのdiscriminatorは、オリジナルの画像と、Generatorが生成したフェイクの画像を見分ける役割(二値分類)のため、出力層の活性化関数がシグモイド関数、ロス関数がbinarycrossentropyである実装が多いが、 今回はTensorflowの実装同様、出力層には活性化関数を適用せず(恒等写像), ロス関数にlogitbinarycrossentropyを用いた。\nシグモイド関数を\\( \\sigma \\) とすると、\n\\( \\text{binarycrossentropy}(\\hat{y}, y) = -y \\log \\hat{y} - (1 - y) \\log(1 - \\hat{y}), \\\\ \\text{logitbinarycrossentropy}(\\hat{z}, y) = (1 - y) \\log \\hat{y} - \\log(\\sigma(\\hat{z})) \\)\nだから、(\\( y = 0, 1 \\) を代入して確かめることで)\n\\( \\text{binarycrossentropy}(\\sigma(\\hat{z}), y) = \\text{logitbinarycrossentropy}(\\hat{z}, y) \\)\nだから数式上では同じ値になる。 しかし、シグモイド関数を適用する前の値が大きい場合、適用後の値は極めて1に近くなるため、binarycrossentropyの計算中に桁落ちが発生してしまい本来の値からの誤差が大きくなり、勾配の値もおかしくなる。 そのため、logitbinarycrossentropyを使ったほうが計算が安定するようである(実験はしてません、ごめんなさい)。 Numerical issues for (logit)binarycrossentropy #914\nv0.9.0では binarycrossentropy と logitbinarycrossentropy はCUDA環境で動かなかったがv0.10.0では修正されている。 このあたりを試していた時、masterブランチで binarycrossetnropy は直っていたのに logitbinarycrossentropy は未修正だったので、 初めてFlux.jlにPull resuestを投げて取り込んでもらった。\nDiscriminatorとGeneratorのtrain関数は下のように書ける。 細かい部分はリポジトリ参照\nfunction train_discriminator!(dcgan::DCGAN, batch::AbstractArray{Float32, 4}) noise = randn(Float32, dcgan.noise_dim, dcgan.batch_size) |\u0026gt; gpu fake_input = dcgan.generator(noise) loss(m) = discriminator_loss(m(batch), m(fake_input)) disc_grad = gradient(()-\u0026gt;loss(dcgan.discriminator), Flux.params(dcgan.discriminator)) update!(dcgan.discriminator_optimizer, Flux.params(dcgan.discriminator), disc_grad) return loss(dcgan.discriminator) end function train_generator!(dcgan::DCGAN, batch::AbstractArray{Float32, 4}) noise = randn(Float32, dcgan.noise_dim, dcgan.batch_size) |\u0026gt; gpu loss(m) = generator_loss(dcgan.discriminator(m(noise))) gen_grad = gradient(()-\u0026gt;loss(dcgan.generator), Flux.params(dcgan.generator)) update!(dcgan.generator_optimizer, Flux.params(dcgan.generator), gen_grad) return loss(dcgan.generator) end Tracker から Zygote.jl への変更 using Zygote #669 のマージにより自動微分のバックエンドがTrackerからZygote.jlに変更された。 Trackerで書かれたモデルは、Zygote.jlに合わせて多少書き直す必要がある。\n型の変更 gradient を取った時に返ってくる型が変わった。\nv0.9.0\njulia\u0026gt; using Flux.Tracker: gradient julia\u0026gt; f(x) = 3x^2 + 2x + 1; julia\u0026gt; gr = gradient(f, 2.0) (14.0 (tracked),) julia\u0026gt; typeof(gr) Tuple{Tracker.TrackedReal{Float64}} v0.10.0\njulia\u0026gt; f(x) = 3x^2 + 2x + 1; julia\u0026gt; gr = gradient(f, 2.0) (14.0,) julia\u0026gt; typeof(gr) Tuple{Float64} この変更で Tracker.data や .data で TrackerArray や TrackerReal などでラップされた型からデータを取り出す必要がなくなって便利になった。\ngradientの書き方 Zygote.jl のリファレンス には Tracker.gradient を単に Zygote.gradient に置き換えれば良いと書いてあるが、 自分の場合はTrackerで取れた微分がZygoteにバックエンドが変わって取れなくなった。\nTrackerでは微分を取るときに\nnoise = randn(Float32, 100, 10) fake_input = generator(noise) fake_output = discriminator(fake_input) loss = sum(fake_output) gen_grad = gradient(()-\u0026gt;loss, Flux.params(generator)) このような書き方もできた。model-zooのPull RequestのDCGANのコードもこのような形式で書いてある。\nv0.9.0\njulia\u0026gt; gen_grad.grads IdDict{Any,Any} with 14 entries: Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[0.0456388, -0.00530366, -0.0689154, 0.0356684, 0.033944, 0.0469224, 0… Tracked{Array{Float32,4}}(0x00000000, … =\u0026gt; Float32[-0.0663779 0.470391 0.0135268 0.169848; -0.265991 0.113839 -0.297718 … Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[-1.0491] (tracked) Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[0.0448993, -0.0436305, -0.0396288, -0.0178894, 0.0191187, 0.0322982, … Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[3.05707e-7, -6.56961e-7, -1.86265e-7, 6.1249e-8, 3.40864e-7, 3.57977e… Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[-2.31666e-8, -1.72295e-7, 4.83415e-8, 2.7474e-8, 2.61934e-8, -9.76142… Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[-0.257108, -1.30009, 0.643118, -0.70479, -0.0380322, 0.047996, 0.1616… Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[-1.68035, -1.09166, -1.92644, 0.398565, 0.342392, -0.541331, 0.957729… Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[-0.34392, -1.29767, 0.489044, -0.76697, -0.265278, 0.834581, 0.20901,… Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[-1.86325, -1.0232, -2.0715, -0.0989702, 0.453471, -0.632238, 1.33671,… Tracked{Array{Float32,4}}(0x00000000, … =\u0026gt; Float32[0.161715 0.358326 1.0731 1.53449; 1.10473 0.652393 -0.844213 0.973572… Tracked{Array{Float32,4}}(0x00000000, … =\u0026gt; Float32[-0.107908 0.042381 … -0.0503733 -0.0570333; 0.141959 -0.0503319 … -0.… Tracked{Array{Float32,2}}(0x00000000, … =\u0026gt; Float32[-0.210451 -0.383133 … -0.441269 -0.122698; 0.0191366 -0.273669 … -0.1… Tracked{Array{Float32,1}}(0x00000000, … =\u0026gt; Float32[0.0, -2.23517e-8, 2.6077e-8, 0.0, 2.00234e-8, -9.31323e-9, -2.98023e-… 一方、v0.10.0では\njulia\u0026gt; gen_grad.grads IdDict{Any,Any} with 14 entries: Float32[0.0396942 0.00191599 0.0301089 0.00723371; 0.0816196 0.036961 0.0352632 0.0343… =\u0026gt; nothing Float32[0.0] =\u0026gt; nothing Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 … 1.0, 1.0, 1.0, 1.0, 1.0, … =\u0026gt; nothing Float32[-0.0002127 0.0137428 … -0.0121552 0.0268332; -0.0131425 -0.00983153 … -0.02382… =\u0026gt; nothing Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 … 1.0, 1.0, 1.0, 1.0, 1.0, … =\u0026gt; nothing Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 … 0.0, 0.0, 0.0, 0.0, 0.0, … =\u0026gt; nothing Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 … 0.0, 0.0, 0.0, 0.0, 0.0, … =\u0026gt; nothing Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 … 0.0, 0.0, 0.0, 0.0, 0.0, … =\u0026gt; nothing Float32[0.0171712 0.00370337 0.0333522 -0.0189711; 0.0416152 -0.0110209 0.0113975 -0.0… =\u0026gt; nothing Float32[-0.0109217 0.0165013 … -0.0128005 0.000112204; -0.00316031 -0.0308092 … -0.011… =\u0026gt; nothing Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 … 0.0, 0.0, 0.0, 0.0, 0.0, … =\u0026gt; nothing Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 … 0.0, 0.0, 0.0, 0.0, 0.0, … =\u0026gt; nothing Float32[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 … 0.0, 0.0, 0.0, 0.0, 0.0, … =\u0026gt; nothing Float32[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0 … 1.0, 1.0, 1.0, 1.0, 1.0, … =\u0026gt; nothing 微分が nothing になってしまう。自分は、下のように書き換えた。\nnoise = randn(Float32, 100, 10) loss(m) = sum(discriminator(m(noise))) gen_grad = gradient(()-\u0026gt;loss(generator), Flux.params(generator)) julia\u0026gt; gen_grad.grads IdDict{Any,Any} with 23 entries: RefValue{typeof(^)}(^) =\u0026gt; RefValue{Any}((x = nothing,)) Float32[0.0396942 0.00191599 0.… =\u0026gt; Float32[-0.136635 -0.1123 -0.0335189 -0.108103; -0.0265187 -0… RefValue{Val{2}}(Val{2}()) =\u0026gt; RefValue{Any}((x = nothing,)) Float32[0.0, 0.0, 0.0, 0.0, 0.0… =\u0026gt; [-2.7719e-10, 3.03544e-11, 2.1797e-10, 2.24403e-10, 2.26078e-… RefValue{typeof(^)}(^) =\u0026gt; RefValue{Any}((x = nothing,)) RefValue{Val{2}}(Val{2}()) =\u0026gt; RefValue{Any}((x = nothing,)) Float32[-0.0109217 0.0165013 … … =\u0026gt; [-0.00735242 0.000570209 … 0.00351829 0.0103457; 0.0116238 -0… Float32[0.0, 0.0, 0.0, 0.0, 0.0… =\u0026gt; AbstractFloat[0.00270601, -0.0176082, 0.00565182, 0.0125242, … BatchNorm(128, λ = relu) =\u0026gt; RefValue{Any}((λ = nothing, β = AbstractFloat[0.00270601, -0.… RefValue{Val{2}}(Val{2}()) =\u0026gt; RefValue{Any}((x = nothing,)) RefValue{typeof(^)}(^) =\u0026gt; RefValue{Any}((x = nothing,)) Float32[1.0, 1.0, 1.0, 1.0, 1.0… =\u0026gt; AbstractFloat[-0.00987214, -0.0315625, 0.0199244, 0.0148943, … Float32[1.0, 1.0, 1.0, 1.0, 1.0… =\u0026gt; AbstractFloat[0.00182929, 0.00162896, 0.00011289, 0.00182924,… Float32[-0.0002127 0.0137428 … … =\u0026gt; Float32[0.00630109 0.0134955 … 0.0117517 0.000913039; -0.0059… Float32[1.0, 1.0, 1.0, 1.0, 1.0… =\u0026gt; AbstractFloat[-0.0303094, -0.028408, 0.0697083, -0.00634472, … Float32[0.0, 0.0, 0.0, 0.0, 0.0… =\u0026gt; AbstractFloat[-0.0158277, -0.0324276, 0.0719301, 0.00790212, … Float32[0.0, 0.0, 0.0, 0.0, 0.0… =\u0026gt; AbstractFloat[0.00251813, 0.00111592, -0.000486438, 0.0019682… BatchNorm(64, λ = relu) =\u0026gt; RefValue{Any}((λ = nothing, β = AbstractFloat[-0.0158277, -0.… Float32[0.0171712 0.00370337 0.… =\u0026gt; Float32[0.00725331 -0.00364046 -0.000333806 -0.00218348; 0.00… Float32[0.0] =\u0026gt; [-0.426291] Float32[0.0, 0.0, 0.0, 0.0, 0.0… =\u0026gt; [-9.77911e-11, -9.91324e-11, -7.81544e-10, -2.83712e-11, -4.1… Float32[0.0, 0.0, 0.0, 0.0, 0.0… =\u0026gt; [5.82077e-11, -6.54836e-11, -5.45697e-12, -3.49246e-10, -2.25… BatchNorm(12544, λ = relu) =\u0026gt; RefValue{Any}((λ = nothing, β = AbstractFloat[0.00251813, 0.0… Zygoteでは上のようなimplicit parametersの書き方だけではなく、explicitな書き方 gradient(loss, generator) による微分も可能で、 Zygote.jlの Gradients of ML models にはimplicitな書き方は、 Trackerとの互換性のために残してあると書いてある。\nしかしながら、この二つを利用したときに返ってくる型が異なる\njulia\u0026gt; typeof(gen_grad) Zygote.Grads julia\u0026gt; typeof(gradient(loss, generator)) Tuple{NamedTuple{(:layers,),Tuple{Tuple{NamedTuple{(:W, :b, :σ),Tuple{Array{Float64,2},Array{Float64,1},Nothing}},Base.RefValue{Any},Nothing,NamedTuple{(:σ, :weight, :bias, :stride, :pad, :dilation),Tuple{Nothing,Array{Float32,4},Array{Float64,1},Tuple{Nothing,Nothing},Nothing,Nothing}},Base.RefValue{Any},NamedTuple{(:σ, :weight, :bias, :stride, :pad, :dilation),Tuple{Nothing,Array{Float32,4},Array{Float64,1},Tuple{Nothing,Nothing},Nothing,Nothing}},Base.RefValue{Any},NamedTuple{(:σ, :weight, :bias, :stride, :pad, :dilation),Tuple{Nothing,Array{Float32,4},Array{Float64,1},Tuple{Nothing,Nothing},Nothing,Nothing}}}}}} ため、update! を使ってモデルパラメータを更新しようとすると、 implicitに書く必要がある。このあたりは、将来的に変わっていく可能性もありそう。\nzero_grad! が不要に DCGANでDiscriminator, Generatorを交互に学習させる時、TrackerではDiscriminatorを学習させた後 zero_grad! 使ってを勾配を0にしないと正しく学習されなかった https://github.com/FluxML/model-zoo/pull/111#discussion_r341396388\nhttps://github.com/FluxML/model-zoo/pull/111#discussion_r341847127\nが、Zygote.jlではその必要がなくなっている。 v0.9.0でこれに気づかず正しく学習が進まず苦戦したので、この修正はありがたい。\nv0.9.0\nusing Flux d1 = Dense(2, 1) d2 = Dense(1, 1) c = Chain(d1, d2) p1 = params(d1) p2 = params(d2) pall = params(c) x = rand(2, 10) loss() = sum(c(x)) @info \u0026#34;Case1\u0026#34; Flux.Tracker.gradient(loss, pall).grads |\u0026gt; values |\u0026gt; println @info \u0026#34;Case2\u0026#34; Flux.Tracker.gradient(loss, p1).grads |\u0026gt; values |\u0026gt; println Flux.Tracker.gradient(loss, p2).grads |\u0026gt; values |\u0026gt; println # zero out for next case Flux.Tracker.zero_grad!.(Tracker.grad.(p1)) Flux.Tracker.zero_grad!.(Tracker.grad.(p2)) @info \u0026#34;Case3\u0026#34; Flux.Tracker.gradient(loss, p1).grads |\u0026gt; values |\u0026gt; println Flux.Tracker.zero_grad!.(Tracker.grad.(p2)) Flux.Tracker.gradient(loss, p2).grads |\u0026gt; values |\u0026gt; println Output\n[ Info: Case1 Any[Float32[-6.40395 -5.80043] (tracked), Float32[-4.58864] (tracked), Float32[10.0] (tracked), Float32[-15.8992] (tracked)] [ Info: Case2 Any[Float32[-6.40395 -5.80043] (tracked), Float32[-15.8992] (tracked)] Any[Float32[-9.17728] (tracked), Float32[20.0] (tracked)] [ Info: Case3 Any[Float32[-6.40395 -5.80043] (tracked), Float32[-15.8992] (tracked)] Any[Float32[-4.58864] (tracked), Float32[10.0] (tracked)] 上のCase2のような状況を防ぐために、Case3のように途中にzero_grad!を挟む必要があった。 一方、v0.10.0は\nusing Flux d1 = Dense(2, 1) d2 = Dense(1, 1) c = Chain(d1, d2) p1 = params(d1) p2 = params(d2) pall = params(c) x = rand(2, 10) loss() = sum(c(x)) @info \u0026#34;Case1\u0026#34; gradient(loss, pall).grads |\u0026gt; values |\u0026gt; println @info \u0026#34;Case2\u0026#34; gradient(loss, p1).grads |\u0026gt; values |\u0026gt; println gradient(loss, p2).grads |\u0026gt; values |\u0026gt; println Output\n[ Info: Case1 Any[Float32[9.715003], Float32[3.7775292 4.41461], Float32[10.0], Float32[-5.8413825]] [ Info: Case2 Any[Float32[9.715003], Float32[3.7775292 4.41461]] Any[Float32[10.0], Float32[-5.8413825]] と正しく計算できる。\nFlux.istraining() testmode! が廃止されて istraining になった。@eval Flux.istraining() = true と @eval Flux.istraining() = false で切り替えると思われるが正直よく分かっていない。\n今までモデル単位で設定していたのがグローバルな設定となり、機能性について\nLimitation of Flux.istraining() #909\nこのようなissueが立っているのでここも変更の可能性がありそう。\n以下は他に気づいた点。\n常にFloat32を使う これはバージョンは関係ない話で、 Don\u0026rsquo;t use more precision than you need. には、必ずしも Float64 を使う必要はなく、 Float32 を使えば良いとある。\n何も考えずにJuliaで実数型を使うと Float64 になるので、明示的に Float32 を使う意識が必要。\njulia\u0026gt; typeof(1.0) Float64 julia\u0026gt; [1.0, 2.0, 3.0] 3-element Array{Float64,1}: 1.0 2.0 3.0 julia\u0026gt; typeof(1.0f0) Float32 julia\u0026gt; Float32[1.0, 2.0, 3.0] 3-element Array{Float32,1}: 1.0 2.0 3.0 これと関連して、Make sure your activation and loss functions preserve the type of their inputs に書いてあることではあるが、Float64 と Float32 の変換が起こらないようにする。\n例えば、Float32 を使ってモデル構築をしているのに、leakyrelu の勾配を変更して\nx-\u0026gt;leakyrelu.(x, 0.2) と書いてしまうと 0.2 の型が Float64 であるため、型の変換が行われて激烈に遅くなる。\nx-\u0026gt;leakyrelu.(x, 0.2f0) とするのが良い。自分は最初これを知らず前者のように書いてしまい、一向に計算が終わらなくなってしまい時間を浪費した。 logitbinarycrossentropy に 0, 1 ではなく 0f0, 1f0を渡したのも同様の理由。\n生成結果 MNISTを使って、バッチサイズ128、30エポック(14,000イテレーション)回した結果、\niterations = 0\niterations = 1,000\niterations = 2,500\niterations = 5,000\niterations = 10,000\niterations = 14,000 (最後)\nアニメーション\n損失関数\nと数字っぽい画像が無事に生成できた。\nまとめ Google Colaboratory上でお気楽に環境やモデル構築ができるTensorflowに比べるとFlux.jlは環境構築やリファレンスの少なさで苦労することはあるかもしれないが、 開発はアクティブに行われているので、今後の発展が楽しみである。自分も、また色々試してみたい。\n",
    "permalink": "https://matsueushi.github.io/posts/fluxjl-dcgan/",
    "tags": [
      "Julia",
      "Flux",
      "DCGAN",
      "MNIST",
      "MLP"
    ],
    "title": "Flux.jl v0.10.0でDCGANを動かす(CUDA環境)"
  },
  {
    "contents": "何かと必要になる単位行列だが、Julia v1.0以降だと LinearAlgebra をインポートして Matrix と I の組み合わせで作成するのが楽なようだ。\nusing LinearAlgebra using Distributions Matrix(I, 2, 2) 2×2 Array{Bool,2}: true false false true Matrix{Int64}(I, 2, 2) 2×2 Array{Int64,2}: 1 0 0 1 Matrix{Float64}(I, 2, 2) 2×2 Array{Float64,2}: 1.0 0.0 0.0 1.0 MvNormal の分散を単位行列にしたいときは、 I だけで大丈夫。\nMvNormal([3, 4], I) IsoNormal( dim: 2 μ: [3.0, 4.0] Σ: [1.0 0.0; 0.0 1.0] ) 参考\nhttps://stackoverflow.com/questions/57270276/identity-matrix-in-julia\nhttps://www.reddit.com/r/Julia/comments/9cfosj/identity_matrix_in_julia_v10/\n",
    "permalink": "https://matsueushi.github.io/posts/julia-identity/",
    "tags": [
      "Julia"
    ],
    "title": "Juliaの単位行列"
  },
  {
    "contents": "最近なかなか統計モデルに取り組む時間が十分捻出できていないが、「ノンパラメトリックベイズ 点過程と統計的機械学習の数理」に入門を開始した。\nノンパラベイズに到達する前のデータ点をクラスに分類するクラスタリングの段階で出てきた、\\(K\\)-平均アルゴリズム(Wikipedia) を実装したので記録。使っているのはいつものようにJulia。\n\\(K\\)-平均アルゴリズムではすでにクラス数 \\(K \\) は given として計算を進めていく。実装したアルゴリズムは本を参考にして下のようにした。\nデータ点を \\( \\mathbf{x}_i \\in \\R^d, i = 1, \\ldots, n \\), クラスタリングにより決定される、 各クラスを代表する点を \\(\\boldsymbol{\\mu}_k \\in \\R^d, k = 1, 2, \\ldots, K \\) とする。\n各データ点 \\( x_i \\) が属するクラスを \\( z_i \\in \\{ 1, 2, \\ldots, K \\}\\) とすると、 \\( K \\)-平均法では、 各データ点は \\( (\\boldsymbol{\\mu}_k)_{k=1}^K \\) のなかで一番(平方ユークリッド)距離が近い点が代表するクラスに分類されるので、 $$ z_i = \\argmin_k || \\mathbf{x}_i - \\boldsymbol{\\mu}_k||^2 $$ となる。\nアルゴリズムは、目的関数\n$$ f((z_i)_{i=1}^n, (\\boldsymbol{\\mu}_k)_{k=1}^K) = \\sum_{i=1}^n || \\mathbf{x}_i - \\boldsymbol{\\mu}_{z_i} ||^2 $$\nが最小となるように \\( (z_i)_{i=1}^n, (\\boldsymbol{\\mu}_k)_{k=1}^K \\) を更新していく。\nアルゴリズム \\( (z_i)_{i=1}^n \\) を乱数を用いて初期化する。集合 \\( \\{ z_i \\mid i = 1, \\ldots, n \\} \\) の個数が \\( K \\) ではない場合、個数が \\( K \\)になるまで \\( (z_i)_{i=1}^n \\) を乱数を用いて再初期化する $$ \\boldsymbol{\\mu}_k = \\frac{1}{\\sharp \\{i \\mid z_i = k \\}} \\sum_{i, z_i=k} \\mathbf{x}_i $$ と代表点の更新を行う 以下のアルゴリズムを、 \\( (z_i)_{i=1}^n, (\\boldsymbol{\\mu}_k)_{k=1}^K \\) を更新することによる目的関数 \\( f \\) の減少が閾値以下になるまで繰り返す \\( z_i = \\argmin_k || \\mathbf{x}_i - \\boldsymbol{\\mu}_k||^2, i = 1, \\ldots, n \\) とラベリングの更新を行う 集合 \\( \\{ z_i \\mid i = 1, \\ldots, n \\} \\) の個数が \\( K \\) ではない場合(=分類されるクラスが減少してしまった場合)、最初に戻って \\( (z_i)_{i=1}^n \\) の初期化からやり直す 代表点の位置によっては分類されたクラスの数が当初設定した \\( K \\)より小さくなってしまうことがあり、 そのまま計算を行うと、\\( \\boldsymbol{\\mu}_k \\) のいずれかが NaN になって計算できないので、 \\( K \\) を置き換えるか、ラベルを振り直すというのがすぐに思いつく方法だが、今回は後者の方法を採用した。\n使ったデータは ScikitLearn.jl で作成。 下の図のような三種類のパターン (noisy_circles, noisy_moons, blobs) を用意して、サンプル点は1500個。 このページ が参考になる。\nusing ScikitLearn using Statistics using Plots using Printf using Random @sk_import datasets: (make_circles, make_moons, make_blobs) n_samples = 1500 noisy_circles = make_circles(n_samples=n_samples, factor=.5, noise=.05) noisy_moons = make_moons(n_samples=n_samples, noise=.05) blobs = make_blobs(n_samples=n_samples, random_state=8) plts = [] for data in [noisy_circles, noisy_moons, blobs] points, label = data push!(plts, scatter(points[:, 1], points[:, 2], label=\u0026#34;\u0026#34;, mc=label)) end Plots.plot(plts..., layout = (1, 3), size = [800, 400]) 本体の実装はこんな感じで、dist で \\( f \\) の値、 dist_change で \\( f \\) の変化を保持。\nmutable struct KMean points::Array{Float64} K::Int64 zs::Vector{Int64} μs::Array{Float64} dist::Float64 dist_change::Float64 end function KMean(points::Array{Float64}, K::Int64) n_points = size(points, 1) init_zs = nothing while true init_zs = rand(1:K, n_points) if Base.length(Set(init_zs)) == K break end end zs = init_zs kmean = KMean(points, K, zs, zeros(1, size(points, 2), K), 0, typemax(Float64)) update_μs!(kmean) kmean end function update_μs!(km::KMean) km.μs = cat([mean(km.points[km.zs .== i, :], dims=1) for i in 1:km.K]..., dims=3) new_dist = sum((km.points - reshape(km.μs[:, :, km.zs], 2, :)\u0026#39;).^2) km.dist_change = km.dist - new_dist km.dist = new_dist km end function update_zs!(km::KMean) norms = sum((km.points .- km.μs).^2, dims=2) argmin_norms = [x[3] for x in argmin(norms, dims=3)][:] while true if Base.length(Set(argmin_norms)) == km.K break end argmin_norms = rand(1:km.K, size(km.points, 1)) end km.zs = argmin_norms km end function update!(km::KMean) update_zs!(km) update_μs!(km) km end それぞれのサンプルデータに対し、\\( f \\) の減少幅が0.1以下になるまでイテレーションを行う(最高100回)様子をアニメーションして、gifファイルに出力させると下のようになる。 Juliaはgifのアニメーションを作るのも楽でいいですね。\ngifs = [] for (i, (data, K)) in enumerate(zip([noisy_circles, noisy_moons, blobs], [2, 2, 3])) points, label = data km = KMean(points, K) anim = @animate for n=1:100 if abs(km.dist_change) \u0026lt; 0.01 break end scatter(km.points[:, 1], km.points[:, 2], mc=km.zs, label=\u0026#34;\u0026#34;) plt = scatter!(km.μs[1, 1, :], km.μs[1, 2, :], ms=8, mc=:yellow, msw=3, label=\u0026#34;\u0026#34;, title=@sprintf(\u0026#34;Iterations=%d\u0026#34;, n)) update!(km) plt end push!(gifs, gif(anim, @sprintf(\u0026#34;clustering-kmean_%d.gif\u0026#34;, i), fps = 1)) end display.(gifs); 結果は下の通り。黄色の点が、\\( (\\boldsymbol{\\mu}_k)_{k=1}^K \\) に該当。\nnoisy_circles と noisy_moons では次のような結果で、 代表点からの距離でクラスタリングするならばまあそうなるだろう、という結果。\nblobs では一見うまくいくように見えるが、\n乱数による初期化次第で、下のように期待とは違う場所に収束することも起こり得る。\n次は混合ガウスモデルのギブスサンプリングかな。無限次元への扉は遠い\u0026hellip;\nJupyter Notebook (アニメーションは表示されない):\nhttps://github.com/matsueushi/notebook_blog/blob/master/clustering.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/clustering-kmean/",
    "tags": [
      "Julia",
      "KMean"
    ],
    "title": "K-平均アルゴリズム"
  },
  {
    "contents": "前回 の続き。GaussianProcesses.jlを使ってガウス過程回帰のハイパーパラメータ推定を行ってみる。 「ガウス過程と機械学習」の図3.20(a)を例とする。\nxxs = [-0.5, 0.5, 1, 1.4, 3] yys = [0.7, 1.8, 1.7, 2.3, 1] scatter(xxs, yys) 0 1 2 3 0.9 1.2 1.5 1.8 2.1 y1 平均0のガウスカーネルのガウス過程に(ノイズ項込みで)フィッティングさせるのは非常に簡単で、optimize! を呼べば良いだけ。\ngp = GP(xxs, yys, MeanZero(), SE(0.0, 0.0)) optimize!(gp) Results of Optimization Algorithm * Algorithm: L-BFGS * Starting Point: [-2.0,0.0,0.0] * Minimizer: [-1.250611250087999,0.5939445695924219, ...] * Minimum: 5.464078e+00 * Iterations: 10 * Convergence: true * |x - x\u0026#39;| ≤ 0.0e+00: false |x - x\u0026#39;| = 1.80e-09 * |f(x) - f(x\u0026#39;)| ≤ 0.0e+00 |f(x)|: false |f(x) - f(x\u0026#39;)| = 1.63e-16 |f(x)| * |g(x)| ≤ 1.0e-08: true |g(x)| = 1.23e-14 * Stopped by an increasing objective: false * Reached Maximum Number of Iterations: false * Objective Calls: 26 * Gradient Calls: 26 パラメーターを確認すると、\nprint(gp) GP Exact object: Dim = 1 Number of observations = 5 Mean function: Type: MeanZero, Params: Float64[] Kernel: Type: SEIso{Float64}, Params: [0.593945, 0.233886] Input observations = [-0.5 0.5 1.0 1.4 3.0] Output observations = [0.7, 1.8, 1.7, 2.3, 1.0] Variance of observation noise = 0.08198471101193598 Marginal Log-Likelihood = -5.464 「ガウス過程と機械学習」では、カーネルは $$ k(\\mathbf{x}, \\mathbf{x}^\\prime | \\bm{\\theta}) = \\theta_1 \\exp \\left( - \\frac{|\\mathbf{x} - \\mathbf{x}^\\prime|^2}{\\theta_2}\\right) + \\theta_3 \\delta(\\mathbf{x}, \\mathbf{x}^\\prime) $$ となっていて、推定結果は \\((\\theta_1, \\theta_2, \\theta_3)=(1.596,6.560,0.082)\\) とされている。 \\(\\theta_3\\)はVariance of observation noiseの0.08198471101193598とそのまま一致。 SEIsoのカーネル関数は $$ k(\\mathbf{x}, \\mathbf{x}^\\prime) = \\sigma^2 \\exp \\left( - \\frac{(\\mathbf{x} - \\mathbf{x}^\\prime)^\\top(\\mathbf{x} - \\mathbf{x}^\\prime))}{2l^2}\\right) $$ で、パラメーターは \\(l\\) と \\(\\sigma\\) の対数をとった ll と lσ だから \\(\\theta_1 = \\exp(2 * l\\sigma), \\theta_2=2 * \\exp(2 * ll)\\) という変換で対応できる。 SEIso のメンバー変数 σ2 と ℓ2 を使って確認すると、\nprintln(\u0026#34;theta1: \u0026#34;, gp.kernel.σ2) println(\u0026#34;theta2: \u0026#34;, gp.kernel.ℓ2 * 2) theta1: 1.5964347486496255 theta2: 6.560299908989858 となり、同じ結果が得られている。\nplot(gp; xlabel=\u0026#34;gp.x\u0026#34;, ylabel=\u0026#34;gp.y\u0026#34;, legend=false, fmt=:png) -0.5 0.0 0.5 1.0 1.5 2.0 2.5 3.0 0.5 1.0 1.5 2.0 gp.x gp.y 上だと点が端ギリギリに配置され結構見ずらい(+ガウス誤差が含まれていない？)ので、ガウス観測誤差も含めた予測結果を自分でプロットすると、\nxtest = reshape(collect(range(-1, stop = 3.5, length = 100)), 1, :) μ, σ2 = predict_y(gp, xtest) dists = Normal.(μ, sqrt.(σ2)) p = [0.025, 0.975] qt = hcat(map(x -\u0026gt; quantile.(x, p), dists)...) plot(xtest[:], qt[1, :], fillrange = qt[2, :], fillalpha = 0.3, label = \u0026#34;\u0026#34;, linewidth = 0) scatter!(xxs, yys, label = \u0026#34;\u0026#34;) plot!(xtest[:], mean.(dists), linewidth = 2, linestyle = :dash, label = \u0026#34;\u0026#34;) -1 0 1 2 3 -0.5 0.0 0.5 1.0 1.5 2.0 2.5 ノートブック: https://github.com/matsueushi/notebook_blog/blob/master/gaussianprocess-julia.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/gaussianprocess-jl-2/",
    "tags": [
      "GaussianProcess",
      "Julia"
    ],
    "title": "Juliaのガウス過程ライブラリGaussianProcesses.jlを使う(ハイパーパラメーター推定)"
  },
  {
    "contents": "Juliaのガウス過程ライブラリ GaussianProcesses.jl を触ってみる。 チュートリアルはまだ未整備のようなので、サンプルノートブックとガウス過程と機械学習」などを参考にしながらやっていく。 Juliaのはv1.1.0, GaussianProcesses.jlはv0.9.0を使っている。\nインストールはいつものように\nusing Pkg Pkg.add(\u0026#34;GaussianProcesses\u0026#34;) カーネル関数 すでに多くの種類のカーネル関数が実装されており、 ガウスカーネル、線形カーネル、指数カーネル、周期カーネル、Matérnカーネルなど、 「ガウス過程と機械学習」に出てきたカーネル関数はほぼカバーされているようだ。\n全て見ていくとキリがないのでいくつか基本的な部分だけ確認することにする。\nガウスカーネルのカーネル関数は「ガウス過程と機械学習」では $$ k(\\mathbf{x}, \\mathbf{x}^\\prime) = \\theta_1 \\exp \\left( - \\frac{|\\mathbf{x} - \\mathbf{x}^\\prime|^2}{\\theta_2}\\right) $$\nとなっているが、GaussianProcesses.jlでこれに対応するのは [GaussianProcesses.SEIso] (http://stor-i.github.io/GaussianProcesses.jl/latest/kernels.html#GaussianProcesses.SEIso) である。 関数のパラメトライズは対数スケールとなっているため十分注意する必要があり、カーネル関数 SEIso(ll::T, lσ::T) は、 \\(\\sigma = \\log (\\) lσ \\()\\), \\(l = \\log (\\) ll \\()\\) とした時に\n$$ k(\\mathbf{x}, \\mathbf{x}^\\prime) = \\sigma^2 \\exp \\left( - \\frac{(\\mathbf{x} - \\mathbf{x}^\\prime)^\\top(\\mathbf{x} - \\mathbf{x}^\\prime))}{2l^2}\\right) $$\nだから、\\( k(\\mathbf{x}, \\mathbf{x}^\\prime) = \\exp \\left( - |\\mathbf{x} - \\mathbf{x}^\\prime|^2\\right) \\) は\nrbf = SEIso(log(1/sqrt(2)), 0.0) に対応している。「ガウス過程と機械学習」の pp.69 のように、\\( (x_1, x_2, x_3, x_4) = (1, 2, 3, 4) \\) とした時の共分散行列を求める。\nxs = [1, 2, 3, 4] cov(rbf, xs, xs) このようにすると xs の全体が1要素として認識されてしまい\n1.0 が帰ってきてダメなので、reshape で 1×4 Arrayに変換して次のようにする。\nxs = reshape([1.0, 2, 3, 4], 1, :) cov(rbf, xs, xs) 4×4 Array{Float64,2}: 1.0 0.367879 0.0183156 0.00012341 0.367879 1.0 0.367879 0.0183156 0.0183156 0.367879 1.0 0.367879 0.00012341 0.0183156 0.367879 1.0 となり本と同様の結果が得られた。ちなみに\nxs = reshape([1, 2, 3, 4], 1, :) cov(rbf, xs, xs) は\nInexactError: Int64(0.3678794411714422) となり動かないので、xs を Real のベクターにする。\nガウス過程からのサンプル 次はこのカーネル関数で定義したガウス過程からサンプリングを行う。GaussianProcesses.jl でガウス過程を呼び出すメソッド GPE は、 学習データからフィッティングを行うものと行わないものの両方が用意されている。\nすでにカーネル関数を定義したので、使うのはフィッティングしない方。 ちなみに GPE は観測ノイズを考慮しないノイズフリーのガウス過程のフィッティングをするメソッドで、観測ノイズも考慮したフィッティングを行いたければ GP を使う。 この辺りは 公式ドキュメント を見た方が良いかもしれない。\n先ほどのRBFカーネルで定まるガウス過程を定義し、サンプルを5つ取得する。\nコード上ではカーネルのみを指定して平均は与えていないが、GPE の mean 引数のデフォルトが MeanZero() なので平均0のガウス過程を考えていることになる。 mean 引数を変更すれば様々な平均関数のガウス過程を考えられる(はず、未確認)。\nサンプルは rand で行うことができ、\nxs = -25:0.1:25 gp_rbf = GPE(kernel = rbf) samples = rand(gp_rbf, xs, 5) plot(xs, samples, label = \u0026#34;\u0026#34;, lw = 2) -20 -10 0 10 20 -2 -1 0 1 2 非常にお手軽である。\nカーネルの和、積 カーネルの和と積も定義されている。線形カーネルと周期カーネルで和、積を使ってみる。\nkernel_sum = Lin(2.0) + Periodic(0.0, 0.0, 2.0) gp_sum = GPE(kernel = kernel_sum) samples = rand(gp_sum, xs, 5) plot(xs, samples, label = \u0026#34;\u0026#34;, lw = 2) -20 -10 0 10 20 -6 -4 -2 0 2 4 6 kernel_prod = Lin(2.0) * Periodic(0.0, 0.0, 2.0) gp_prod = GPE(kernel = kernel_prod) samples = rand(gp_prod, xs, 5) plot(xs, samples, label = \u0026#34;\u0026#34;, lw = 2) -20 -10 0 10 20 -7.5 -5.0 -2.5 0.0 2.5 5.0 7.5 これまた簡単。\n「やってみた」系の記事になってしまったが、今日はここまで。 まだ少し触っただけではあるが、手軽にガウス過程が使えて便利。 次は何か具体例を用いて GP, GPE のフィッティングを行いたい。\n上の内容のjupyter notebook:\nhttps://github.com/matsueushi/notebook_blog/blob/master/gaussianprocess-julia.ipynb\n参考 FAIRBROTHER, Jamie, et al. GaussianProcesses. jl: A Nonparametric Bayes package for the Julia Language. arXiv preprint arXiv:1812.09064, 2018.\nGitHubレポジトリ: STOR-i/GaussianProcesses.jl, サンプルノートブック\nドキュメント: http://stor-i.github.io/GaussianProcesses.jl/latest/\n持橋大地, 大羽成征. ガウス過程と機械学習, 講談社 機械学習プロフェッショナルシリーズ, 2019\n",
    "permalink": "https://matsueushi.github.io/posts/gaussianprocess-jl/",
    "tags": [
      "GaussianProcess",
      "Julia"
    ],
    "title": "Juliaのガウス過程ライブラリGaussianProcesses.jlを使う(基本編)"
  },
  {
    "contents": "Velocity:Design:Comfort. by Sweet Trip RateYourMusic を巡回していたら2003年の年間ランキング4位に挙げられていたこのアルバム。近未来感のある色とりどりのジャケットとvelocity:design:comfort.という抽象的なタイトルに妙に心惹かれたので聞いてみたところかなりハマってしまい、いつの間にかBandcampの購入ボタンをクリックしていた。 日本語で調べてもあまりこのアルバムについて書かれた情報は見つからなかったのが残念。\nサンフランシスコのSweet Tripと言うバンドの2枚目で、2009年の3rd以降新作は出ていないようである。 2013年にはSoundcloudに曲がアップロードされていて、Probably not the last Sweet Trip song ever. とあるので解散はしていないみたいだ。\nシューゲイザーとIDM、グリッチが美しく溶け合ったようなサウンドは、他に似たような曲を聞いたことがないからなのか、 それともジャケットを見た先入観なのか、15年以上前のアルバムなのになぜか未来を感じずにいられない。\n1曲目のTekkaだけはやや2曲目以降とは趣が異なる曲で、どこかAuthchreを連想するような攻撃的なドリルンベース。聞いているうちに現実の世界から離脱し、アルバムのジャケットの中の世界にどんどん没入していくような意図があったのだろうか？\n普通のシューゲイザーだと聞いている間にうたた寝から夢の世界に入り込んでしまうような気分にしばしば陥るが、このアルバムだと徐々に夢の世界といっても電脳空間、仮想空間に誘われていくような気がする。\nCDとダウンロードのみのリリースのようだが、レコードでリイシューされてほしい。\n(2020/6/29 https://darla.com/products/sweet-trip-velocity-design-comfort リイシューされていました)\nリーダーのRoberto BurgosのSoundCrowd: https://soundcloud.com/wotf\n好きな曲: Dsco, International, Dedicated, To All The Dancers Of The World\n",
    "permalink": "https://matsueushi.github.io/posts/sweettrip-velocity-design-comfort/",
    "tags": [
      "Music",
      "SweetTrip",
      "Shoegaze",
      "Glitchpop"
    ],
    "title": "Sweet Trip - velocity:design:comfort. (2003)"
  },
  {
    "contents": "7/5 追記 タイトルが「変数補助法」になっていたのを「補助変数法」に修正\n前回書いた 「ガウス過程の補助変数法 (Inducing variable method) を理解する 」の続き。 Julia (v1.0) を使って、前回調べた SoD, SoR, DTC, FITC による回帰の近似結果を実際に確認する。\n簡単のため、gp.jl により、\nガウスカーネルのクラス GaussianKernel が定義されていて、 カーネル k に対してカーネル関数 \\( k(x, y) \\) と相互共分散 \\( (k(x_i, y_j))_{i,j}\\) がそれぞれ ker(k, x, y) と cov(k, xs, ys) で計算できる と仮定する。ということで、まずはライブラリの読み込み。\nusing Distributions using Plots using LinearAlgebra include(\u0026#34;gp.jl\u0026#34;) データは、MLPシリーズ 「ガウス過程と機械学習」の pp.157, 図5.3 補助入力点の配置 と同じサンプルを使う。上記のページに掲載されている、「補助変数法の例 (1次元の場合).」のデータの生成方法を参考にして次のようにデータを100個作成した。\n# サンプルデータの作成 xs = vcat(rand(80),rand(20) * 3 .+ 1.0) sort!(xs) fx = sin.(xs*2) ys = fx + rand(Normal(), Base.length(fx)) * 0.3 ts = collect(-1:0.01:5) plot(ts, sin.(ts*2), lw = 2, label = \u0026#34;\u0026#34;) scatter!(xs, ys, label = \u0026#34;\u0026#34;) \\( y = \\sin (2x) \\) にノイズを加えたもので、\\( [0,1] \\) の間はデータの密度が高くなっている。ts は、あとで使う分布を予測したい点である。\n今回予測するのは、観測値 \\( y \\) ではなく、出力値 \\( f \\)とする。 (最初にやっていた時は観測値を予測していて、本の図と同じにならなくて混乱していた)\n考えるカーネルは、ガウスカーネル \\( k(x, x^\\prime) = \\exp(-|x- x^\\prime|^2) \\) である。 観測誤差は \\( \\sigma^2 = 1.0 \\) としておく。コードの中ではこれを eta で表す。\ngk = GaussianKernel() eta = 1.0 GP まずは、通常のガウス回帰モデルの場合の予測を確認。予測分布は、\n$$ p(\\mathbf{f}_* | \\mathbf{y}) = \\mathcal{N}(\\mathbf{K}_{*, \\mathbf{f}} (\\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{K}_{*, \\mathbf{f}} (\\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \\mathbf{K}_{\\mathbf{f}, *}) $$\nであった。今回は、複数点の同時予測分布からサンプルを発生させることは行わず、各点ごとに予測分布を求めて平均と2.5%, 97.5%点を計算する。\n1点の予測分布を計算する関数を実装しよう。自分の実装では、cov は行列を返すため、1x1の行列を first を使ってスカラーにしている。\nKff = cov(gk, xs, xs) n = Base.length(xs) Σ = inv(Kff + eta * Matrix{Float64}(I, n, n)) # 1点の予測分布 function gp(t) Kft = cov(gk, xs, [t]) Ktf = Kft\u0026#39; Ktt = [ker(gk, t, t)] gp_mu = Ktf * Σ * ys gp_cov = Ktt - Ktf * Σ * Kft Normal(first(gp_mu), sqrt(first(gp_cov))) end 以下のコードで表示すると、\ngp_dists = [gp(t) for t in ts] gp_mean = mean.(gp_dists) gp_qt = hcat([quantile.(s, [0.025, 0.975]) for s in gp_dists]...) function gp_plot() plot(ts, gp_qt[1, :], fillrange = gp_qt[2, :], fillalpha = 0.4, label = \u0026#34;\u0026#34;, linewidth = 0) plot!(ts, sin.(ts*2), lw = 2, label = \u0026#34;y=sin(2x)\u0026#34;) plot!(ts, gp_mean, lw = 2, label = \u0026#34;GP\u0026#34;) scatter!(xs, ys, label = \u0026#34;\u0026#34;) end gp_plot() (なぜか savefig でpng形式で保存すると fillrange した最小値の部分に線が出てしまった。)\n早速それぞれの補助変数法でどれくらい近似できているかを見ていこう。補助入力点が、2点、5点、10点ある場合を考え、点は等間隔に配置されているとする。(SoD を除く)\n本質的な部分とは関係ないが、先にプロット用の関数を定義しておく。\nfunction plot_result(gp_mean, gp_qt, mn, qt, ind_xs, label) plot(ts, gp_qt[1, :], fillrange = gp_qt[2, :], fillalpha = 0.4, label = \u0026#34;GP\u0026#34;, linewidth = 0) plot!(ts, qt[1, :], fillrange = qt[2, :], fillalpha = 0.4, label = label, linewidth = 0) plot!(ts, gp_mean, lw = 2, label = \u0026#34;\u0026#34;) plot!(ts, mn, lw = 2, label = \u0026#34;\u0026#34;) scatter!(xs, ys, label = \u0026#34;\u0026#34;) scatter!(ind_xs, fill(-2, Base.length(ind_xs)), markershape = :x, label = \u0026#34;\u0026#34;) end The Subset of Data (SoD) SoD は他の SoR, DTC, FITC とは違い、任意に補助入力点を選べる訳ではなく元の入力点の部分集合として選ばなくてはいけない。 ここでは、サンプルの左からの順番が等間隔になるように選んだ。(例えば5点選ぶ場合、左から1, 21, 41, 61, 81番目)。\nランダムに選択したり、なるべく等間隔になるように選んだりすればもっとデータがよく代表されるようになり精度が向上するかもしれない。 実装に関しては、GPの入力点を減らしただけである。\nfunction sod_plot(sod_xs, sod_ys) Kff = cov(gk, sod_xs, sod_xs) n = Base.length(sod_xs) Σ = inv(Kff + eta * Matrix{Float64}(I, n, n)) # 各点の分布を計算して信用区間を計算する function sod(t) Kft = cov(gk, sod_xs, [t]) Ktf = Kft\u0026#39; Ktt = [ker(gk, t, t)] gp_mu = Ktf * Σ * sod_ys gp_cov = Ktt - Ktf * Σ * Kft Normal(first(gp_mu), sqrt(first(gp_cov))) end sod_dists = [sod(t) for t in ts] sod_mean = mean.(sod_dists) sod_qt = hcat( [quantile.(s, [0.025, 0.975]) for s in sod_dists]...) plot_result(gp_mean, gp_qt, sod_mean, sod_qt, sod_xs, \u0026#34;SoD\u0026#34;) end plts = [gp_plot()] for where_xs in [1:50:100, 1:20:100, 1:10:100] sod_xs = xs[where_xs] sod_ys = ys[where_xs] push!(plts, sod_plot(sod_xs, sod_ys)) end plot(plts..., layout = (2, 2), size = [800, 600]) 左上がGPで、補助入力点のx座標はグラフの下部に示している。データの左から順番で等間隔になるように補助入力点を選ぶと、データがスパースなところの情報が大きく切り捨てられてかなり近似が悪くなるということだろう。\nThe Subset of Regressors (SoR) 前回考えた、予測分布 \\( q_{\\text{SoR}}(\\mathbf{f}_* | \\mathbf{y}) \\) が $$ \\begin{aligned} \\Sigma = (\\sigma^{-2} \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} + \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}})^{-1} \\end{aligned} $$ を用いて $$ \\begin{aligned} \\mathcal{N} (\\sigma^{-2} \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{y}, \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, *} ) \\end{aligned} $$ と表されることを思い出すと、SoRは次のように実装できる。us の取り方が SoD と違っていることに注意。\nfunction sor_plot(us) Kuu = cov(gk, us, us) Kuf = cov(gk, us, xs) Kfu = Kuf\u0026#39; Σ = inv(1 / eta * Kuf * Kfu + Kuu) function sor(t) Kut = cov(gk, us, [t]) Ktu = Kut\u0026#39; sor_mu = 1 / eta * Ktu * Σ * Kuf * ys sor_cov = Ktu * Σ * Kut Normal(first(sor_mu), sqrt(first(sor_cov))) end sor_dists = [sor(t) for t in ts] sor_mean = mean.(sor_dists) sor_qt = hcat( [quantile.(s, [0.025, 0.975]) for s in sor_dists]...) plot_result(gp_mean, gp_qt, sor_mean, sor_qt, us, \u0026#34;SoR\u0026#34;) end plts = [gp_plot()] for du in [2.5, 1.0, 0.5] us = collect(range(0, stop = 5 - du, step = du)) push!(plts, sor_plot(us)) end plot(plts..., layout = (2, 2), size = [800, 600]) 式を見て結構大胆な近似だと思っていたが、この例だと、5点の段階でも入力データが存在している範囲での予測はそう悪くない。\nThe Deterministic Training Conditional (DTC) DTC, FITCに関しては、SoRの共分散の計算がちょっと変わるだけ。 $$ \\begin{aligned} q_{\\text{DTC}}(\\mathbf{f}_* | \\mathbf{y}) = \\mathcal{N} (\\sigma^{-2} \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *} + \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, *} ) \\end{aligned} $$\nだったから、SoRの最初の計算部分を\nKuu = cov(gk, us, us) Kuf = cov(gk, us, xs) Kfu = Kuf\u0026#39; Σ = inv(1 / eta * Kuf * Kfu + Kuu) function dtc(t) Kut = cov(gk, us, [t]) Ktu = Kut\u0026#39; Qtt = Ktu * inv(Kuu) * Kut Ktt = [ker(gk, t, t)] sor_mu = 1 / eta * Ktu * Σ * Kuf * ys sor_cov = Ktt - Qtt + Ktu * Σ * Kut Normal(first(sor_mu), sqrt(first(sor_cov))) end に変えるだけでいい。\n5点の場合のデータがない部分の分散の情報がかなり改善されているし、10点ではほとんど平均、分散共にぴったり近似できている。 そうなるとFITCを使うまでもないということにもなりかねないが……\nThe Fully Independent Training Conditional (FITC) 最後にFITC。\n$$ \\begin{aligned} \\Sigma = (\\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\Lambda^{-1} \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} + \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}})^{-1}, \\Lambda = \\text{diag}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} - \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}} + \\sigma^2 \\mathbf{I}) \\end{aligned} $$ を使って $$ \\begin{aligned} q_{\\text{FITC}}(\\mathbf{f}_* | \\mathbf{y}) = \\mathcal{N} (\\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\Lambda^{-1} \\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *} + \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, *} ), \\end{aligned} $$\nだったから同様に\nKuu = cov(gk, us, us) Kuf = cov(gk, us, xs) Kfu = Kuf\u0026#39; Λ = Diagonal([ker(gk, xs[i], xs[i]) - Kfu[i, :]\u0026#39; * inv(Kuu) * Kuf[:, i] + eta for i in 1:Base.length(xs)]) Σ = inv(Kuf * inv(Λ) * Kfu + Kuu) function fitc(t) Kut = cov(gk, us, [t]) Ktu = Kut\u0026#39; Qtt = Ktu * inv(Kuu) * Kut Ktt = [ker(gk, t, t)] sor_mu = Ktu * Σ * Kuf * inv(Λ) * ys sor_cov = Ktt - Qtt + Ktu * Σ * Kut Normal(first(sor_mu), sqrt(first(sor_cov))) end あまりDTCと変わらない感じになってしまった。この場合だと追加で計算した分散の対角線部分があまり効いてこなかったのだろう。\n手法の比較 最後に、点の数を揃えて比較してみる。図示方法を変えるだけなので、コードは省略。\n2点 5点 10点 DTCの段階で十分良く近似できていて、\\( \\mathbf{f} | \\mathbf{u} \\) の分散の対角部分を考えるメリットがあまり感じられないような結果となってしまった。 どのような場合にFITCの近似ががDTCの場合より劇的に向上するのか考えてみたい。\nJupyter Notebook: https://nbviewer.jupyter.org/github/matsueushi/gp_and_mlp/blob/master/ivm.ipynb\nレポジトリ: https://github.com/matsueushi/gp_and_mlp\n",
    "permalink": "https://matsueushi.github.io/posts/ivm/",
    "tags": [
      "GaussianProcess",
      "InducingVariableMethod",
      "SparseApproximation",
      "SoD",
      "SoR",
      "DTC",
      "FITC"
    ],
    "title": "ガウス過程の補助変数法をJuliaで実装、回帰結果を比較"
  },
  {
    "contents": "6/27 追記: typo, \\( p(\\mathbf{y} | \\mathbf{f}) \\) の誤字を修正, \\( q_{\\text{FITC}}(\\mathbf{f}_* | \\mathbf{y}) \\) の二番目の等号を修正 (\\( \\sigma^{-2} \\) を削除)\n「ガウス過程と機械学習」を読んでいるが、5.2補助変数法のところで、どの部分で近似が行われているのかよく分からなくなってしまった。\nそのため、今回は原論文であるQuinonero Candela, J. and Rasmussen, CE.の \u0026ldquo;A Unifying View of Sparse Approximate Gaussian Process Regression\u0026rdquo; を読んでスパース近似についてまとめて見ようと思う。ゴールは、The Fully Independent Training Conditional (FITC) の理解である。\n\\( \\mathbf{X}=(\\mathbf{x}_1, \\ldots, \\mathbf{x}_N) \\) を学習データ、 \\( \\mathbf{y}=(y_1, \\ldots, y_N)^\\top \\) を観測値とする。学習データと観測値の関係は、ガウス過程から生成される関数 \\( f \\) と誤差 \\( \\epsilon_n \\) を用いて\n$$ y_n = f(\\mathbf{x_n}) + \\epsilon_n,$$ $$\\epsilon_n \\sim \\mathcal{N}(0, \\sigma^2)$$\nと結びつく観測モデルを考える。\\( \\mathbf{f}=(f_1, \\ldots, f_N)^\\top, f_n=f(\\mathbf{x}_n) \\) は学習データの出力値である。 上の観測モデルは、 $$ p(\\mathbf{y} | \\mathbf{f}) = \\mathcal{N}(\\mathbf{f}, \\sigma^2\\mathbf{I}) $$ と書き直せる。\n取り組みたい問題は、ガウス過程回帰に基づいた回帰モデル。\n予測したい点を \\( \\mathbf{X}_*=(\\mathbf{x}_{*1}, \\ldots, \\mathbf{x}_{*M} ) \\) , 出力値を \\( \\mathbf{f}_* \\) , 観測値を \\( \\mathbf{y}_* \\) とする。\n\\( \\mathbf{f}, \\mathbf{f}_* \\) の条件付き同時確率分布はベイズルールから\n$$ \\begin{aligned} p(\\mathbf{f}, \\mathbf{f}_* | \\mathbf{y}) = \\frac{p(\\mathbf{f}, \\mathbf{f}_*)p(\\mathbf{f} | \\mathbf{y})}{p(\\mathbf{y})}, \\end{aligned} $$\n同時事前確率は、ガウス過程の定義より、カーネル関数が定める共分散行列 \\( \\mathbf{K}=(k(\\mathbf{x}_i, \\mathbf{x}_j))_{i, j} \\) を用いて\n$$ \\begin{aligned} p(\\mathbf{f}, \\mathbf{f}_*) = \\mathcal{N}\\left( \\mathbf{0}, \\left( \\begin{matrix} \\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} \u0026amp; \\mathbf{K}_{*, \\mathbf{f}} \\\\ \\mathbf{K}_{\\mathbf{f}, *} \u0026amp; \\mathbf{K}_{*, *} \\end{matrix} \\right) \\right), \\end{aligned} $$\nとなる。学習データ \\( \\mathbf{X} \\) が大きくなると \\( \\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} \\) の計算量が大きくなるので、この部分の計算量を減らすような近似を行いたいわけである。\nガウス過程の予測分布 \\( p(\\mathbf{f}_* | \\mathbf{y} ) \\) は、\n$$ \\begin{aligned} p(\\mathbf{f}_* | \\mathbf{y}) \u0026amp;= \\int p (\\mathbf{f}, \\mathbf{f}_* | \\mathbf{y}) d\\mathbf{f} \\\\ \u0026amp;= \\frac{1}{p(\\mathbf{y})} \\int p(\\mathbf{y} | \\mathbf{f}) p(\\mathbf{f}, \\mathbf{f}_*)d\\mathbf{f} \\\\ \u0026amp;= \\mathcal{N}(\\mathbf{K}_{*, \\mathbf{f}} \\widetilde{\\mathbf{K}}_{\\mathbf{f}, \\mathbf{f}}^{-1}\\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{K}_{*, \\mathbf{f}}\\widetilde{\\mathbf{K}}_{\\mathbf{f}, \\mathbf{f}}^{-1} \\mathbf{K}_{\\mathbf{f}, *}), \\end{aligned} $$ ここで \\( \\widetilde{\\mathbf{K}}_{\\mathbf{f}, \\mathbf{f}} = \\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} + \\sigma^2 \\mathbf{I} \\) である。 この式は「ガウス過程と機械学習」の公式3.8に対応し、こちらではノイズ項目 \\( \\sigma^2 \\mathbf{I} \\) もカーネルに含めているので、notationが少し違っている。\nいくつかスパース近似にはバリエーションがあるが、補助入力点 \\( \\mathbf{u}=(\\mathbf{u}_1, \\ldots, \\mathbf{u}_m)^\\top \\) を使って \\( p(\\mathbf{f}_* | \\mathbf{f}) \\)を近似するという方法は共通している。まずは近似ではなく正確に成り立っている式を確認する。\n$$ \\begin{aligned} p(\\mathbf{f}_*, \\mathbf{f}) \u0026amp;= \\int p(\\mathbf{f}_*, \\mathbf{f}, \\mathbf{u})d\\mathbf{u} \\\\ \u0026amp;= \\int p(\\mathbf{f}_*, \\mathbf{f} | \\mathbf{u})p(\\mathbf{u})d\\mathbf{u}, \\end{aligned} $$\n$$ p(\\mathbf{u}) = \\mathcal{N}(\\mathbf{0}, \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}), $$\n$$ p(\\mathbf{f} | \\mathbf{u}) = \\mathcal{N}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} - \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}}), $$\n$$ p(\\mathbf{f}_* | \\mathbf{u}) = \\mathcal{N}(\\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *}) $$\nと表される。ここで、 \\( \\mathbf{Q}_{\\mathbf{a}, \\mathbf{b}} := \\mathbf{K}_{\\mathbf{a}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{b}} \\) である。\n補助入力点 \\( \\mathbf{u} \\) を使った条件付き確率 \\( q(\\mathbf{f}_* | \\mathbf{u}), q(\\mathbf{f} | \\mathbf{u})\\) を使って、\n$$ \\begin{aligned} p(\\mathbf{f}_*, \\mathbf{f}) \u0026amp;\\simeq q(\\mathbf{f}_*, \\mathbf{f}) \\\\ \u0026amp;= \\int q(\\mathbf{f}_* | \\mathbf{u}) q(\\mathbf{f} | \\mathbf{u}) p(\\mathbf{u}) d\\mathbf{u} \\end{aligned} $$\nという近似を行う。この時の \\( q \\) の作り方が近似の手法によって異なることになる。\nThe Subset of Data (SoD) Approximation 部分データ法は元々の入力点の中から代表となる点を抜き出し、抜き出した点を新たな入力点としてガウス回帰を行うやり方。細かい説明は省略。\nThe Subset of Regressors (SoR) Approximation The Subset of Regressors Approximation (部分回帰法?, 以下SoR) は \\( \\mathbf{f}, \\mathbf{f}_* \\)の同時分布を\n$$ \\begin{aligned} q_{\\text{SoR}}(\\mathbf{f}, \\mathbf{f}_*) = \\mathcal{N}\\left( \\mathbf{0}, \\left( \\begin{matrix} \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}} \u0026amp; \\mathbf{Q}_{*, \\mathbf{f}} \\\\ \\mathbf{Q}_{\\mathbf{f}, *} \u0026amp; \\mathbf{Q}_{*, *} \\end{matrix} \\right) \\right) \\end{aligned} $$\nと近似するもので、後に出てくるDTC, FITCの基礎となる考え方である。 心持ちとしては、\n$$ \\begin{aligned} q_{\\text{SoR}}(\\mathbf{f} | \\mathbf{u}) \u0026amp;= \\mathcal{N}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{0}) \\\\ \u0026amp;\\simeq \\mathcal{N}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} - \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}}) \\\\ \u0026amp;= p(\\mathbf{f} | \\mathbf{u}), \\end{aligned} $$\n$$ \\begin{aligned} q_{\\text{SoR}}(\\mathbf{f}_* | \\mathbf{u}) \u0026amp;= \\mathcal{N}(\\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{0}) \\\\ \u0026amp;\\simeq \\mathcal{N}(\\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *}) \\\\ \u0026amp;= p(\\mathbf{f}_* | \\mathbf{u}) \\end{aligned} $$\nと、\\( p(\\mathbf{f} | \\mathbf{u}), p(\\mathbf{f}_* | \\mathbf{u}) \\) の分散を \\( 0 \\) と近似して、\\( \\mathbf{f}, \\mathbf{f}_* \\) と \\( \\mathbf{u} \\) の関係がdeterministicと仮定するものである。(deterministicの場合はもはや \\( \\mathbf{f} | \\mathbf{u}\\) は正規分布ではないので、この書き方は微妙な感じかもしれないが、論文のnotationに従った)\n仮定から \\( q_{\\text{SoR}}(\\mathbf{f}, \\mathbf{f}_* ) \\) の導出は、 同時分布が正規分布になることと、多変数正規分布の線形変換の性質から、\n$$ \\begin{aligned} \\mathbf{f} \u0026amp;= \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u} \\\\ \u0026amp; \\sim \\mathcal{N}(\\mathbf{0}, (\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1}) \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}} (\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1})^\\top) \\\\ \u0026amp; \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}}) \\\\ \u0026amp; \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}}), \\end{aligned} $$\nであり、同様に \\( \\mathbf{f}_* \\sim \\mathcal{N}(\\mathbf{0}, \\mathbf{Q}_{*, *}) \\) を得られることと、相互共分散行列の線型性から、\n$$ \\begin{aligned} \\text{cov}(\\mathbf{f}, \\mathbf{f}_*) \u0026amp;= \\text{cov}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u} ) \\\\ \u0026amp; = \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\text{cov}(\\mathbf{u}, \\mathbf{u}) (\\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1})^\\top \\\\ \u0026amp; = \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, *} \\\\ \u0026amp; = \\mathbf{Q}_{\\mathbf{f}, *}, \\end{aligned} $$\n\\( \\text{cov}(\\mathbf{f}_*, \\mathbf{f}) = \\mathbf{Q}_{*, \\mathbf{f}} \\) であることから従う。\n予測分布は、\n$$ \\begin{aligned} q_{\\text{SoR}}(\\mathbf{f}_* | \\mathbf{y}) \u0026amp; = \\mathcal{N}(\\mathbf{Q}_{*, \\mathbf{f}}(\\mathbf{Q}_{\\mathbf{f},\\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \\mathbf{y}, \\mathbf{Q}_{*, *} - \\mathbf{Q}_{*, \\mathbf{f}}(\\mathbf{Q}_{\\mathbf{f},\\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \\mathbf{Q}_{\\mathbf{f}, *}) \\end{aligned} $$\nで与えられる。これが \\( \\Sigma = (\\sigma^{-2} \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} + \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}})^{-1} \\) を用いて \\( \\mathcal{N} (\\sigma^{-2} \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{y}, \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, *} ) \\) と等しくなることを示そう。 初見でなぜこうなるか不明だった……\nまず、\n$$ \\begin{aligned} \\sigma^2 \\Sigma^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \u0026amp; = (\\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} + \\sigma^2 \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}) \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\\\ \u0026amp; = \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} (\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} + \\sigma^2 \\mathbf{I}) \\\\ \u0026amp; = \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} (\\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}} + \\sigma^2 \\mathbf{I}) \\end{aligned} $$\nであるから、\n$$ \\begin{aligned} \\mathbf{Q}_{*, \\mathbf{f}}(\\mathbf{Q}_{\\mathbf{f},\\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \u0026amp; = \\sigma^{-2} \\mathbf{K}_{*, \\mathbf{u}} \\Sigma (\\sigma^2 \\Sigma^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}}) (\\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \\\\ \u0026amp; = \\sigma^{-2} \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\end{aligned} $$\nを得る。分散の方の等号も、この式を使えば最終的に \\( \\Sigma (\\mathbf{K}_{\\mathbf{u}, \\mathbf{u}} + \\sigma^{-2}\\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}}) = \\mathbf{I} \\) に帰着させて示すことができる。\nThe Deterministic Training Conditional (DTC) Approximation DTCはSoRと似ていて、\n$$ q_{\\text{DTC}}(\\mathbf{f} | \\mathbf{u}) = \\mathcal{N}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{0}) $$\nと \\( \\mathbf{f} \\) が deterministic に \\( \\mathbf{u} \\) によって定まると仮定する。一方、出力値の方は\n$$ \\begin{aligned} q_{\\text{DTC}}(\\mathbf{f}_* | \\mathbf{u}) \u0026amp;= p(\\mathbf{f}_* | \\mathbf{u}) \\\\ \u0026amp;= \\mathcal{N}(\\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *}) \\end{aligned} $$\nと近似を行わない。\n$$ \\begin{aligned} \\text{cov}(\\mathbf{f}, \\mathbf{f}_*) \u0026amp;= \\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\text{cov}(\\mathbf{u}, \\mathbf{f}_*) \\\\ \u0026amp;= \\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{K}_{\\mathbf{u}, *} \\\\ \u0026amp;= \\mathbf{Q}_{\\mathbf{f}, *} \\end{aligned} $$ などから、\n$$ \\begin{aligned} q_{\\text{DTC}}(\\mathbf{f}, \\mathbf{f}_*) = \\mathcal{N}\\left( \\mathbf{0}, \\left( \\begin{matrix} \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}} \u0026amp; \\mathbf{Q}_{*, \\mathbf{f}} \\\\ \\mathbf{Q}_{\\mathbf{f}, *} \u0026amp; \\mathbf{K}_{*, *} \\end{matrix} \\right) \\right) \\end{aligned} $$ となる。SoRの時とほとんど同じ。入力値の近似で計算量が十分削減できる場合は、出力値のカーネルの部分で正確な値を使いたいということだろう。\n予測分布は、\n$$ \\begin{aligned} q_{\\text{DTC}}(\\mathbf{f}_* | \\mathbf{y}) \u0026amp; = \\mathcal{N}(\\mathbf{Q}_{*, \\mathbf{f}}(\\mathbf{Q}_{\\mathbf{f},\\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, \\mathbf{f}}(\\mathbf{Q}_{\\mathbf{f},\\mathbf{f}} + \\sigma^2 \\mathbf{I})^{-1} \\mathbf{Q}_{\\mathbf{f}, *}) \\\\ \u0026amp; = \\mathcal{N} (\\sigma^{-2} \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *} + \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, *} ) \\end{aligned} $$\nとなる。これはSoRの時の結果からすぐに従う。\nThe Fully Independent Training Conditional (FITC) Approximation いよいよ、当初の目的だったFITCまでたどり着いた。FITCは、DTCとほぼ同じだが、 DTCでは切り捨てていた \\( q(\\mathbf{f} | \\mathbf{u}) \\) の分散を考慮する。\nただ、分散共分散行列をフルで計算したくない (フルで計算すると近似を行わない通常のガウス回帰である) ので、 出力値の間の相関を無視して、対角線の部分だけを計算する。つまり、\n$$ q_{\\text{FITC}}(\\mathbf{f} | \\mathbf{u}) = \\mathcal{N}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\text{diag}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} - \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}})) $$\n$$ \\begin{aligned} q_{\\text{FITC}}(\\mathbf{f}_* | \\mathbf{u}) \u0026amp;= p(\\mathbf{f}_* | \\mathbf{u}) \\\\ \u0026amp;= \\mathcal{N}(\\mathbf{K}_{*, \\mathbf{u}} \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}}^{-1} \\mathbf{u}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *}) \\end{aligned} $$\nとなる。今までと同じように計算して、同時分布\n$$ \\begin{aligned} q_{\\text{FITC}}(\\mathbf{f}, \\mathbf{f}_*) = \\mathcal{N}\\left( \\mathbf{0}, \\left( \\begin{matrix} \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}} + \\text{diag}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} - \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}}) \u0026amp; \\mathbf{Q}_{*, \\mathbf{f}} \\\\ \\mathbf{Q}_{\\mathbf{f}, *} \u0026amp; \\mathbf{K}_{*, *} \\end{matrix} \\right) \\right) \\end{aligned} $$\nと予測分布\n$$ \\begin{aligned} q_{\\text{FITC}}(\\mathbf{f}_* | \\mathbf{y}) \u0026amp; = \\mathcal{N}(\\mathbf{Q}_{*, \\mathbf{f}}(\\mathbf{Q}_{\\mathbf{f},\\mathbf{f}} + \\Lambda)^{-1} \\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, \\mathbf{f}}(\\mathbf{Q}_{\\mathbf{f},\\mathbf{f}} + \\Lambda)^{-1} \\mathbf{Q}_{\\mathbf{f}, *}) \\\\ \u0026amp; = \\mathcal{N} (\\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\Lambda^{-1} \\mathbf{y}, \\mathbf{K}_{*, *} - \\mathbf{Q}_{*, *} + \\mathbf{K}_{*, \\mathbf{u}} \\Sigma \\mathbf{K}_{\\mathbf{u}, *} ) \\end{aligned} $$\nを得る。ここで、 \\( \\Sigma = (\\mathbf{K}_{\\mathbf{u}, \\mathbf{f}} \\Lambda^{-1} \\mathbf{K}_{\\mathbf{f}, \\mathbf{u}} + \\mathbf{K}_{\\mathbf{u}, \\mathbf{u}})^{-1}, \\Lambda = \\text{diag}(\\mathbf{K}_{\\mathbf{f}, \\mathbf{f}} - \\mathbf{Q}_{\\mathbf{f}, \\mathbf{f}} + \\sigma^2 \\mathbf{I}) \\) である。\n最後に 統一的な枠組みで SoD, SoR, DTC, FITC と順に読んでいくことで補助変数法を一望することができて面白かった。\n本文では、一部の相関を無視しないで考える The Partially Independent Training Conditional (PITC) や Inducing Variables の選び方についても触れられているようだ。\n時間があれば、各補助変数法を実際に実装してみて、回帰結果がどの程度変わるのか確認してみたい。\n-\u0026gt; やりました\nガウス過程の補助変数法をJuliaで実装、回帰結果を比較\n",
    "permalink": "https://matsueushi.github.io/posts/sparse-approximate-gp/",
    "tags": [
      "GaussianProcess",
      "InducingVariableMethod",
      "SparseApproximation",
      "SoD",
      "SoR",
      "DTC",
      "FITC"
    ],
    "title": "ガウス過程の補助変数法 (Inducing variable method) を理解する"
  },
  {
    "contents": "500ms by Softman たまたまbandcampを徘徊していたら出会ったGlitch。\n言葉で表現するのが難しいのだが、パソコンとか家電の起動音とか動作音とかの一番綺麗な部分が切り取られて、ノイズと共に閉じ込められて音楽になったような感じだろうか……\nシンガポールのアンビエントレーベルEvening Chantsというところからリリースされていて、フィジカルはカセットテープのみ。\nレーベルは2018年の9月に立ち上がったばかりで、他のリリースも配信とカセットテープなので何かこだわりがあるのかと思ったが、 このような記事もあったので、アンビエント界隈ではカセットテープリリースというのがよくあることなのかもしれない。\nロンドンベースのミュージシャンということ以外Softmanの素性は不明(bandcampに写真は載っている)で、 Twitterやウェブサイトでの言及もほとんど見つからず、謎が多い。\n“The track listings avoids implying anything or to artificially making you feel something - just face value. It’s not meant to be about anything,”\nhttps://softman.bandcamp.com/album/500ms\nと書かれているので、細かいことは追求せず純粋にノイズの美しい揺らめきに耳を傾けよう。\n好きな曲: 500ms_07, 500ms_12, 500ms_22\n",
    "permalink": "https://matsueushi.github.io/posts/softman-500ms/",
    "tags": [
      "Music",
      "Softman"
    ],
    "title": "Softman - 500ms (2018)"
  },
  {
    "contents": "「ガウス過程と機械学習」を3章まで読み終えたので、復習を兼ねてJulia(1.1.0)でガウス過程を実装し、 カーネルのハイパーパラメーターをOptim.jlで推定するところまでをまとめる。数学的に細かい内容は本を読んで欲しい。 図3.23の陸上男子100mの世界記録の回帰モデルを作成することを今回の目標とする。\nガウスカーネルによる回帰: ガウスカーネル＋線形カーネルによる回帰: 任意の有限の入力 \\( x_1, \\ldots , x_n \\) を与えたときに、出力 \\( (f(x_1), \\ldots , f(x_n)) \\) が平均 \\( (\\mu(x_1), \\ldots , \\mu(x_n)) \\) 分散 \\( (k(x_n, x_{nm} )) \\) のガウス分布に従う時、 \\( f \\) をガウス過程と呼び、 \\( f \\sim \\text{GP} (\\mu(x), k(x, x^\\prime)) \\) と書く。そして \\( \\mu \\) を平均関数、 \\( k \\) をカーネル関数と呼んでいるのであった。\n今回は本と同様、簡単のために平均関数が恒等的に0となるものだけを考える。\nガウスカーネルの定義 もっとも基本的なカーネルであるガウスカーネルを定義して、ガウス過程を構成する。ガウスカーネルのカーネル関数は次のものとする。 $$ k(x, x^\\prime ) = \\exp \\left( -\\frac{|x-x^\\prime|^2}{\\theta}\\right) $$ 本文では $$ k(x, x^\\prime ) = \\theta_1 \\exp \\left( -\\frac{|x-x^\\prime|^2}{\\theta_2}\\right) $$ この形で紹介されていたが、後々カーネルの線型結合を考えるのでここでは \\( \\exp \\) の前に係数を付けない前者を採用する。\nabstract type Kernel end function cov(k::Kernel, xs1, xs2) # covariance matrix n1 = size(xs1, 1) n2 = size(xs2, 1) c = zeros(n1, n2) for i in 1:n1 for j in 1:n2 c[i, j] = ker(k, xs1[i, :], xs2[j, :]) end end c end cov(k::Kernel, xs) = cov(k, xs, xs) \u0026#34;\u0026#34;\u0026#34; Gaussian Kernel \u0026#34;\u0026#34;\u0026#34; mutable struct GaussianKernel \u0026lt;: Kernel theta::Float64 end function ker(k::GaussianKernel, x1, x2) exp(- sum((x1 - x2).^2) / k.theta) end 分散共分散行列を計算する cov 関数とガウスカーネルを定義した。 mutable にしたのは、後々パラメーター推定をするときにパラメーターの更新をするため。\nusing Distributions using Plots gk = GaussianKernel(1) xs = collect(-4:0.5:4) gk_dist = MvNormal(zeros(Base.length(xs)), cov(gk, xs)) Plots.plot(xs, rand(gk_dist, 5), label = \u0026#34;\u0026#34;, xlabel = \u0026#34;x\u0026#34;, ylabel = \u0026#34;f\u0026#34;, linewidth = 2, title = \u0026#34;\u0026#34;) \\( \\theta=1 \\)のガウスカーネルから生成されるガウス過程から、入力を-4から4まで0.5ごとに選んだ点とし、サンプルをいくつか取ってみる。\nガウス過程の定義 上でガウスカーネルを定義した方法には一つ問題があり、例えば点を0.1毎に取ると上手く動かない。\nxs = collect(1:0.1:4) gk_dist = MvNormal(zeros(Base.length(xs)), cov(gk, xs)) Plots.plot(xs, rand(gk_dist, 5), label = \u0026#34;\u0026#34;, xlabel = \u0026#34;x\u0026#34;, ylabel = \u0026#34;f\u0026#34;, linewidth = 2, title = \u0026#34;\u0026#34;) PosDefException: matrix is not positive definite; Cholesky factorization failed. Stacktrace: [1] checkpositivedefinite at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/factorization.jl:11 [inlined] [2] #cholesky!#96(::Bool, ::Function, ::LinearAlgebra.Hermitian{Float64,Array{Float64,2}}, ::Val{false}) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/cholesky.jl:153 [3] #cholesky! at ./none:0 [inlined] [4] #cholesky!#97(::Bool, ::Function, ::Array{Float64,2}, ::Val{false}) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/cholesky.jl:185 [5] #cholesky#101 at ./none:0 [inlined] [6] cholesky at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/cholesky.jl:275 [inlined] (repeats 2 times) [7] Type at /Users/apple/.julia/packages/PDMats/AObTs/src/pdmat.jl:19 [inlined] [8] MvNormal(::Array{Float64,1}, ::Array{Float64,2}) at /Users/apple/.julia/packages/Distributions/wY4bz/src/multivariate/mvnormal.jl:196 [9] top-level scope at In[18]:6 問題が発生した原因は、 cov 関数により生成される分散共分散行列が正定値にならないことである。対策としては、分散共分散行列の対角成分に小さい数を加えて行列が正定値になるようにすれば良い。（1.4のリッジ回帰の説明を参照)\n各成分ごとにカーネル関数を計算した結果得られる分散共分散行列に、単位行列の定数倍を加えて最終的に使う分散共分散行列を作るというのは、観測ノイズを考慮した観測モデルを考えるときも同じなので、今回はガウス回帰モデルを次のように定義する。\nusing LinearAlgebra \u0026#34;\u0026#34;\u0026#34; Gaussian Process \u0026#34;\u0026#34;\u0026#34; mutable struct GaussianProcess{K \u0026lt;: Kernel} kernel::K eta::Float64 # regularization parameter GaussianProcess(kernel::K) where {K \u0026lt;: Kernel} = new{K}(kernel, 1e-6) GaussianProcess(kernel::K, eta::Real) where {K \u0026lt;: Kernel} = new{K}(kernel, Float64(eta)) end function cov(gp::GaussianProcess, xs) # regularlize n = size(xs, 1) cov(gp.kernel, xs) + gp.eta * Matrix{Float64}(I, n, n) end function dist(gp::GaussianProcess, xs) l = size(xs, 1) k = cov(gp, xs) MvNormal(zeros(l), k) end ここでは、 eta が観測ノイズの項目に相当し、観測値にノイズがないものとして考える場合は分散共分散行列の正則化のため対角成分に1e-6を加えることにする。xs の刻みを細かくしてサンプリングできることを確認しよう。\ngp = GaussianProcess(GaussianKernel(1)) xs = collect(-4:0.1:4) Plots.plot(xs, rand(dist(gp, xs), 5), label = \u0026#34;\u0026#34;, xlabel = \u0026#34;x\u0026#34;, ylabel = \u0026#34;f\u0026#34;, linewidth = 2, title = \u0026#34;\u0026#34;) xs = collect(-4:0.01:4) Plots.plot(xs, rand(dist(gp, xs), 5), label = \u0026#34;\u0026#34;, xlabel = \u0026#34;x\u0026#34;, ylabel = \u0026#34;f\u0026#34;, linewidth = 2, title = \u0026#34;\u0026#34;) )\nノイズ項を入れるとこんな感じ\ngp = GaussianProcess(GaussianKernel(1), 0.01) xs = collect(-4:0.01:4) Plots.plot(xs, rand(dist(gp, xs), 5), label = \u0026#34;\u0026#34;, xlabel = \u0026#34;x\u0026#34;, ylabel = \u0026#34;f\u0026#34;, linewidth = 2, title = \u0026#34;\u0026#34;) 同様に定数カーネル、線形カーネルも定義しておこう。(その他のカーネルにも本文には出てくるが、ここでは省略)\n\u0026#34;\u0026#34;\u0026#34; Constant kernel \u0026#34;\u0026#34;\u0026#34; struct ConstantKernel \u0026lt;: Kernel end function ker(k::ConstantKernel, x1, x2) return 1.0 end \u0026#34;\u0026#34;\u0026#34; Linear kernel \u0026#34;\u0026#34;\u0026#34; struct LinearKernel \u0026lt;: Kernel end function ker(k::LinearKernel, x1, x2) return 1.0 + dot(x1, x2) end LinearKernelのカーネルの実装では、定数項を考慮するために1を加えている。サンプルをプロットするとそれぞれ下のようになる（コードは略）\nカーネルの定数倍、和 本文3.3.2にあるように、カーネルは組み合わせて使うことができ、カーネルの和・積もまたカーネル関数になる。\n今回、ガウスカーネル、ガウスカーネル＋線形カーネルを考えるにあたっては、カーネルの定数倍、カーネルの和が定義されていれば十分なので、その二つを定義しておこう。\nimport Base: +, * \u0026#34;\u0026#34;\u0026#34; Scalar product \u0026#34;\u0026#34;\u0026#34; mutable struct KernelScalarProd \u0026lt;: Kernel coef::Float64 kernel::Kernel end function ker(k::KernelScalarProd, x1, x2) k.coef * ker(k.kernel, x1, x2) end \u0026#34;\u0026#34;\u0026#34; Sum \u0026#34;\u0026#34;\u0026#34; mutable struct KernelSum \u0026lt;: Kernel kernel1::Kernel kernel2::Kernel end function ker(k::KernelSum, x1, x2) ker(k.kernel1, x1, x2) + ker(k.kernel2, x1, x2) end *(coef::Real, k::Kernel) = KernelScalarProd(Float64(coef), k) +(k1::Kernel, k2::Kernel) = KernelSum(k1, k2) こんな風にカーネルの線型結合からガウス過程が定義できるようになった。下は、線形カーネルとガウスカーネルの線型結合を考えた例。\ngp = GaussianProcess(2.0 * LinearKernel() + 0.8 * GaussianKernel(0.01)) xs = collect(-1:0.01:3) Plots.plot(xs, rand(dist(gp, xs), 10), label = \u0026#34;\u0026#34;, xlabel = \u0026#34;x\u0026#34;, ylabel = \u0026#34;f\u0026#34;, linewidth = 2, title = \u0026#34;\u0026#34;) 回帰 サンプリングができたので、次に回帰を行う。\n回帰を行おう。本文の後半には、ガウス過程回帰の計算方法を少なくする方法が書いてあるが、まだそこまで読んでいないのでここは素直な方法(本の公式3.8)でガウス過程回帰を定義する。\nfunction predict(gp::GaussianProcess, xtest, xtrain, ytrain) k_star = cov(gp.kernel, xtrain, xtest) s = cov(gp, xtest) k_inv = inv(cov(gp, xtrain)) k_star_inv = k_star\u0026#39; * k_inv mu = k_star_inv * ytrain sig = s - k_star_inv * k_star MvNormal(mu, sig) end まず、パラメーターは既知のものとして、予測分布からのサンプリングと、誤差範囲を示してみよう。\nxs = [-0.5, 0.5, 1, 1.4, 3] ys = [0.7, 1.8, 1.7, 2.3, 1] gp = GaussianProcess(1.596 * GaussianKernel(6.560), 0.082) xtest = collect(range(-1, stop=3.5, length=100)) pred = predict(gp, xtest, xs, ys) qt = mapslices(x -\u0026gt; quantile(x, [0.025, 0.975]), rand(pred, 10000), dims = 2) Plots.plot(xtest, qt[:, 1], fillrange = qt[:, 2], fillalpha = 0.3, label = \u0026#34;\u0026#34;, linewidth = 0) Plots.plot!(xtest, mean(pred), label = \u0026#34;Mean\u0026#34;, linewidth = 2, linestyle = :dash) scatter!(xs, ys, label = \u0026#34;\u0026#34;, title = \u0026#34;Posterior distribution\u0026#34;) 実は、これだとうまくいかない\nPosDefException: matrix is not Hermitian; Cholesky factorization failed. Stacktrace: [1] checkpositivedefinite(::Int64) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/factorization.jl:11 [2] #cholesky!#97(::Bool, ::Function, ::Array{Float64,2}, ::Val{false}) at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/cholesky.jl:182 [3] #cholesky#101 at ./none:0 [inlined] [4] cholesky at /Users/osx/buildbot/slave/package_osx64/build/usr/share/julia/stdlib/v1.1/LinearAlgebra/src/cholesky.jl:275 [inlined] (repeats 2 times) [5] Type at /Users/apple/.julia/packages/PDMats/AObTs/src/pdmat.jl:19 [inlined] [6] Type at /Users/apple/.julia/packages/Distributions/wY4bz/src/multivariate/mvnormal.jl:196 [inlined] [7] predict(::GaussianProcess{KernelScalarProd}, ::Array{Float64,1}, ::Array{Float64,1}, ::Array{Float64,1}) at ./In[24]:10 [8] top-level scope at In[25]:7 原因は、 predict の sig が計算誤差によりSymmetricになっていないのが原因なので、predict を次のように修正する。\nfunction predict(gp::GaussianProcess, xtest, xtrain, ytrain) k_star = cov(gp.kernel, xtrain, xtest) s = cov(gp, xtest) k_inv = inv(cov(gp, xtrain)) k_star_inv = k_star\u0026#39; * k_inv mu = k_star_inv * ytrain sig = Symmetric(s - k_star_inv * k_star) MvNormal(mu, sig) end すると、次のような結果が得られる。\n微分を定義する 学習データを \\( \\mathcal{D}=(\\mathbf{X}, \\mathbf{y}) \\), ハイパーパラメーターを \\( \\boldsymbol{\\theta} \\), ハイパーパラメータから計算されるカーネル行列を \\( \\mathbf{K}_\\boldsymbol{\\theta} \\) とした時に、対数尤度関数\n$$ L := -\\log | \\mathbf{K}_\\boldsymbol{\\theta} | - \\mathbf{y}^T \\mathbf{K}_\\boldsymbol{\\theta}^{-1} \\mathbf{y} $$\nを最大化するハイパーパラメーターを勾配法で求めよう。\\( L \\) の偏微分は、\n$$ \\frac{\\partial L}{\\partial \\theta} = \\text{tr} \\left( \\mathbf{K}_\\boldsymbol{{\\theta}}^{-1} \\frac{\\partial \\mathbf{K}_\\boldsymbol{\\theta}}{\\partial \\theta} \\right) + (\\mathbf{K}_\\boldsymbol{\\theta}^{-1} \\mathbf{y})^T \\frac{\\partial \\mathbf{K}_\\boldsymbol{\\theta}}{\\partial \\theta} (\\mathbf{K}_\\boldsymbol{\\theta}^{-1} \\mathbf{y})$$\nだった。パラメータ \\( \\theta \\in \\boldsymbol{\\theta} \\) は \\( \\theta \u0026gt; 0 \\) でなくてはならないので、\\( \\tau = \\log \\theta \\) と変換して \\( \\tau \\) を最適化する。つまり、実際に勾配法で使う偏微分は $$ \\frac{\\partial L}{\\partial \\tau} = \\frac{\\partial L}{\\partial \\theta} \\frac{\\partial \\theta}{\\partial \\tau} = \\theta \\frac{\\partial L}{\\partial \\theta}$$ である。同様に \\( \\frac{\\partial \\mathbf{K}_\\boldsymbol{\\theta}}{\\partial \\tau} = \\theta \\frac{\\partial \\mathbf{K}_\\boldsymbol{\\theta}}{\\partial \\theta} \\) だから、\\( \\theta \\) の代わりに \\( \\tau \\) を考えて\n$$ \\frac{\\partial L}{\\partial \\tau} = \\text{tr} \\left( \\mathbf{K}_\\boldsymbol{{\\theta}}^{-1} \\frac{\\partial \\mathbf{K}_\\boldsymbol{\\theta}}{\\partial \\tau} \\right) + (\\mathbf{K}_\\boldsymbol{\\theta}^{-1} \\mathbf{y})^T \\frac{\\partial \\mathbf{K}_\\boldsymbol{\\theta}}{\\partial \\tau} (\\mathbf{K}_\\boldsymbol{\\theta}^{-1} \\mathbf{y})$$\nを計算する。まずは GaussianKernel, ConstantKernel, LinearKernel の微分を定義する。パラメーターごとの偏微分したもののリストを返すことにする ConstantKernel, LinearKernel はパラメーターを持たないので、空のリストを返しておく。\nfunction logderiv(k::GaussianKernel, x1, x2) [ker(k, x1, x2) / k.theta * sum((x1 - x2).^2)] end function logderiv(k::ConstantKernel, x1, x2) [] end function logderiv(k::LinearKernel, x1, x2) [] end カーネルの定数倍、和に対して、元のカーネルの微分を利用して微分を定義する。\nfunction logderiv(k::KernelScalarProd, x1, x2) [ker(k.kernel, x1, x2), k.coef * logderiv(k.kernel, x1, x2)...] end function logderiv(k::KernelSum, x1, x2) [logderiv(k.kernel1, x1, x2)..., logderiv(k.kernel2, x1, x2)...] end Optim.jlによる最適化 微分を定義したので、Optim.jl で最適化しよう。\nまず、カーネルのパラメーターを更新する update! を定義。\nfunction update!(k::GaussianKernel, theta) k.theta = Float64(theta) k end update!(k::ConstantKernel) = k update!(k::LinearKernel) = k function update!(gp::GaussianProcess, params...) update!(gp.kernel, params[1:end - 1]...) gp.eta = params[end] gp end これを和と定数倍の場合にも延長する。和のカーネルを更新する時に、ぞれぞれのカーネルのパラメーターの数を知る必要がある。Base.length をカーネル、ガウス過程に対して拡張しよう。\nBase.length(k::Kernel) = Base.length(fieldnames(typeof(k))) Base.length(k::KernelScalarProd) = 1 + Base.length(k.kernel) Base.length(k::KernelSum) = Base.length(k.kernel1) + Base.length(k.kernel2) Base.length(gp::GaussianProcess) = Base.length(gp.kernel) + 1 これでようやく和と定数倍の場合の update が定義できる。\nfunction update!(k::KernelScalarProd, params...) k.coef = params[1] update!(k.kernel, params[2:end]...) k end function update!(k::KernelSum, params...) l = Base.length(k.kernel1) update!(k.kernel1, params[1:l]...) update!(k.kernel2, params[l+1:end]...) k end 対数尤度関数と微分では共通する計算があるので、\nAvoid repeating computations\nhttps://julianlsolvers.github.io/Optim.jl/stable/#user/tipsandtricks/#avoid-repeating-computations\nを参考にして fg! を定義。Optim.jlは関数の最小化を行うため、fg! では \\( -L \\) の値と微分を計算している。(ついでに対数尤度も定義しておく)\nfunction logp(gp::GaussianProcess, xs, ys) k = cov(gp, xs) k_inv = inv(k) -log(det(k)) - ys\u0026#39; * k_inv * ys end function fg!(gp::GaussianProcess, xs, ys, F, G, params) # -logp and gradient y = exp.(params) update!(gp, y...) k = cov(gp, xs) k_inv = inv(k) k_inv_y = k_inv * ys n = size(xs, 1) function deriv(d_mat::Matrix{\u0026lt;: Real}) -(-tr(k_inv * d_mat) + k_inv_y\u0026#39; * d_mat * k_inv_y) end # gradient if G != nothing d_tensor = zeros(n, n, Base.length(gp)) for i in 1:n for j in 1:n t = logderiv(gp.kernel, xs[i, :], xs[j, :]) d_tensor[i, j, 1:end - 1] = t end end # eta d_tensor[:, :, end] = y[end] .* Matrix{Float64}(I, n, n) G .= mapslices(deriv, d_tensor, dims = [1, 2])[:] end # log likelihoood if F != nothing return -(-log(det(k)) - ys\u0026#39; * k_inv * ys) end end まずは図3.16のデータでハイパーパラメーターを推定しよう。推定したいハイパーパラメータの形は $$ k(\\mathbf{x}, \\mathbf{x}^\\prime \\mid \\boldsymbol{\\theta}) = \\theta_1 \\exp \\left( - \\frac{|\\mathbf{x} - \\mathbf{x}^\\prime |^2}{\\theta_2} \\right) + \\theta_3 \\delta (\\mathbf{x}, \\mathbf{x}^\\prime) $$ だから、パラメーターを仮置きして下のようにガウス過程を定義する。\ngp = GaussianProcess(1.0 * GaussianKernel(1.0), 1.0) Optim.jlのGradientDescent を使ってパラメーターを推定する。実際のハイパーパラメーターに戻すために、最後に exp を取っている。\nusing Optim lower = fill(-30.0, 3) upper = fill(30.0, 3) res = optimize( Optim.only_fg!((F, G, x) -\u0026gt; fg!(gp, xs, ys, F, G, x)), lower, upper, [0.0, 0.0, 0.0], Fminbox(GradientDescent())) println(res) pars = Optim.minimizer(res) println(\u0026#34;[theta1, theta2, theta3] = \u0026#34;, exp.(pars)) Results of Optimization Algorithm * Algorithm: Fminbox with Gradient Descent * Starting Point: [0.0,0.0,0.0] * Minimizer: [0.4677728528438338,1.8810363129622452, ...] * Minimum: 1.738770e+00 * Iterations: 3 * Convergence: true * |x - x\u0026#39;| ≤ 0.0e+00: false |x - x\u0026#39;| = 6.21e-08 * |f(x) - f(x\u0026#39;)| ≤ 0.0e+00 |f(x)|: false |f(x) - f(x\u0026#39;)| = 9.45e-15 |f(x)| * |g(x)| ≤ 1.0e-08: true |g(x)| = 9.23e-09 * Stopped by an increasing objective: false * Reached Maximum Number of Iterations: false * Objective Calls: 353 * Gradient Calls: 353 [theta1, theta2, theta3] = [1.59643, 6.5603, 0.0819847] 男子100m走の世界記録のデータを使ったハイパーパラメーター推定 長くなったが、最後に、本と同様、男子100m走の世界記録のデータを使ってハイパーパラメーターを推定してみよう。\nusing CSV using Dates using DataFrames df = CSV.read(IOBuffer( \u0026#34;Date,Time 1964/10/15,10.06 1968/6/20,10.03 1968/10/13,10.02 1968/10/14,9.95 1983/7/3,9.93 1987/8/30,9.93 1988/8/17,9.93 1988/9/24,9.92 1991/7/14,9.9 1991/8/25,9.86 1994/7/6,9.85 1996/7/27,9.84 1999/6/16,9.79 2002/9/14,9.78 2005/6/14,9.77 2006/5/12,9.77 2006/6/11,9.77 2006/8/18,9.77 2007/9/9,9.74 2008/5/31,9.72 2008/8/16,9.69 2009/8/16,9.58\u0026#34;); dateformat=\u0026#34;yyyy/mm/dd\u0026#34;) disallowmissing!(df) scatter(df.Date, df.Time, label=\u0026#34;\u0026#34;) 値を平均0, 分散1となるように正規化する。\nusing Dates xs_raw = Dates.value.(df.Date .- Date(0, 1, 1)) ./ 365 xs_mean, xs_std = mean(xs_raw), std(xs_raw) ys_raw = df.Time ys_mean, ys_std = mean(ys_raw), std(ys_raw) xs = (xs_raw .- xs_mean) ./ xs_std ys = (ys_raw .- ys_mean) ./ ys_std scatter(xs, ys, label=\u0026#34;\u0026#34;) LBFGS でハイパーパラメーターを推定する。[0, 0, 0] からスタートすると、\nfunction plot_gp_100m(gp, pars) update!(gp, exp.(pars)...) x_test = collect(range(-2, stop=2, length=100)) pred = predict(gp, x_test, xs, ys) qt = mapslices(x -\u0026gt; quantile(x, [0.025, 0.975]), rand(pred, 10000), dims = 2) # convert x_test = x_test .* xs_std .+ xs_mean qt = qt .* ys_std .+ ys_mean Plots.plot(x_test, qt[:, 1], fillrange = qt[:, 2], fillalpha = 0.3, label = \u0026#34;\u0026#34;, linewidth = 0) Plots.plot!(x_test, mean(pred) .* ys_std .+ ys_mean, label = \u0026#34;\u0026#34;, linewidth = 2, linestyle = :dash) scatter!(xs_raw, ys_raw, label = \u0026#34;\u0026#34;) end gp = GaussianProcess(1.0 * GaussianKernel(1.0), 1.0) res = optimize( Optim.only_fg!((F, G, x) -\u0026gt; fg!(gp, xs, ys, F, G, x)), fill(-10.0, 3), fill(10.0, 3), [0.0, 0.0, 0.0], Fminbox(LBFGS())) println(res) pars = Optim.minimizer(res) println(\u0026#34;[theta1, theta2, theta3] = \u0026#34;, exp.(pars)) println(\u0026#34;logp:\u0026#34;, logp(gp, xs, ys)) plot_gp_100m(gp, pars) Results of Optimization Algorithm * Algorithm: Fminbox with L-BFGS * Starting Point: [0.0,0.0,0.0] * Minimizer: [1.4404906589345008,2.6294999978819886, ...] * Minimum: -1.486413e+01 * Iterations: 20 * Convergence: true * |x - x\u0026#39;| ≤ 0.0e+00: true |x - x\u0026#39;| = 0.00e+00 * |f(x) - f(x\u0026#39;)| ≤ 0.0e+00 |f(x)|: true |f(x) - f(x\u0026#39;)| = 0.00e+00 |f(x)| * |g(x)| ≤ 1.0e-08: false |g(x)| = 5.07e-08 * Stopped by an increasing objective: true * Reached Maximum Number of Iterations: false * Objective Calls: 7536 * Gradient Calls: 7536 [theta1, theta2, theta3] = [4.22277, 13.8668, 0.102625] logp:14.864131619224107 となって本に載っているのとは別の局所解に収束してしまう。[0, 0, -3] からスタートすると、\nres = optimize( Optim.only_fg!((F, G, x) -\u0026gt; fg!(gp, xs, ys, F, G, x)), fill(-10.0, 3), fill(10.0, 3), [0.0, 0.0, -3.0], Fminbox(LBFGS())) println(res) pars = Optim.minimizer(res) println(\u0026#34;[theta1, theta2, theta3] = \u0026#34;, exp.(pars)) println(\u0026#34;logp:\u0026#34;, logp(gp, xs, ys)) plot_gp_100m(gp, pars) Results of Optimization Algorithm * Algorithm: Fminbox with L-BFGS * Starting Point: [0.0,0.0,-3.0] * Minimizer: [0.4403584574143354,-1.4741097963164387, ...] * Minimum: -1.407396e+01 * Iterations: 5 * Convergence: true * |x - x\u0026#39;| ≤ 0.0e+00: true |x - x\u0026#39;| = 0.00e+00 * |f(x) - f(x\u0026#39;)| ≤ 0.0e+00 |f(x)|: true |f(x) - f(x\u0026#39;)| = 0.00e+00 |f(x)| * |g(x)| ≤ 1.0e-08: false |g(x)| = 1.45e-08 * Stopped by an increasing objective: true * Reached Maximum Number of Iterations: false * Objective Calls: 331 * Gradient Calls: 331 [theta1, theta2, theta3] = [1.55326, 0.228982, 0.0429989] logp:14.073964533876048 と、本と同様の回帰結果が得られる。(パラメーターの値は本と違ってしまっているが\u0026hellip;)\n最後に、ガウスカーネル + 線形カーネルによる回帰を行ってみよう。\ngp_2 = GaussianProcess(1.0 * ConstantKernel() + 1.0 * LinearKernel() + 1.0 * GaussianKernel(1.0), 1.0) res = optimize( Optim.only_fg!((F, G, x) -\u0026gt; fg!(gp_2, xs, ys, F, G, x)), fill(-10.0, 5), fill(10.0, 5), [0.0, 0.0, 0.0, 0.0, -3.0], Fminbox(LBFGS())) println(res) pars = Optim.minimizer(res) println(\u0026#34;[theta1, theta2, theta3, theta4, theta5] = \u0026#34;, exp.(pars)) println(\u0026#34;logp:\u0026#34;, logp(gp_2, xs, ys)) plot_gp_100m(gp_2, pars) Results of Optimization Algorithm * Algorithm: Fminbox with L-BFGS * Starting Point: [0.0,0.0,0.0,0.0,-3.0] * Minimizer: [-3.591175043240611,-0.6634886622587809, ...] * Minimum: -1.970913e+01 * Iterations: 12 * Convergence: true * |x - x\u0026#39;| ≤ 0.0e+00: true |x - x\u0026#39;| = 0.00e+00 * |f(x) - f(x\u0026#39;)| ≤ 0.0e+00 |f(x)|: true |f(x) - f(x\u0026#39;)| = 0.00e+00 |f(x)| * |g(x)| ≤ 1.0e-08: false |g(x)| = 6.18e+00 * Stopped by an increasing objective: true * Reached Maximum Number of Iterations: false * Objective Calls: 4960 * Gradient Calls: 4960 [theta1, theta2, theta3, theta4, theta5] = [0.0275659, 0.515051, 0.110337, 0.0252142, 0.0470559] logp:19.709131389510937 内容をまとめたJupyter Notebook -\u0026gt;\nhttps://nbviewer.jupyter.org/github/matsueushi/notebook_blog/blob/master/gp_blog.ipynb\nカーネル部分をjlファイルに分離し、指数カーネルや周期カーネルも定義したレポジトリはこちら -\u0026gt;\nhttps://github.com/matsueushi/gp_and_mlp\n",
    "permalink": "https://matsueushi.github.io/posts/gp-parameter-estimation/",
    "tags": [
      "Julia",
      "GaussianProcess",
      "ML",
      "Optim"
    ],
    "title": "Juliaでガウス過程を実装\u0026パラメーター推定"
  },
  {
    "contents": "過去のポストをこっちのGitHub Pagesに移行させた。疲れた。\n",
    "permalink": "https://matsueushi.github.io/posts/hugo/",
    "tags": null,
    "title": "GitHub Pagesに引っ越した"
  },
  {
    "contents": "結構手間取った。\nバックスラッシュを4つ重ねた後スペースを置く \\\\\\\\ と改行できる。\n\\\\( \\begin{aligned} x \u0026amp;= 1+1 \\\\\\\\ \u0026amp;= 2 \\end{aligned} \\\\) 結果:\n\\( \\begin{aligned} x \u0026amp;= 1+1 \\\\ \u0026amp;= 2 \\end{aligned} \\)\n参考 :\nCannot achieve line break in multiline equation (LaTeX/Mathjax)\nhttps://github.com/gcushen/hugo-academic/wiki/FAQ\n",
    "permalink": "https://matsueushi.github.io/posts/katex-multiline/",
    "tags": [
      "KaTeX"
    ],
    "title": "KaTeXで複数行の数式を入力"
  },
  {
    "contents": "KaTeX Test\n\\( \\lim \\sum \\int \\)\nKatexでは \\( \\varprojlim \\) はサポートされていない\n_ではなく\\_を使うと \\( x_{mn} \\)などの添字が出せる\n",
    "permalink": "https://matsueushi.github.io/posts/katex-test/",
    "tags": [
      "test",
      "KaTeX"
    ],
    "title": "KaTeX Test"
  },
  {
    "contents": "引き続き「ガウス過程と機械学習(第二刷)」を読み進めJuliaで実装している。\nハイパーパラメーターの最適化(勾配を使わず、Optim.jlの optimize を使ってしまった)のところまで読み進めた。\n3.4.2のガウス過程回帰の計算を行う際、予測分布の分散共分散行列が計算誤差の影響で対称行列にならずエラーが発生することがあったので、場合によっては対称化が必要。 図3.16のガウスカーネル\n\\( \\begin{aligned} k(x, x^\\prime) = \\theta_1 \\exp \\left( - \\frac{|x-x^\\prime|^2}{\\theta_2} \\right) \\end{aligned} \\) のパラメーター推定で、\\( (\\theta_1, \\theta_2, \\theta_3)=(1, 0.4, 0.1) \\) とすると下のようになり本と違ってしまった。 \\( (\\theta_1, \\theta_2, \\theta_3)=(1, 0.4, 0.01) \\) とすると近い図になる(全く同じには見えない)\n尤度の計算が合わなかった。尤度を図示した図3.16で-5未満を切り捨てるとうまくいかなかった。20以下を切り捨てると近い図になった。 本文の局所解(ii)に該当する点の尤度は-2.0299となり本文の-1.934とは違ってしまった。\n図3.20のパラメーター推定は正しくできたが、こちらも対数尤度が違ってしまった((a):本文-1.788、実装-1.738, (b):本文-2.174, 実装-2.5029) 詳細は下のレポジトリ、ノートブックを見て下さい。更新は下のMedium用のブランチではなく、masterの方に行う予定です。\nhttps://github.com/matsueushi/gp_and_mlp/tree/blog-2019-05-19\nhttps://nbviewer.jupyter.org/github/matsueushi/gp_and_mlp/blob/blog-2019-05-19/gp.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/gp-nlp-2/",
    "tags": [
      "Julia",
      "GaussianProcess",
      "MLP"
    ],
    "title": "ガウス過程と機械学習: 3.5まで"
  },
  {
    "contents": "持橋・大羽の「ガウス過程と機械学習」を読み始めた。Juliaでコードを書きながら内容を確かめている。\n本を読むまで定義も理解していなかったレベルだったが、無限次元のガウス分布を考えるというモチベーションから「有限次元に制限すれば(通常の)ガウス分布になるもの」としてガウス過程の定義が出てくるのは非常に自然だと思った。\n分散共分散行列の成分を作る時に使われるカーネル \\( k(x,x^\\prime) \\) は \\( x \\) と \\(x^\\prime \\) の「近さ」を表す関数とでも考えれば良いのだろうか。\nなんでそういうことを考えるのかという気持ちの部分が丁寧に説明されているので意図がわからずに数式の中に闇雲に迷い込むことなく今の所楽しく読み進められている。\nエラッタ:\nhttp://chasen.org/~daiti-m/gpbook/errata.html\nhttps://scrapbox.io/GPandML2019/support\n3.3の「ガウス過程とカーネル」のところまで読んだ。\n自分が躓いた点\n“3.2.4 ガウス過程からのサンプル”で図3.9のようなサンプルを実装するときは正則化項を入れないと計算がうまくいかないことがある(1.4 リッジ回帰の部分で触れられている)。著者のサンプルコードでは非常に正則化項として1e-6を導入していた。共分散行列の計算の際に対角成分に正規化項を加えればよい。 “3.3.1 ガウス過程のRBFカーネル”で、線形モデルの基底関数のグリッドを無限に細かくするとRBFカーネルになると書かれている部分は、本文中の基底関数を使うと \\( H \\rightarrow \\infty \\) とした時にカーネル関数がRBF関数に収束しない。基底関数に \\( 1 / \\sqrt{H} \\) を掛けたものを考えればOK “3.3.2 さまざまなカーネル”で線形カーネルを実装するときに、カーネル関数は dot(x1, x2) ではなく、必ず1となる入力の最初の次元も考慮して 1 + dot(x1, x2) とする。他のカーネルの場合は x1 — x2 の計算の段階で消えるので考慮する必要はない また、Matérnカーネルを定義する際に、Juliaでは第二種のベッセル関数は SpecialFunctions の besselk を使えば良い。ベッセル関数は \\( x=0 \\) で特異性を持つので、カーネル関数 k(x1, x2) を定義するときは x1 = x2 の時に条件分岐で1を返すようにすればいい カーネルとガウシアン過程を定義したjlファイル:\nhttps://github.com/matsueushi/gp_and_mlp/blob/blog-2019-05-10/gp.jl\n3.3章までのノートブック:\nhttps://nbviewer.jupyter.org/github/matsueushi/gp_and_mlp/blob/blog-2019-05-10/gp.ipynb\n引き続き3.4章の回帰モデルから読む予定。\n",
    "permalink": "https://matsueushi.github.io/posts/gp-nlp-1/",
    "tags": [
      "Julia",
      "GaussianProcess",
      "MLP"
    ],
    "title": "「ガウス過程と機械学習」を読み始めた"
  },
  {
    "contents": "公式ドキュメントでは記述が見つけられなかったが、 LocationScale を使えば良いっぽい。\nDistributions.jl/src/univariate/continuous/locationscale.jl https://github.com/JuliaStats/Distributions.jl/blob/master/src/univariate/continuous/locationscale.jl\n例えば、PyMC3の StudentT\npm.StudentT(\u0026#39;x\u0026#39;, nu=nu, mu=mu, lam=lam) に対応する分布をDistribution.jlで使いたいとき、Distribution.jlでの TDist のパラメトライズは nu だけで mu や lam は指定できないが、\nLocationScale(mu, lam, TDist(nu)) とすればOK。PyMCの StudentT に出ている pdf と同じグラフを書いて確認しよう。\nusing Distributions using Plots using Printf # StudentT分布のシフト x = -8:0.01:8 mu = [0, 0, -2, -2] lam = [1, 1, 1, 2] nu = [1, 5, 5, 5] plt = Plots.plot() for i in 1:4 y = pdf.(LocationScale(mu[i], lam[i], TDist(nu[i])), x) Plots.plot!(x, y, linewidth = 2, label = @sprintf(\u0026#34;mu = %.1f, lam = %.1f, nu = %.1f\u0026#34;, mu[i], lam[i], nu[i])) end plt 良さそうだ。\n",
    "permalink": "https://matsueushi.github.io/posts/shift-scale-distribution/",
    "tags": [
      "Julia",
      "Distribution"
    ],
    "title": "Distribution.jlで分布をシフト・スケールさせる"
  },
  {
    "contents": "引き続き「Pythonで体験するベイズ推論」のJulia+Mambaによる実装に挑戦している。わざわざ特別Mediumに書くような題材は無いな、と思っていたのだが、第5章の「例題 : テレビ番組 “The Price Is Right”の最適化」のモデリング( pm.potential が出てくるところ)でちょっと詰まったので、Mambaでの実装について記しておく。\n問題を単純化すると、\n二つの賞品A, Bの合計価格(これを真の価格と今後呼ぶ)を予想したい 真の価格は正規分布 \\( \\text{Normal}(35000, 7500^2) \\) に従うと仮定する 賞品A, Bの価格の事前分布はそれぞれ正規分布 \\( \\text{Normal}(12000, 3000^2) \\) , \\( \\text{Normal}(3000,500^2) \\) に従うと仮定する このような条件のモデリングである。 実際にモデリングをやってみて、賞品A, Bの事前分布と、その和をモデリングするところまでは下のようにすればいいので簡単であるのだが、( using 等は略した)真の価格の分布とサンプリングした賞品A, Bの価格の分布の和を結びつける段階で、はて？？？となった。\ndata = Dict{Symbol, Any}( :data_mu =\u0026gt; [3e3, 12e3], :data_std =\u0026gt; [5e2, 3e3], :mu_prior =\u0026gt; 35e3, :std_prior =\u0026gt; 75e2, ) model = Model( prize = Stochastic(1, (data_mu, data_std) -\u0026gt; MvNormal(data_mu, data_std)), price_estimate = Logical(prize -\u0026gt; sum(prize)), ) モデルを下のようにしてしまうと、\nmodel = Model( true_price = Stochastic((mu_prior, std_prior) -\u0026gt; Normal(mu_prior, std_prior)), prize = Stochastic(1, (data_mu, data_std) -\u0026gt; MvNormal(data_mu, data_std)), price_estimate = Logical(prize -\u0026gt; sum(prize)), ) price_estimate と true_price が結びつかないのである。\n本文のコードを見てみると、 @pm.potential というデコレーターが付いた関数が使われている。(PyMC3では pm.Potential )\n@pm.potential def error(true_price=true_price, price_estimate=price_estimate): return pm.normal_like(true_price, price_estimate, 1 / (3e3)**2) 要は毎回真の価格の分布からサンプリングされている観測値 true_price を \\( \\text{Normal}( \\) price_estimate \\(, 3000^2) \\) という分布に当てはめた時の尤度を制約条件として加えるということである。\n参考にした pm.potential についてのStackExchangeの質問:\nWhat is pm.Potential in PyMC3? https://stats.stackexchange.com/questions/251280/what-is-pm-potential-in-pymc3\n\\\npm.Potential() much needed explanation for newbie https://discourse.pymc.io/t/pm-potential-much-needed-explanation-for-newbie/2341\nMambaに pm.potential に該当する機能が見つからなかったので、ユーザー定義の分布を定義することで制約条件を実装した。\ntrue_price に対して計算される尤度が通常の \\( \\text{Normal}(\\mu, \\sigma^2) \\) に対応する尤度と今回考えたい制約に対応する \\( \\text{Normal}( \\) price_estimate \\(, 3000^2) \\) の尤度の話になるような分布にすれば良いので、\n@everywhere extensions = quote using Distributions import Distributions: minimum, maximum, logpdf mutable struct TruePriceDist \u0026lt;: ContinuousUnivariateDistribution mu::Float64 sig::Float64 price_estimate::Float64 end minimum(d::TruePriceDist) = -Inf maximum(d::TruePriceDist) = Inf function logpdf(d::TruePriceDist, x::Real) logpdf(Normal(d.mu, d.sig), x) + logpdf(Normal(d.price_estimate, 3000), x) end end @everywhere eval(extensions) と新しく分布を定義する。こうすると logpdf が正規化されていないものになる(pdfを積分して1にならない)がMambaで使う分布としては問題は起こらない。\nモデルはこの TruePriceDist を使って、\nmodel = Model( true_price = Stochastic( (mu_prior, std_prior, price_estimate) -\u0026gt; TruePriceDist(mu_prior, std_prior, price_estimate) ), prize = Stochastic(1, (data_mu, data_std) -\u0026gt; MvNormal(data_mu, data_std)), price_estimate = Logical(prize -\u0026gt; sum(prize)), ) とすれば良い。\n事後分布を確認すると、本と同様の結果がきちんと得られていた。\nサンプリングの詳細、期待損失の計算や最小化に関しては下のipynb参照。\nhttps://nbviewer.jupyter.org/github/matsueushi/bayesian_methods_julia/blob/master/chapter5_thepriceisright.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/bayesian-methods-julia-7/",
    "tags": [
      "Julia",
      "Bayesian",
      "Mamba"
    ],
    "title": "Juliaで体験するベイズ推論(7) - The Price Is Right"
  },
  {
    "contents": "最近はGaussianRandomWalkを使った時系列ベイズモデルの推定に挑戦していたが、あまりうまくいかなかったので一旦「Pythonで体験するベイズ推論」に戻ろうと思う。\n今回は「Pythonで体験するベイズ推論」の「2.2.27 例題 カンニングした学生の割合」をJuliaで実装した内容を紹介する。\nまずはライブラリのインポート\nusing Distributed addprocs(3) using CSV using DataFrames using HTTP using LaTeXStrings using LinearAlgebra @everywhere using Mamba using Plots データの加工はこのような形で行った。DataFrame で Int64 にパースしたい行にMissing valueやNaNがあるとき、convertではエラーになるので、 パースできない場合は missing になる tryparse を使って、その後 nothing になる行を削除して、Union{Nothing, Int64} から Int64 にもう一度変換している。\nr = HTTP.request(\u0026#34;GET\u0026#34;, \u0026#34;https://git.io/vXknD\u0026#34;); challengers_data = CSV.read(IOBuffer(r.body)) names!(challengers_data, [:date, :temperature, :incident]) # incidentのパース challengers_data[:incident] = tryparse.(Int64, challengers_data[:incident]) # NaNを削除 challengers_data = challengers_data[challengers_data[:incident] .!= nothing, :] challengers_data[:incident] = convert.(Int64, challengers_data[:incident]) disallowmissing!(challengers_data) データの図示をする。weighted_color_mean を使って、マーカーの色を青から赤にグラデーションさせた。\ntemperature = challengers_data[:temperature] color_weight = (temperature .- minimum(temperature)) ./ (maximum(temperature) .- minimum(temperature)) wcolor = weighted_color_mean.(color_weight, colorant\u0026#34;red\u0026#34;, colorant\u0026#34;blue\u0026#34;) scatter(challengers_data.temperature, challengers_data.incident, markercolor = wcolor, xlabel = \u0026#34;Temprature (F)\u0026#34;, ylabel = \u0026#34;O-ring failure\u0026#34;, label = \u0026#34;\u0026#34;) 破損発生の有無を表す確率変数 \\( D_i \\) は、ベルヌーイ分布とロジスティック関数を用いて\n\\( \\begin{aligned} D_i \u0026amp;\\sim \\text{Bernoulli}(p(t_i)), \\\\ p(t) \u0026amp;= \\frac{1}{1 +\\exp(\\beta t + \\alpha)}, \\end{aligned} \\)\n\\( t \\) : 温度 とモデリングされる。今回は、あとでサンプルされた p の値を使ってデータのシミュレーションを行うために、下のように p に Logical ノードを割り当てたが、\nmodel = Model( observed = Stochastic(1, p -\u0026gt; UnivariateDistribution[Bernoulli(x) for x in p], false ), p = Logical(1, (alpha, beta, temperature) -\u0026gt; @.(1.0 / (1.0 + exp(beta * temperature + alpha))) ), alpha = Stochastic(() -\u0026gt; Normal(0, sqrt(1000))), beta = Stochastic(() -\u0026gt; Normal(0, sqrt(1000))), ) observedのモデリングだけであればpを経由せずに直接モデリングすることもできる。\nmodel = Model( observed = Stochastic(1, (alpha, beta, temperature) -\u0026gt; UnivariateDistribution[ Bernoulli(1.0 / (1.0 + exp(beta * x + alpha))) for x in temperature], false ), alpha = Stochastic(() -\u0026gt; Normal(0, sqrt(1000))), beta = Stochastic(() -\u0026gt; Normal(0, sqrt(1000))), ) モデルパラメータ alpha, beta の事後分布は次のようになった。\ndata = Dict{Symbol, Any}( :observed =\u0026gt; challengers_data[:incident], :temperature =\u0026gt; challengers_data[:temperature], ) inits = [ Dict{Symbol, Any}( :observed =\u0026gt; challengers_data[:incident], :alpha =\u0026gt; 0, :beta =\u0026gt; 0, ) for _ in 1:3 ] scheme = [AMWG([:alpha, :beta], 0.1)] setsamplers!(model, scheme) sim = mcmc(model, data, inits, 200000, burnin = 50000, thin = 50, chains = 3) p = Mamba.plot(sim[:, [:alpha, :beta], :], legend = true) Mamba.draw(p, nrow = 2, ncol = 2) p = Mamba.plot(sim[:, [:alpha, :beta], :], [:autocor, :mean], legend=true) Mamba.draw(p, nrow = 2, ncol = 2) alpha に対して beta をプロットすると、次のような原点を通る直線上のグラフになる。\\( p(t) = 0.5 \\) となるのが \\( t = -\\alpha / \\beta \\) となるので、故障するかしないか半々となる温度はシミュレーションで大きく変化しないことがわかる。\nalpha_samples = sim[:, [:alpha], :].value[:] beta_samples = sim[:, [:beta], :].value[:] scatter(alpha_samples, beta_samples, label = \u0026#34;\u0026#34;, markersize = 3) 破損確率の事後期待値と、サンプルから選んでプロットする。\nfunction logistic(x, alpha, beta) 1.0 ./ (1.0 .+ exp.(beta * x .+ alpha)) end xs = collect((minimum(temperature) - 5):0.1:(maximum(temperature) + 5)) p_t = logistic(transpose(xs), alpha_samples, beta_samples) Plots.plot(xs, vec(mean(p_t, dims=1)), linewidth = 2, label = \u0026#34;Average posterior probability\u0026#34;) Plots.plot!(xs, p_t[1, :], linewidth = 2, linestyle = :dash, label = \u0026#34;Realization from posterior\u0026#34;) Plots.plot!(xs, p_t[end-2, :], linewidth = 2, linestyle = :dash, label = \u0026#34;Realization from posterior\u0026#34;) scatter!(challengers_data.temperature, challengers_data.incident, markercolor = weighted_color_mean.(color_weight, colorant\u0026#34;blue\u0026#34;, colorant\u0026#34;red\u0026#34;), xlabel = \u0026#34;Temprature (F)\u0026#34;, ylabel = \u0026#34;O-ring failure\u0026#34;, label = \u0026#34;\u0026#34;) 破損確率の事後期待値と、95%信頼区間をプロットする\np_t_ci = mapslices(x -\u0026gt; quantile(x, [0.025, 0.975]), p_t, dims = 1) Plots.plot(xs, p_t_ci[2, :], linewidth = 0, fillrange = p_t_ci[1, :], fillalpha = 0.4, label = \u0026#34;95% Confidence interval\u0026#34;) Plots.plot!(xs, vec(mean(p_t, dims=1)), linewidth = 2, label = \u0026#34;Average posterior probability\u0026#34;) scatter!(challengers_data.temperature, challengers_data.incident, markercolor = weighted_color_mean.(color_weight, colorant\u0026#34;blue\u0026#34;, colorant\u0026#34;red\u0026#34;), xlabel = \u0026#34;Temprature (F)\u0026#34;, ylabel = \u0026#34;O-ring failure\u0026#34;, label = \u0026#34;\u0026#34;) ",
    "permalink": "https://matsueushi.github.io/posts/bayesian-methods-julia-6/",
    "tags": [
      "Julia",
      "Bayesian",
      "Mamba"
    ],
    "title": "Juliaで体験するベイズ推論(6) -スペースシャトル「チャレンジャー号」の悲劇"
  },
  {
    "contents": "Pandasの pd.rolling のようなことをJuliaで行うためのメモ\nhttps://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rolling.html\n複雑なことがやりたければこれを使えば良さそうだ。\nJeffreySarnoff/RollingFunctions.jl\nhttps://github.com/JeffreySarnoff/RollingFunctions.jl\n",
    "permalink": "https://matsueushi.github.io/posts/rollingwindow/",
    "tags": [
      "Julia"
    ],
    "title": "JuliaでRollingWindow"
  },
  {
    "contents": "やり方がよくわからなくなるので自分用メモを兼ねて。JuliaのVersion は1.1.0 (2019–01–21)。\n2次元 julia\u0026gt; x = [1 2; 3 4] 2×2 Array{Int64,2}: 1 2 3 4 縦方向に拾っていきたいときは簡単で、 vec\njulia\u0026gt; vec(x) 4-element Array{Int64,1}: 1 3 2 4 横方向に拾いたい場合は permutedims を噛ませる。\njulia\u0026gt; vec(permutedims(x)) 4-element Array{Int64,1}: 1 2 3 4 transpose と collect を使う\njulia\u0026gt; vec(collect(transpose(x))) 4-element Array{Int64,1}: 1 2 3 4 だと場合によっては問題があり、 Transpose は LinearAlgebra の操作なので、例えば Array{Char, 2} に対しては定義されていないので実行できない。\njulia\u0026gt; [\u0026#39;a\u0026#39; \u0026#39;b\u0026#39;;\u0026#39;c\u0026#39; \u0026#39;d\u0026#39;] 2×2 Array{Char,2}: \u0026#39;a\u0026#39; \u0026#39;b\u0026#39; \u0026#39;c\u0026#39; \u0026#39;d\u0026#39; julia\u0026gt; transpose([\u0026#39;a\u0026#39; \u0026#39;b\u0026#39;;\u0026#39;c\u0026#39; \u0026#39;d\u0026#39;]) 2×2 LinearAlgebra.Transpose{Union{},Array{Char,2}}: Error showing value of type LinearAlgebra.Transpose{Union{},Array{Char,2}}: ERROR: MethodError: no method matching transpose(::Char) permutedims を使えばこの場合もOK.\njulia\u0026gt; vec(permutedims([\u0026#39;a\u0026#39; \u0026#39;b\u0026#39;;\u0026#39;c\u0026#39; \u0026#39;d\u0026#39;])) 4-element Array{Char,1}: \u0026#39;a\u0026#39; \u0026#39;b\u0026#39; \u0026#39;c\u0026#39; \u0026#39;d\u0026#39; 3次元 julia\u0026gt; x = reshape([(1:24)...], 2, 3, 4) 2×3×4 Array{Int64,3}: [:, :, 1] = 1 3 5 2 4 6 [:, :, 2] = 7 9 11 8 10 12 [:, :, 3] = 13 15 17 14 16 18 [:, :, 4] = 19 21 23 20 22 24 横方向(?)に連結する\njulia\u0026gt; reshape(x, size(x, 1), :) 2×12 Array{Int64,2}: 1 3 5 7 9 11 13 15 17 19 21 23 2 4 6 8 10 12 14 16 18 20 22 24 縦方向(?)に連結する\njulia\u0026gt; permutedims(reshape(permutedims(x, (2, 1, 3)), size(x, 2), :)) 8×3 Array{Int64,2}: 1 3 5 2 4 6 7 9 11 8 10 12 13 15 17 14 16 18 19 21 23 20 22 24 もっと良い方法はないものか……\n",
    "permalink": "https://matsueushi.github.io/posts/julia-array-dim/",
    "tags": [
      "Julia"
    ],
    "title": "Juliaの2次元のArrayを1次元にする / Juliaの3次元のArrayを2次元にする"
  },
  {
    "contents": "PyMC3にはTimeseriesとして GaussianRandomWalk などの時系列モデルが実装されている。\nhttps://docs.pymc.io/api/distributions/timeseries.html#pymc3.distributions.timeseries.GaussianRandomWalk\nだが残念なことに私が使っているMamba.jl(0.12.1)には時系列モデルがない。下のように cumsum を使ってモデルを作成することは可能ではあるが、面倒だし次元が大きくなってきたりモデルが複雑になってくると遅い。\nlocal_level_model = Model( obs = Stochastic(1, (N, T, sigma_I) -\u0026gt; MvNormal(T, sigma_I), false ), T = Logical(1, (T_0, disturbance) -\u0026gt; T_0 .+ vcat([0], cumsum(disturbance)), ), disturbance = Stochastic(1, (N, sigma_T) -\u0026gt; MvNormal(N - 1, sigma_T), false ), sigma_I = Stochastic(() -\u0026gt; InverseGamma()), sigma_T = Stochastic(() -\u0026gt; InverseGamma()), T_0 = Stochastic(T_init -\u0026gt; Normal(T_init, 100)), ) だからと言ってそのためにわざわざPython+PyMC3に移るのも癪だし、練習を兼ねてJulia+Mamba用の確率分布を試しに作ってみようと思ったのが今回の内容である。幸いなことに、Mamba.jlには作り方のガイドラインが書いてあるので、多変量分布用のガイドラインを参考にして作ることができた。\n今回は、GaussianRandomWalk は、初期値の分布 \\( D \\) とドリフト \\( \\mu_i \\) , 分散 \\( \\sigma \\) とした時に、\n\\( \\begin{aligned} Y_0 \u0026amp;= D, \\\\ Y_{i+1} \u0026amp;= Y_i + \\mu_i + \\epsilon_i, \\\\ \\epsilon_i \u0026amp;\\sim \\text{Normal}(0, \\sigma) \\end{aligned} \\)\nというモデルに従っているとする。\nMamba.jlでUser-Definedの多変量分布を使うためには, Distributionの全ての関数を定義する必要はなく、 次元 length, 分布のサポート insupport, 確率密度関数の対数 _logpdf だけ定義すればサンプリングができる。\nusing Distributed @everywhere extensions = quote using Distributions import Distributions: length, insupport, _logpdf mutable struct GaussianRandomWalk \u0026lt;: ContinuousMultivariateDistribution mu::Vector{Float64} sig::Float64 init::ContinuousUnivariateDistribution end length(d::GaussianRandomWalk) = length(d.mu) + 1 function insupport(d::GaussianRandomWalk, x::AbstractVector{T}) where {T\u0026lt;:Real} length(d) == length(x) \u0026amp;\u0026amp; all(isfinite.(x)) end function _logpdf(d::GaussianRandomWalk, x::AbstractVector{T}) where {T\u0026lt;:Real} randomwalk_like = logpdf.(Normal.(d.mu + x[1:end-1], d.sig), x[2:end]) logpdf(d.init, x[1]) + sum(randomwalk_like) end end length を定義するときは、ドリフト項の数が次元より一つ小さくなることに注意。\n\\( D \\) の確率密度関数を \\( f_D \\), \\( \\text{Normal}(\\mu, \\sigma) \\)の確率密度関数を \\( f_{\\mu, \\sigma} \\) とすると、 多変量分布 \\( (Y_0, …, Y_n) \\) の確率密度関数 \\( f \\) が\n\\( f(x_0, \\ldots, x_n) = f_D(x_0)\\cdot f_{x_0+\\mu_0, \\sigma}(x_1)\\cdots f_{x_{n-1}+\\mu_{n-1}, \\sigma}(x_n) \\)\nとなるので _logpdf は上のような定義になっている。(本当はここの理由もちゃんと詰めて書いた方が良い気がする)\nquote の意味が最初わからなかったが、これで quote から end までのコード全体をオブジェクトとして extensions に代入して、下のように空のモジュールを作成して、\nmodule Testing end 下を実行すると\nCore.eval(Testing, extensions) Testing モジュール内で quote した extension の内容が読み込まれるということのようだ。\nhttps://docs.julialang.org/en/v1/manual/metaprogramming/index.html#Metaprogramming-1\n新しく作成した分布を用いてMambaのモデルを作成し、サンプリングをしてみよう。 簡単のためにドリフトは無視して、分散 \\( \\sqrt{100} \\) の正規分布の列からなる100次元の GaussianRandomWalk のサンプルを作成し、モデルを作成して分散を推定してみる。\n@everywhere using Mamba @everywhere eval(extensions) model = Model( y = Stochastic(1, sig -\u0026gt; GaussianRandomWalk(zeros(99), sqrt(sig), Normal(0, sqrt(sig))), false ), sig = Stochastic( () -\u0026gt; InverseGamma(0.001, 0.001) ), ) scheme = [AMWG(:sig, 10.0)] setsamplers!(model, scheme) data = Dict( :y =\u0026gt; cumsum(rand(MvNormal(100, sqrt(100)))) ) inits = [ Dict( :y =\u0026gt; data[:y], :sig =\u0026gt; 1, ) for _ in 1:3 ] sim = mcmc(model, data, inits, 21000, burnin=1000, thin=4, chains=3) describe(sim) println(\u0026#34;Actual variance: \u0026#34;, var(diff(data[:y]))) p = Mamba.plot(sim, legend = true) Mamba.draw(p, nrow = 1, ncol = 2) 結果-\u0026gt;\nMCMC Simulation of 21000 Iterations x 3 Chains... Chain 1: 0% [1:17:22 of 1:17:24 remaining] Chain 1: 10% [0:00:24 of 0:00:27 remaining] Chain 1: 20% [0:00:11 of 0:00:14 remaining] Chain 1: 30% [0:00:07 of 0:00:09 remaining] Chain 1: 40% [0:00:04 of 0:00:07 remaining] Chain 1: 50% [0:00:03 of 0:00:06 remaining] Chain 1: 60% [0:00:02 of 0:00:05 remaining] Chain 1: 70% [0:00:01 of 0:00:05 remaining] Chain 1: 80% [0:00:01 of 0:00:04 remaining] Chain 1: 90% [0:00:00 of 0:00:04 remaining] Chain 1: 100% [0:00:00 of 0:00:04 remaining] Chain 2: 0% [0:00:01 of 0:00:01 remaining] Chain 2: 10% [0:00:01 of 0:00:01 remaining] Chain 2: 20% [0:00:01 of 0:00:01 remaining] Chain 2: 30% [0:00:01 of 0:00:01 remaining] Chain 2: 40% [0:00:01 of 0:00:01 remaining] Chain 2: 50% [0:00:00 of 0:00:01 remaining] Chain 2: 60% [0:00:00 of 0:00:01 remaining] Chain 2: 70% [0:00:00 of 0:00:01 remaining] Chain 2: 80% [0:00:00 of 0:00:01 remaining] Chain 2: 90% [0:00:00 of 0:00:01 remaining] Chain 2: 100% [0:00:00 of 0:00:01 remaining] Chain 3: 0% [0:00:01 of 0:00:01 remaining] Chain 3: 10% [0:00:01 of 0:00:01 remaining] Chain 3: 20% [0:00:01 of 0:00:01 remaining] Chain 3: 30% [0:00:01 of 0:00:01 remaining] Chain 3: 40% [0:00:01 of 0:00:01 remaining] Chain 3: 50% [0:00:01 of 0:00:01 remaining] Chain 3: 60% [0:00:00 of 0:00:01 remaining] Chain 3: 70% [0:00:00 of 0:00:01 remaining] Chain 3: 80% [0:00:00 of 0:00:01 remaining] Chain 3: 90% [0:00:00 of 0:00:01 remaining] Chain 3: 100% [0:00:00 of 0:00:01 remaining] Iterations = 1004:21000 Thinning interval = 4 Chains = 1,2,3 Samples per chain = 5000 Empirical Posterior Estimates: Mean SD Naive SE MCSE ESS sig 91.87928 13.629016 0.111280453 0.21081987 4179.323 Quantiles: 2.5% 25.0% 50.0% 75.0% 97.5% sig 69.039156 82.188388 90.31312 100.2171 122.073783 Actual variance: 92.0192593899444 標本分散が92だから正しく推定できているのではないだろうか。\n次は、確認を兼ねて、作った GaussianRandomWalk を使って時系列モデルの構築に挑戦したい。\n全部のコード:\n",
    "permalink": "https://matsueushi.github.io/posts/mamba-gaussianrandomwalk/",
    "tags": [
      "Julia",
      "Mamba",
      "RandomWalk"
    ],
    "title": "Mamba.jlでGaussianRandomWalkを作って使う"
  },
  {
    "contents": "GCPに環境を作っていて気づいたのだが、Distibution.jlのv0.17.0と関数が干渉していて using Mamba すると下のようなワーニングが出て、\nWARNING: Method definition (::Type{Distributions.DiscreteNonParametric{Int64, P, Base.OneTo{Int64}, Ps} where Ps where P})(AbstractArray{T\u0026lt;:Real, 1}) where {T\u0026lt;:Real} in module Distributions at /Users/apple/.julia/packages/Distributions/fMt8c/src/univariate/discrete/categorical.jl:40 overwritten in module Mamba at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:7. WARNING: Method definition (::Type{Distributions.MvNormal{T, Cov, Mean} where Mean\u0026lt;:(AbstractArray{T, 1} where T) where Cov\u0026lt;:(PDMats.AbstractPDMat{T} where T\u0026lt;:Real) where T\u0026lt;:Real})(AbstractArray{T\u0026lt;:Real, 1}, Real) where {T\u0026lt;:Real} in module Distributions at /Users/apple/.julia/packages/Distributions/fMt8c/src/multivariate/mvnormal.jl:200 overwritten in module Mamba at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:35. WARNING: Method definition (::Type{Distributions.MvNormalCanon{T, P, V} where V\u0026lt;:(AbstractArray{T, 1} where T) where P\u0026lt;:(PDMats.AbstractPDMat{T} where T\u0026lt;:Real) where T\u0026lt;:Real})(AbstractArray{T\u0026lt;:Real, 1}, U\u0026lt;:Real) where {T\u0026lt;:Real, U\u0026lt;:Real} in module Distributions at /Users/apple/.julia/packages/Distributions/fMt8c/src/multivariate/mvnormalcanon.jl:116 overwritten in module Mamba at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:53. 以前動いていた次のようなコードが動かない。\nMvNormal(zeros(3), 4) StackOverflowError: Stacktrace: [1] MvNormal(::Array{Float64,1}, ::Float64) at /Users/apple/.julia/packages/Mamba/qNBKz/src/distributions/constructors.jl:35 (repeats 80000 times) masterブランチでは修正されているみたいなので、次のリリースでは治るはず\u0026hellip;。\nRemove unneeded MvNormal constructor · brian-j-smith/Mamba.jl@dcaf1cc\nhttps://github.com/brian-j-smith/Mamba.jl/commit/dcaf1ccac1c468d20d49a21acbaeb0cb6adcb4cf\n応急処置として代わりに\nMvNormal(zeros(3), fill(4.0, 3)) にしておけば動くのでこっちを使っておくか。\n追記:\n平均が0だったら\nMvNormal(3, 4.0) これで良さそう。\n追記:\nMamba 0.12.1で直っていた！\n",
    "permalink": "https://matsueushi.github.io/posts/mamba-v-0-12-0/",
    "tags": [
      "Julia",
      "Mamba"
    ],
    "title": "Mamba.jl v0.12.0のStackOverflowError:"
  },
  {
    "contents": "自分用メモ\nローカルの公開鍵をGCPのインスタンスに登録\n[秘密鍵/公開鍵]GCPにSSHで接続する方法\nhttps://sleepless-se.net/2018/09/15/gcp-ssh/\nJuliaのバイナリをダウンロード\ncurl -OL https://julialang-s3.julialang.org/bin/linux/x64/1.1/julia-1.1.0-linux-x86_64.tar.gz 解凍\n$ sudo mkdir /bin/julia $ sudo tar xvzf julia-1.1.0-linux-x86_64.tar.gz -C /bin/julia $ /bin/julia/julia-1.1.0/bin/julia _ _ _ _(_)_ | Documentation: https://docs.julialang.org (_) | (_) (_) | _ _ _| |_ __ _ | Type \u0026#34;?\u0026#34; for help, \u0026#34;]?\u0026#34; for Pkg help. | | | | | | |/ _` | | | | |_| | | | (_| | | Version 1.1.0 (2019-01-21) _/ |\\__\u0026#39;_|_|_|\\__\u0026#39;_| | Official https://julialang.org/ release |__/ | julia\u0026gt; シンボリックリンクを作成\n$ sudo ln -s /bin/julia/julia-1.1.0/bin/julia /usr/local/bin/julia $ julia _ _ _ _(_)_ | Documentation: https://docs.julialang.org (_) | (_) (_) | _ _ _| |_ __ _ | Type \u0026#34;?\u0026#34; for help, \u0026#34;]?\u0026#34; for Pkg help. | | | | | | |/ _` | | | | |_| | | | (_| | | Version 1.1.0 (2019-01-21) _/ |\\__\u0026#39;_|_|_|\\__\u0026#39;_| | Official https://julialang.org/ release |__/ | julia\u0026gt; IJuliaのインストール\njulia\u0026gt; using Pkg julia\u0026gt; Pkg.add(“IJulia”) Anacondaもインストールしておく。bzip2が入っていなかったのでインストールして、\n$ sudo apt-get update $ sudo apt-get install bzip2 Anacondaをインストール\n$ curl -OL https://repo.anaconda.com/archive/Anaconda3-2018.12-Linux-x86_64.sh $ bash Anaconda3-2018.12-Linux-x86_64.sh これを参考にしてJupyter Notebookの設定に入る\nRunning Jupyter Notebook on Google Cloud Platform in 15 min\nhttps://towardsdatascience.com/running-jupyter-notebook-in-google-cloud-platform-in-15-min-61e16da34d52\n$ jupyter notebook --generate-config vim /home/matsueushi/.jupyter/jupyter_notebook_config.py を開いて\nc = get_config() c.NotebookApp.ip = \u0026#39;0.0.0.0\u0026#39; c.NotebookApp.open_browser = False c.NotebookApp.port = \u0026lt;Port Number\u0026gt; を追加する\nGCPのVMインスタンス設定画面でFirewallsの「Allow HTTPS traffic」をチェック\n「NETWORKING -\u0026gt; VPC Network -\u0026gt; Firewall rules -\u0026gt; Create a firewall」で\n「Target tags」を「https-server」、\n「Source IP range」を「0.0.0.0/0」、\n「Protocols and ports」の「Specified protocols and ports-\u0026gt;tcp」をチェックしてポート番号に\nc.NotebookApp.port = \u0026lt;Port Number\u0026gt; のポート番号を追加。\nhttp://:8888/\nにアクセスして、\nhttp://(julia or 127.0.0.1):8888/?token= のあとのtokenを入れる\n",
    "permalink": "https://matsueushi.github.io/posts/gcp-julia/",
    "tags": [
      "Julia",
      "GCP",
      "Jupyter"
    ],
    "title": "GCPでJuliaのノートブックを実行"
  },
  {
    "contents": " aspece_ratio=1 とすれば良いだけだった。簡単だった。\nusing Distributions using Plots x = y = 0:0.5:5 exp_x = Exponential(3) exp_y = Exponential(10) z = Surface((s, t) -\u0026gt; pdf(exp_x, s) * pdf(exp_y, t), x, y) heatmap(x, y, z) heatmap(x, y, z, aspect_ratio = 1) ",
    "permalink": "https://matsueushi.github.io/posts/plotly-scale/",
    "tags": [
      "Julia",
      "Plots"
    ],
    "title": "Plots.jlでx軸、y軸のスケールを揃える"
  },
  {
    "contents": "自分用メモ。Juliaで Array を横に並べて Matrix にする方法は、repeat で第1引数を1にして、第2引数を並べたい個数にすればいい。\njulia\u0026gt; xs = [1, 2, 3, 4, 5] 5-element Array{Int64,1}: 1 2 3 4 5 julia\u0026gt; repeat([1, 2, 3, 4, 5], 1, 4) 5×4 Array{Int64,2}: 1 1 1 1 2 2 2 2 3 3 3 3 4 4 4 4 5 5 5 5 ",
    "permalink": "https://matsueushi.github.io/posts/julia-array-matrix/",
    "tags": [
      "Julia"
    ],
    "title": "Arrayを横に並べてMatrixにする"
  },
  {
    "contents": "「Pythonで体験するベイズ推論」の「2.2.7 例題 カンニングした学生の割合」をやってみよう。\n学生が試験中にカンニングする頻度を求めたい。観測データは個人がカンニングしたかどうかは特定できない、以下のアルゴリズムを用いる。\nコイントスを(こっそり)行い、表が出たら正直に答える 裏が出た場合、もう一枚コインを(こっそり)投げ、表が出たら「カンニングした」と答え、裏が出たら「カンニングしなかった」と答える。 まずはライブラリをインポート。\nusing Distributed addprocs(3) @everywhere using Mamba using Plots 学生の数が100人、「カンニングした」という回答が35人とする。\nN = 100 X = 35 Mambaのモデルは次のようになる。\nmodel = Model( obs = Stochastic( (proportion, N) -\u0026gt; Binomial(N, proportion), false ), proportion = Logical( (true_answers, first_coin_flips, second_coin_flips) -\u0026gt; (observed = @.(first_coin_flips * true_answers + (1 - first_coin_flips) * second_coin_flips); mean(observed)), false ), true_answers = Stochastic(1, p -\u0026gt; Bernoulli(p), false), first_coin_flips = Stochastic(1, () -\u0026gt; Bernoulli(0.5), false), second_coin_flips = Stochastic(1, () -\u0026gt; Bernoulli(0.5), false), p = Stochastic(() -\u0026gt; Uniform()), ) proportionを計算するときの\nobserved = @.(first_coin_flips * true_answers + (1 - first_coin_flips) * second_coin_flips) は@マクロを使った書き方で、\nobserved = first_coin_flips .* true_answers .+ (1 .- first_coin_flips) .* second_coin_flips) と同じである。 true_answers , first_coin_flips , second_coin_flips は長さNの Stochastic ベクターだが、Nをモデルに与えなくても、Stochastic コンストラクタの第1引数を1(1次元)にして、初期値に長さNのベクターを与えれば大丈夫。\ndata = Dict{Symbol, Any}( :obs =\u0026gt; X, :N =\u0026gt; N, ) inits = [ Dict{Symbol, Any}( :obs =\u0026gt; X, :proportion =\u0026gt; 0.5, :true_answers =\u0026gt; rand(Bernoulli(), N), :first_coin_flips =\u0026gt; rand(Bernoulli(), N), :second_coin_flips =\u0026gt; rand(Bernoulli(), N), :p =\u0026gt; rand(Uniform()), ) for _ in 1:3 ] true_answers , first_coin_flips , second_coin_flips は \\( \\{0, 1\\} \\) からのサンプリングなので、Sampling Functionsを見ると BHMC, BIA, BMC3, BMGのどれかを使えば良いようである。BIA, BMC3, BMGを使って比較してみた。\nBIAのサンプリング設定は下の通り。BMC3, BMG も scheme だけ変えればよく同様である。\nsamplings = 100000 burning = 20000 scheme_bia = [NUTS(:p), BIA([:true_answers, :first_coin_flips, :second_coin_flips])] setsamplers!(model, scheme_bia) sim_bia = mcmc(model, data, inits, samplings, burnin = burning, thin = 10, chains = 3) p_bia = reshape(Mamba.plot(sim_bia, [:trace, :density, :autocor, :mean], legend = true), (2, 2)) Mamba.draw(p_bia, nrow = 2, ncol = 2) BIA BMC3 BMG 自己相関や確率密度を見ると BIA, BMC3 が良さそう。\nもう一つのモデル 「カンニングしました」と答える確率は p/2 + 1/4 なので、proportion を計算する代わりにこれを直接使ってモデリングすることもできる。\nanother_model = Model( obs = Stochastic( (p, N) -\u0026gt; (p_skewed = 0.5 * p + 0.25; Binomial(N, p_skewed)), false ), p = Stochastic(() -\u0026gt; Uniform()), ) another_scheme = [NUTS(:p)] setsamplers!(another_model, another_scheme) another_sim = mcmc(another_model, data, inits, samplings, burnin = burning, thin = 10, chains = 3) another_p = reshape(Mamba.plot(another_sim, [:trace, :density, :autocor, :mean], legend = true), (2, 2)) Mamba.draw(another_p, nrow = 2, ncol = 2) true_answers, first_coin_flips, second_coin_flips をモデリングした場合に比べて、収束が大きく向上している。\nコード -\u0026gt; https://nbviewer.jupyter.org/github/matsueushi/bayesian_methods_julia/blob/master/chapter2_cheat.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/bayesian-methods-julia-5/",
    "tags": [
      "Julia",
      "Bayesian",
      "Mamba"
    ],
    "title": "Juliaで体験するベイズ推論(5) -嘘に対抗するアルゴリズム"
  },
  {
    "contents": "今回はMambaを使って、「Pythonで体験するベイズ推論」の「例題 : ベイズ的 A/B」 をモデリングする。\n例題 : ベイズ的 A/B テスト A/Bテストの例題を解いてみよう。\nサイトAを見せられたユーザーが最終的にコンバージョンにつながる確率を \\( p_A \\)と仮定し、\\( N \\) 人がサイトAを見せられて、そのうち \\( n \\) 人がコンバージョンにつながったとする。\nまずはベルヌーイ分布を使って、\\( N \\) 回の試行をシミュレートする。\n# 定数をセット p_true = 0.05 N = 1500 occurrences = rand(Bernoulli(p_true), N) Mamba.jlで推論アルゴリズムを作成すると、次のようになる。\\( p \\) の事前分布は \\( [0, 1] \\) の一様分布に従うとしている。\nmodel0 = Model( obs = Stochastic(1, (p, N) -\u0026gt; UnivariateDistribution[Bernoulli(p) for _ in 1:N], false), p = Stochastic(() -\u0026gt; Uniform()), ) モデルは、等価な次の形で書いた方が単純になってわかりやすいかもしれない。\nmodel0 = Model( obs = Stochastic(1, p -\u0026gt; Bernoulli(p), false), p = Stochastic(() -\u0026gt; Uniform()), ) 観測データと初期値を作ってサンプリングし、\ndata0 = Dict{Symbol, Any}( :obs =\u0026gt; occurrences, :N =\u0026gt; N, ) inits0 = [ Dict{Symbol, Any}( :obs =\u0026gt; occurrences, :p =\u0026gt; rand(Uniform()), ) for _ in 1:3 ] scheme0 = [NUTS(:p)] setsamplers!(model0, scheme0) sim0 = mcmc(model0, data0, inits0, 20000, burnin = 1000, thin = 1, chains = 3) 事後分布のヒストグラムをプロットすると次のようになった。\\( N \\) の数が小さいのか、真の値と分布のピークは多少ずれている。\nhistogram(vec(sim0[:, :p, :].value), bins = 30, normalize = :pdf, linecolor = :transparent, label = \u0026#34;\u0026#34;, xlabel = L\u0026#34;\\mbox{Value of }p_A\u0026#34;, ylabel = \u0026#34;Density\u0026#34;) plot!([p_true], seriestype = :vline, linestyle = :dash, linewidth = 2, label = L\u0026#34;\\mbox{true }p_A\u0026#34;, legendfontsize = 12) \\( N \\) の数を増やしてみる 観測データ数を増やして変化を確認してみよう。\\( N=1500, 5000, 15000 \\) の3種類を試す。\nab_sim = [] Ns = [1500, 5000, 15000] for n in Ns ab_occur = rand(Bernoulli(p_true), n) ab_data = Dict{Symbol, Any}( :obs =\u0026gt; ab_occur, :N =\u0026gt; n, ) ab_inits = [ Dict{Symbol, Any}( :obs =\u0026gt; ab_occur, :p =\u0026gt; rand(Uniform()), ) for _ in 1:3 ] push!(ab_sim, mcmc(model0, ab_data, ab_inits, 20000, burnin = 1000, thin = 1, chains = 3)) end Plots.plot() for (i, sim) in enumerate(ab_sim) histogram!(vec(sim[:, :p, :].value), normalize = :pdf, linecolor = :transparent, label = @sprintf(\u0026#34;N=%d\u0026#34;, Ns[i]), xlabel = L\u0026#34;\\mbox{Value of }p_A\u0026#34;, ylabel = \u0026#34;Density\u0026#34;) end Plots.plot!([p_true], seriestype = :vline, linestyle = :dash, linewidth = 2, linecolor = :red, label = L\u0026#34;\\mbox{true }p_A\u0026#34;, legendfontsize = 12) \\( N \\) を大きくすると分布の裾野が狭くなり、分布の中心が真の値 \\( p_A \\) に近づいている。\nAとBを一緒に サイトA, Bに対し、未知数である真のコンバージョン率 true_p_A, true_p_B はそれぞれ0.05と0.04とし、観測データ数 N_A, N_B は1500, 500として観測データを作成する。\ntrue_p_A = 0.05 true_p_B = 0.04 N_A = 1500 N_B = 750 observation_A = rand(Bernoulli(true_p_A), N_A) observation_B = rand(Bernoulli(true_p_B), N_B) 同時に推論するモデルは以下のようになる。新しく \\( p_A \\) と \\( p_B \\) の差を表す Logical ノード delta が増えた以外は一つだけ推論する場合をコピーペーストして二つにしただけ。\nmodel1 = Model( obs_A = Stochastic(1, p_A -\u0026gt; Bernoulli(p_A), false), obs_B = Stochastic(1, p_B -\u0026gt; Bernoulli(p_B), false), delta = Logical((p_A, p_B) -\u0026gt; p_A - p_B), p_A = Stochastic(() -\u0026gt; Uniform()), p_B = Stochastic(() -\u0026gt; Uniform()), ) 与える観測データと初期値は下のようにした。\\( p_A \\) と \\( p_B \\) の初期値は \\( [0,1] \\) からランダムで取った。\ndata1 = Dict{Symbol, Any}( :obs_A =\u0026gt; observation_A, :obs_B =\u0026gt; observation_B, ) inits1 = [ begin p_A = rand(Uniform()) p_B = rand(Uniform()) Dict{Symbol, Any}( :obs_A =\u0026gt; observation_A, :obs_B =\u0026gt; observation_B, :p_A =\u0026gt; p_A, :p_B =\u0026gt; p_B, :delta =\u0026gt; p_A - p_B, ) end for _ in 1:3 ] scheme1 = [NUTS([:p_A, :p_B])] setsamplers!(model1, scheme1) sim1 = mcmc(model1, data1, inits1, 25000, burnin = 5000, thin = 1, chains = 3) p1 = Mamba.plot(sim1[:, [:p_A, :p_B, :delta], :], legend = true) Mamba.draw(p1, nrow = 3, ncol = 2) \\( p_A \\) と \\( p_B \\) の事後分布と一つの図にプロットして分布の裾の広さを比較する。Bの方がサンプル数が少ないので裾が広い。\nhistogram(vec(sim1[:, :p_A, :].value), normalize = :pdf, bins=30, fillalpha = 0.8, linecolor = :transparent, label = \u0026#34;p_A\u0026#34;) histogram!(vec(sim1[:, :p_B, :].value), normalize = :pdf, bins=30, fillalpha = 0.8, linecolor = :transparent, label = \u0026#34;p_B\u0026#34;) サイトA, サイトBのデータを2倍にした時の delta の分布の変化を見ると、このようになった。もともとの delta の分布が真のデルタの値から近い値を中心に当たっていたため改善されている感じがわかりづらいが、データを2倍にすると裾が狭くなっている。\n同様の改善効果があるのなら、N_B を増やす方が良い(N_B を2倍にするとデータサイズが750増加するが、N_A を2倍にするとデータサイズが1500増加するため)\n真の \\(p_A, p_B \\) を動かして delta の分布を見ると次のようになる。\n",
    "permalink": "https://matsueushi.github.io/posts/bayesian-methods-julia-4/",
    "tags": [
      "Julia",
      "Bayesian",
      "Mamba"
    ],
    "title": "Juliaで体験するベイズ推論(4) -ベイズ的 A/B"
  },
  {
    "contents": "引き続き「Pythonで体験するベイズ推論」の第2章の新しいデータセットの作成をJuliaでやってみる。\n新しいデータセットの生成 PyMCについての説明はスキップして、シミュレーションによるメッセージ数のデータ生成から行う。\nMamba.jlは分布の作成にDistributions.jlを使っているので、シミュレーションだけ行いたかったらDistributionsを using すれば十分。\nusing Distributions using Plots データセットの作成とプロットは下のようになる。\nfunction plot_artificial_sms_dataset() tau = rand(DiscreteUniform(0, 80)) theta = 20 lambda_1, lambda_2 = rand(Exponential(theta), 2) lambda_ = cat(fill(lambda_1, tau), fill(lambda_2, 80 - tau), dims = 1) data = @.rand(Poisson(lambda_)) barc = fill(1, 80) barc[tau] = 2 bar(0:80-1, data, linecolor = :transparent, fillcolor = barc, xlabel = \u0026#34;Time (days)\u0026#34;, ylabel = \u0026#34;Count of messages\u0026#34;, label = \u0026#34;\u0026#34;) end plts = [] for i in 1:4 push!(plts, plot_artificial_sms_dataset()) end plot(plts..., layout = (4, 1), size = [600, 800]) Plots.jlでPythonのMatplotlibと同様に複数のSubplotsを表示するには、一旦list (e.g. plt )にプロット結果を受けておいて、最後に一気に\nplot(plts…, layout = (4, 1), size = [600, 800]) として表示すればできる。\nplot(plts, layout = (4, 1), size = [600, 800]) だと MethodError: no method matching MethodError(::String) が出てダメだった。\nモデルシミュレーションのコード -\u0026gt; https://nbviewer.jupyter.org/github/matsueushi/bayesian_methods_julia/blob/master/chapter2_simulate_model.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/bayesian-methods-julia-3/",
    "tags": [
      "Julia",
      "Bayesian",
      "Mamba"
    ],
    "title": "Juliaで体験するベイズ推論(3) -新しいデータセットの生成"
  },
  {
    "contents": "前回に引き続き、「Pythonで体験するベイズ推論」をJuliaでやってみる。本に従い、前回作成した「メッセージ数に変化はあるか？」を二つの変化点の場合に拡張する。\n変化点が二つの場合を考えてみる。モデルは変化点が一つの場合とほぼ同じで、\nmodel2 = Model( obs = Stochastic(1, (lambda, N) -\u0026gt; UnivariateDistribution[Poisson(lambda[i]) for i in 1:N], false ), lambda = Logical(1, (lambda1, lambda2, lambda3, tau1, tau2, N) -\u0026gt; (out = fill(lambda1, N); i1 = Int64(tau1.value) + 1; # Juliaは1-indexingのため i2 = Int64(tau2.value) + 1; out[i1:end] .= lambda2; out[i2:end] .= lambda3; out), false, ), lambda1 = Stochastic(theta -\u0026gt; Exponential(theta)), lambda2 = Stochastic(theta -\u0026gt; Exponential(theta)), lambda3 = Stochastic(theta -\u0026gt; Exponential(theta)), tau1 = Stochastic(N -\u0026gt; DiscreteUniform(0, N-1)), tau2 = Stochastic((tau1, N) -\u0026gt; DiscreteUniform(tau1, N)), ) 初期値とサンプリングスキームを同様に与えてサンプリングすると、\ninits2 = [ Dict{Symbol, Any}( :obs =\u0026gt; count_data.messages, :lambda1 =\u0026gt; theta, :lambda2 =\u0026gt; theta, :lambda3 =\u0026gt; theta, :tau1 =\u0026gt; 1, :tau2 =\u0026gt; N, ) for _ in 1:3 ] scheme2 = [AMWG([:lambda1, :lambda2, :lambda3], 1.0), DGS([:tau1, :tau2])] setsamplers!(model2, scheme2) sim2 = mcmc(model2, data0, inits2, 40000, burnin = 10000, thin = 3, chains = 3) 事後分布は以下のようになる。\np2 = Mamba.plot(sim2[:, [:tau1, :tau2], :], legend = true) Mamba.draw(p2, nrow = 2, ncol = 2) p2 = Mamba.plot(sim2[:, [:lambda1, :lambda2, :lambda3], :], legend = true) Mamba.draw(p2, nrow = 3, ncol = 2) 本で言及されていた、変化点の個数についても事前分布を作ってモデリングしてみたがうまくいかなかった。\nコード -\u0026gt; https://nbviewer.jupyter.org/github/matsueushi/bayesian_methods_julia/blob/master/chapter1_message.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/bayesian-methods-julia-2/",
    "tags": [
      "Julia",
      "Bayesian",
      "Mamba"
    ],
    "title": "Juliaで体験するベイズ推論(2) -メッセージ数に変化はあるか？"
  },
  {
    "contents": "よく忘れるのでメモ。\n結論から言うと Base.Iterators.flatten を適用して collect すれば良い。\njulia\u0026gt; import Base.Iterators: flatten julia\u0026gt; xs = [[1, 2, 3], [4, 5, 6]] 2-element Array{Array{Int64,1},1}: [1, 2, 3] [4, 5, 6] julia\u0026gt; collect(flatten(xs)) 6-element Array{Int64,1}: 1 2 3 4 5 6 追記(2019/4/7):\nvcat を使った方が簡潔だった。\njulia\u0026gt; vcat(xs...) 6-element Array{Int64,1}: 1 2 3 4 5 6 ",
    "permalink": "https://matsueushi.github.io/posts/julia-array-of-array/",
    "tags": [
      "Julia"
    ],
    "title": "JuliaでArray of Arrayを1次元Vectorにする方法"
  },
  {
    "contents": "久保拓弥「データ解析のための統計モデリング入門」を読み終えたので、次はCameron Davidson-Pilon著、玉木徹訳の「Pythonで体験するベイズ推論」(GitHubリポジトリ) をJuliaとMamba.jlでモデリングしていきたいと思う。\nまず例題1.4.1の「メッセージ数に変化はあるか？」をやってみる。\n元のノートブックはこれ。\nJuliaでCSVファイルをhttps上から取るには、パッケージ HTTP , CSV をインポートして\nr = HTTP.request(\u0026#34;GET\u0026#34;, \u0026#34;https://git.io/vXTVC\u0026#34;); count_data = CSV.read(IOBuffer(r.body), header=[\u0026#34;messages\u0026#34;]) とすれば良い。 Plotsでプロットすると下のような感じ。Juliaはインデックスが1から始まるので、x軸を 0:N-1 にしておく。\nN = length(count_data.messages) bar(0:N-1, count_data.messages, label = \u0026#34;\u0026#34;, size = [600, 200], linecolor = :transparent, xlabel = \u0026#34;Time (days)\u0026#34;, ylabel = \u0026#34;Count of messages\u0026#34;) \\( i \\) 日目のメッセージ数 \\( C_i \\) がポアソン分布 \\( \\text{Poisson}(\\lambda) \\) に従い、\\( \\lambda \\) の値が突然ある日 \\( \\lambda \\) で変わる日があるとする。\\( \\tau \u0026lt; \\lambda \\) のとき \\( \\lambda = \\lambda_1, \\tau \\ge \\lambda \\) の時 \\( \\lambda=\\lambda_2 \\)とする。\nこの \\( \\tau, \\lambda_1, \\lambda_2 \\) 推定する。\\( \\lambda_1, \\lambda_2 \\) の事前分布は指数分布 \\( \\text{Exp}(\\alpha) \\) とする。ここでαは計数データの平均の逆数である。\\( \\tau \\) の事前分布は一様分布とする。\nMambaでモデリングするときに注意しないといけないのは、PyMCと分布のパラメトライズが一部異なるところである。\nclass pymc3.distributions.continuous.Exponential(lam, *args, **kwargs)\nhttps://docs.pymc.io/api/distributions/continuous.html#pymc3.distributions.continuous.Exponential\n\\\nDistributions.Exponential — Type.\nhttps://juliastats.github.io/Distributions.jl/stable/univariate/#Distributions.Exponential\nExponentialのパラメトライズが違うことに気づかずにモデリングを行っていたのだが、Mambaで使っているDistiribution.jlの Exponential(θ) をPyMCの pm.Exponential(lam) と 同じ分布となるためには θ=1/lam とする必要がある。これを間違えていたため下のように事前分布が全く異なってしまい収束しなくなってしまっていた。\nMambaでモデルを作成すると次のようになる。パラメトライズの方法が違うので、変数は α の代わりに θ を使った。\nmodel1 = Model( obs = Stochastic(1, (lambda, N) -\u0026gt; UnivariateDistribution[ Poisson(lambda[i]) for i in 1:N], false ), lambda = Logical(1, (lambda1, lambda2, tau, N) -\u0026gt; (out = fill(lambda1, N); i = Int64(tau.value) + 1; # Juliaは1-indexingのため out[i:end, :] .= lambda2; out), ), lambda1 = Stochastic(theta -\u0026gt; Exponential(theta)), lambda2 = Stochastic(theta -\u0026gt; Exponential(theta)), tau = Stochastic(N -\u0026gt; DiscreteUniform(0, N)), ) 観察されるデータと θ を準備する。θ はメッセージ数の平均の逆数 α の逆数なので、メッセージ数の平均。\ntheta = mean(count_data.messages) data0 = Dict{Symbol, Any}( :obs =\u0026gt; count_data.messages, :theta =\u0026gt; theta, :N =\u0026gt; length(count_data.messages), ) 初期値は下のようにする。今回はサンプリングのパスを3つとするので初期値も3つ用意する。\ninits1 = [ Dict{Symbol, Any}( :obs =\u0026gt; count_data.messages, :lambda1 =\u0026gt; theta, :lambda2 =\u0026gt; theta, :tau =\u0026gt; 1, ) for _ in 1:3 ] サンプリングの設定では、 \\( \\tau \\) は離散値なので DGS を使う。\nscheme1 = [AMWG([:lambda1, :lambda2], 1.0), DGS(:tau)] サンプリングを行うと、本文と同様、44, 45日後にユーザーが振る舞いを変えたというところの確率密度が高くなっている。離散値になっていないので、何か設定が間違っているのかもしれない。\nsetsamplers!(model1, scheme1) sim1 = mcmc(model1, data0, inits1, 40000, burnin = 10000, thin = 3, chains = 3) p1 = Mamba.plot(sim1[:, [:tau, :lambda1, :lambda2], :], legend = true) Mamba.draw(p1, nrow = 3, ncol = 2) \\( \\tau \\) のヒストグラムを確認すると、正しくサンプリングできているようだ。\nhistogram(vec(sim1[:, :tau, :].value), normalize = :probability, title = \u0026#34;tau\u0026#34;, label = \u0026#34;\u0026#34;) 受信メッセージ数と期待値を表示する。\nbar(0:N-1, count_data.messages, label = \u0026#34;\u0026#34;, size = [600, 200], linecolor = :transparent, xlabel = \u0026#34;Time (days)\u0026#34;, ylabel = \u0026#34;Count of messages\u0026#34;) plot!(0:N-1, vec(mean(sim1[:, :lambda, :].value, dims=[1, 3])), linewidth = 3, label = \u0026#34;Expectation\u0026#34;) コード: https://nbviewer.jupyter.org/github/matsueushi/bayesian_methods_julia/blob/master/chapter1_message.ipynb\n",
    "permalink": "https://matsueushi.github.io/posts/bayesian-methods-julia-1/",
    "tags": [
      "Julia",
      "Bayesian",
      "Mamba"
    ],
    "title": "Juliaで体験するベイズ推論(1) -メッセージ数に変化はあるか？"
  },
  {
    "contents": "「データ解析のための統計モデリング入門」第11章の空間構造のある階層ベイズモデルに挑戦する前に、まずPyMC3のIntrinsic Gaussian ModelのサンプルをMambaで実装した。\nhttps://github.com/matsueushi/lip_stick_mamba\n参考にしたMatrix Multiplicationを用いたPyMC3の実装:\nhttps://docs.pymc.io/notebooks/PyMC3_tips_and_heuristic.html#PyMC3-implementation-using-Matrix-multiplication\nPyMCのモデル\nwith pm.Model() as model3: # Vague prior on intercept and effect beta = pm.Normal(\u0026#39;beta\u0026#39;, mu=0.0, tau=1.0, shape=(2, 1)) # Priors for spatial random effects tau = pm.Gamma(\u0026#39;tau\u0026#39;, alpha=2., beta=2.) alpha = pm.Uniform(\u0026#39;alpha\u0026#39;, lower=0, upper=1) phi = pm.MvNormal(\u0026#39;phi\u0026#39;, mu=0, tau=tau*(D - alpha*W), shape=(1, N)) # Mean model mu = pm.Deterministic(\u0026#39;mu\u0026#39;, tt.exp(tt.dot(X, beta) + phi.T + log_offset)) # Likelihood Yi = pm.Poisson(\u0026#39;Yi\u0026#39;, mu=mu.ravel(), observed=O) trace3 = pm.sample(3e3, cores=2, tune=1000) は、Mambaだと下のようになる。PyMCとMambaで分布を指定するときに使うDistribution.jlではMvNormalのパラメーターの持ち方が違うことに注意。PyMCのMvNormalに該当するDistibution.jlの分布は 、MvNormalではなくMvNormalCanon。\ncar_model = Model( beta0 = Stochastic(() -\u0026gt; Normal()), beta1 = Stochastic(() -\u0026gt; Normal()), tau = Stochastic(() -\u0026gt; Distributions.Gamma(2.0, 0.5)), alpha = Stochastic(() -\u0026gt; Uniform()), phi = Stochastic(1, (tau, alpha, N, D, W) -\u0026gt; MvNormalCanon(zeros(N), tau * (D - alpha * W)), ), mu = Logical(1, (beta0, beta1, zscore_aff, phi, log_offset) -\u0026gt; exp.(beta0 .+ beta1 .* zscore_aff .+ phi .+ log_offset) ), y = Stochastic(1, (mu, N) -\u0026gt; UnivariateDistribution[Poisson(mu[i]) for i in 1:N], false ) ) サンプリングに関しては、NUTSが遅すぎるのでAWMGを使った。\ncar_scheme = [ AMWG([:beta0, :beta1, :phi], 1.0), Slice(:alpha, 1.0), Slice(:tau, 10.0), ] setsamplers!(car_model, car_scheme) car_sim = mcmc(car_model, car_data, car_inits, 21000, burnin = 1000, thin = 10, chains = 3) PyMCの場合とおおよそ同じ分布になったが、beta0 の収束がやや微妙な気がする。\nサンプリング方法を下のように変更してもbeta0の収束はあまり良くならない。何か良い方法はあるのだろうか。\ncar_scheme = [ AMWG([:alpha, :beta0], 1.0), AMWG([:beta1, :phi], 0.1), Slice(:tau, 10.0), ] setsamplers!(car_model, car_scheme) car_sim = mcmc(car_model, car_data, car_inits, 25000, burnin = 5000, thin = 10, chains = 3) ",
    "permalink": "https://matsueushi.github.io/posts/intrinsic-gaussian-car/",
    "tags": null,
    "title": "Intrinsic Gaussian CARモデルをMambaで実装"
  },
  {
    "contents": "最近、久保拓弥「データ解析のための統計モデリング入門――一般化線形モデル・階層ベイズモデル・MCMC (確率と情報の科学)を読んでいる。\n生態学のデータ解析 - 久保拓弥\nhttp://hosho.ees.hokudai.ac.jp/~kubo/ce/KuboTakuya.html\n本ではR + WinBUGSを使っているが、今回はJulia(1.1.0) + Mambaを使って実装した(10章まで)。実装はGithubに載せてある。\n実装の中身は上のJupyter Notebookを見てもらうとして、それ以外に実装していて何点か躓いたことがあったので備忘のために記載しておく。\nBinomial分布のGLM formula で指定する説明変数は、0から1の間になっている必要がある。個体の数で割って、wtsに個体の数を指定してフィッティングを行う。\ndf.yy = df.y ./ df.N df.N = convert(Array{Float64}, df.N) result = glm(@formula(yy ~ x + f), df, Binomial(), wts = df.N) モデルのグラフ表示 Mambaのチュートリアルではモデルのグラフ表示にGraphViz.jlパッケージを使っている。\nただGraphViz.jlはメンテナンスが止まっているようで、Julia v0.7以降では動かないようである。\nForneyLab.jlがGraphViz.jlの後継としてモデルのグラフ表示をサポートしているので、こちらを使用すれば良い。\nMultiprocessing Mambaは addproc でプロセスを追加して、\nusing Distributed addprocs(3) Mambaをインポートするときに @everywhere を付ければMambaが自動的にMCMCのチェインごとのサンプリングを並列化してくれる。(section10.ipynb参照)\n@everywhere using Mamba 11章の空間構造のある階層ベイズモデル(intrinsic Gaussian CARモデル)も実装できたらアップデートしたい。\n3/14追記: 11章の空間構造のある階層ベイズモデルも実装したのでアップデートした。これで一通り読破したことになるのかな？次は以前読もうとして諦めた「Pythonで体験するベイズ推論」をJuliaでやってみようか。\n",
    "permalink": "https://matsueushi.github.io/posts/julia-kubo/",
    "tags": [
      "Julia",
      "MCMC",
      "Mamba"
    ],
    "title": "Julia版「データ解析のための統計モデリング入門」読書ノート"
  },
  {
    "contents": "さて、Lolica Tonicaの記事に引き続き、メンバーの一人であるヒイラギペイジのLolica Tonica前の活動や提供曲について紹介したい。\nヒイラギペイジの名前に至るまで、PAIGE → PAGE → TemoTemoe →ヒイラギペイジと言う変遷があったと思われる。\nヒイラギペイジは一番最初はPAIGEと言う名義で活動しているニコラッパーでニコニコにラップ動画をアップしていたようだ（現在は削除されている）。\nマナツニミタユメ / PAIGE\n夢が僕の夢を叶えてくれる。9月4日に日比谷で発売したデモアルバムに収録した曲です。Track.by Salty Mixed.by Jill mylist/28073427\nhttps://www.nicovideo.jp/watch/sm15603665\nMonochrome / PAIGE\nMonochrome\nTrack.by Tiger\nLyric.by PAIGE(mylist/28073427)\nMixed.by 黒衣えすてる(mylist/8488406)\n■孤独な自分と味気ない日々について。\n■何もかも上手くいかない鬱な気持ち。\n■感情を上手く言葉にするのが苦手です。\n□耳がキンキンするというコメントがあったので、修正版mp3を用意しました。\n□a cappellaとLyricもzipに詰めときました。Remixとかもしてくれたら飛んで喜びます。宜しくお願いします。\n□http://www1.axfc.net/uploader/H/so/140127.zip\u0026amp;key=monokuro\nhttps://www.nicovideo.jp/watch/sm15244635\nMonochromeのリミックスはまだ残っていた。\n[ニコラップ] Monochrome(kome remix) / PAIGE [remix] そして2011年には閃光ライオットでグランプリを獲得しており、同じぐらいのタイミングで名前をPAGEに変えている。\nhttps://ja.wikipedia.org/wiki/PAGE_%28%E3%83%A9%E3%83%83%E3%83%91%E3%83%BC%29\nTOKYO FM「SCHOOL OF LOCK！」の呼び掛けにより集まった1万組を超える応募から、＜閃光ライオット2011＞グランプリを獲得したのは愛媛県出身の16歳ラッパーのPAIGE（ペイジ）だった。\nhttps://www.barks.jp/news/?id=1000072980\nこの頃の曲はLolica Tonicaの音楽性とはかなり違う。アルバム「ノンフィクション・ガール」に収録されている2曲目の「あ・い・ど・る」は特にチップチューンのトラックにアイドルに恋するオタク目線の妄想的な歌詞が鏤められてかなり好きである。\nまた、ヒイラギペイジは初期はTemoTemoeという名義を使っていたようだ。\nLolica Tonica is a Tokyo based duo made up of Ky7ie and TemoTemoe. Shortly after releasing a spastic club flip of Ariana Grande’s “The Way” and bright digital burst of energy called “Luv sick”, the pair were picked up by the TREKKIE TRACKS imprint to release their latest single, “Make Me Feel”.\nhttps://nesthq.com/premiere-lolica-tonica-carpainter\nLolica Tonicaの少し前はTemoTemoe名義で活動していたようで、Lolica Tonica初期はTenoTemoe a.k.a ヒイラギペイジと紹介されていたようである。\nKy7ie.とTemoTemoe a.k.a. ヒイラギペイジによる新鋭プロデューサー二人組ユニット。\nhttp://asia.iflyer.jp/venue/performer/48664?frame=1\u0026amp;keepThis=true\u0026amp;TB_iframe=true\u0026amp;height=250\u0026amp;width=600\nくそ緊張してたけどTemoTemoeが落ち着いててめっちゃ楽しくできた\n— @ky7ieee\nTemoTemoeの初期の曲は明らかにLolica Tonicaの曲調とは異なっている。\nListen to Void by TemoTemoe / ヒイラギペイジ #np on #SoundCloud https://t.co/41O13hYYYp\n\u0026mdash; くぬぎ (@fsk0122) December 28, 2014 そのちょっと後ぐらいからLolica TonicaっぽいFuture Bassの曲調になってきたようだ。\nTenoTemoe名義の曲で現在も残っているものは、FOGPAK #11に収録されているTemoTemoe — childish club\nFOGPAK #11 by TemoTemoe と、強がり Temo Temoe Remix\n同世代同士で起こる、新たな化学反応ーーとけた電球×ヒイラギペイジによる『強がり Temo Temoe Remix』ハイレゾ独占配信!!\nhttps://ototoy.jp/feature/2015081901\nそして、ニコニコ動画にヒイラギペイジのアカウント名でアップロードされている、ツギハギスタッカート(TemoTemoe Remix) / とあ feat. 初音ミク である。\nツギハギスタッカート(TemoTemoe Remix) / とあ feat. 初音ミク ボーカルカットアップこそ無いものの、キラキラシンセやビートの感触はが随所に散りばめられていてLolica Tonicaの源流が確かに感じられる。高音質で聴きたいが、mp3のリンクが切れていて落とせず、SoundCloudからも削除されている……残念。\n実は他のアーティストに提供した曲も名曲ぞろいである。\nCY8ERのシングル「リミックススタート」に含まれている「ゆびきり」は切なさ溢れる可愛い曲。\nchelmicoの最初のシングル「ラビリンス’97」はヒイラギペイジが提供している。\nRachel　転機になった人って、今ぱっと思い浮かべただけでも、いっぱいいるんです。よし、細かく言っていこうぜ。\nMamiko　今までで一番細かく言おう。まず最初にGOMESS。そこから繋がったヒイラギペイジくんは最初のシングル『ラビリンス'97』のトラックメイカー。\nhttp://news.line.me/articles/oa-rp52663/814c84e18935\nchelmicoの2ndレコードディング曲、JUNEJULYは気怠げな夏を仄めかす歌詞も相まってアルバムに収録されなかったのが不思議なくらい最高。\nohayoumadayarouのブログ\nJUNEJULY /chelmico\nhttp://ohayoumadayarou.hatenablog.com/entry/2015/09/30/110615\nファンと言いながらGOMESS\u0026amp;Page Hiiragiの配信オンリーミニアルバムは見逃してしまっており、気づけば配信が終了してしまっていた。悲しい。\n追記: サウンドクラウドに新曲(16歳の時の曲の再録だそうです)上がってました。\n追記2 (2019/06/06): https://musicsneak.live/ が閉鎖していていくつかのインタビューが読めなくなっていた。\n追記3 (2019/09/02)\nこの曲もあった。\n復活?\n3月30日（土）🌇\n平成30年度秋葉原MOGRA送迎会\nこの春から東京で新社会人、おやつです！\n秋葉原MOGRAというクラブでDJをします…よろしくね🐣📛\n🍡カレーパイセン\n🍡かのんびーつ\n🍡ギー汰\n🍡JunyaUtsunomiya\n🍡まこ\n🍡ヒイラギペイジ\n🍡RIO\n🍡ムラタナナ\n🍡おやつ ←🐰✋https://t.co/s9Jxthbs6H pic.twitter.com/BNjP9v9Qmj\n\u0026mdash; 𝙾𝚈𝙰𝚃𝚂𝚄 🐇 (@akiyoyo) March 19, 2019 https://club-mogra.jp/2019/03/30/3798/\n追記4 (2020/08/23)\ncolate · colate \u0026amp; Page Hiiragi - 渚のロンリーガール feat. みほりん [+Remix Vocals] Makoto Ota · Page Hiiragi \u0026amp; Makoto Ota - Myslee 追記5 (2022/01/10)\nTwitter, Instagramが開設されていた\nhttps://twitter.com/PageHiiragi\nhttps://www.instagram.com/pagehiiragi/\nこの投稿をInstagramで見る Page Hiiragi(@pagehiiragi)がシェアした投稿\n",
    "permalink": "https://matsueushi.github.io/posts/hiiragipage/",
    "tags": [
      "Music",
      "LolicaTonica"
    ],
    "title": "ヒイラギペイジ"
  },
  {
    "contents": "$ jupyter kernelspec list Available kernels: julia-1.1 /home/matsueushi/.local/share/jupyter/kernels/julia-1.1 python3 /home/matsueushi/.local/share/jupyter/kernels/python3 How do I add python3 kernel to jupyter (IPython) https://stackoverflow.com/questions/28831854/how-do-i-add-python3-kernel-to-jupyter-ipython/44072803#44072803\n",
    "permalink": "https://matsueushi.github.io/posts/jupyter-kernel-location/",
    "tags": [
      "Jupyter"
    ],
    "title": "Jupyter Notebookのkernelの位置を調べる"
  },
  {
    "contents": "物理セキュリティーキーが欲しかったので買ってしまった。\n公式サイトから購入し、バックアップ用と合わせて2つで$90+Tax $7.99=$97.99だった。\n良い点\n難しい設定がなく挿して押すだけで二段階認証が使える 悪い点\niPhoneでYubikeyを使おうとしても、LastPassのiPhoneアプリぐらいしかNFCに対応していない LastPassだとプレミアム会員($2/month)ではないとYubikeyが使えない ",
    "permalink": "https://matsueushi.github.io/posts/yubikey/",
    "tags": [
      "YubiKey"
    ],
    "title": "Yubikey"
  },
  {
    "contents": "Lolica Tonica (Twitter: @LolicaTonica)とはKy7ie.とPage Hiiragi(ヒイラギペイジ)からなる、 キラキラしたシンセとカットアップされたボーカルによる可愛らしい曲調が特徴的なFutureBassユニットである。 ただ可愛らしいだけではなく、時にゴリゴリのビートが同居している所もまた魅力的で、 すでに解散しているのだが、今でも再結成していないか定期的にチェックしているぐらいである。\nLolica Tonicaが活動を開始したのは2015年5月頃のようだ。名前がLolica Tonicaに決まる前は別の名前があったらしい。「ダサい」って言われるような名前、何だったんだろう……\nまぁそれはそれとしてだな、今ペイジくんとのユニット「Lolica Tonica」でテンションくそ高いブート作ってるんで、これはぜひ早くみんなに聞いてもらいたい、そしてあわよくば現場で使って欲しい\n— @ky7ieee\n【新曲】ペイジくんとのユニット「Lolica Tonica」でアリアナ・グランデの曲をREMIXしたよ！フリーDLも！ \u0026lsquo;ARIANA GRANDE - The Way (Lolica Tonica Bootleg REMIX)\u0026rsquo; https://t.co/CEO3vUp1ag\n— @ky7ieee\nLolica Tonicaだいたいこういう感じでやっていきますんでよろしくお願いします\n— @ky7ieee\nandrew Lolica TonicaはKy7ie.くんの方はLOUNGE NEO周りでDJをやってて、個人の曲も作ってて、僕はたまに喋ってたんです。でもヒイラギペイジくんと一緒に作るようになって音がだいぶ変わって。それをSeimeiがすごくいいって言って。\nfutatsuki 僕も１曲目でピンときて、Masayoshi Iimoriのプロデュースがうまくいってたんで、彼らをゼロからプロデュースしようということになったんです。会った時はLolica Tonicaっていう名前もなかったんですよ。前の名前があって、「いやそれはダサイでしょ」って言ったりとか。\nTREKKIE TRAX THE BEST \u0026ldquo;2011\u0026rdquo;-2015 トレッキー、はじまりの場所へ行く。 [ CARELESS CRITIC ]\nhttp://carelesscritic.com/sp/trekkietrax/\n本格始動し始めたのはLolica TonicaのTwitterが開設された2015年7月だろうか。\nHello, world\n\u0026mdash; Lolica Tonica (@LolicaTonica) July 22, 2015 リミックス以外でリリースされたロリトニ作品は少なく、「Lolica Tonica — Luv sick (feat. ina)」「Make me Feel EP」「Eyes on you EP」のみである。\n最初の方はリアルタイムで追っていなかったのでMake me Feelが一番最初にリリースされていたと思っていたが、2015年7月31日にリリースされたLuv sick(feat. ina)の方が先っぽい。これぞカワFutureBassって感じの曲で静から動へ盛り上がっていく感じとハイテンションなボーカルとビートの混ざり合い方が好きだ。\n映像ちょうかっこいい👉🏻 @assassin3120 Lolica Tonica - Luv sick (feat. ina) #maufes pic.twitter.com/3ddSizCDnD\n\u0026mdash; ᎪᏳᎬᏞᏫᎳ(LADY\u0026#39;S ONLY) (@AGELOW) October 25, 2015 Make me FeelがEPから先行してリリースされたのは2015年8月26日。\n9月2日リリースの予定の Lolica Tonica - Make me Feel EPより表題曲を先行フリーダウンロードで配信開始！https://t.co/i4q3eg2EvB\n\u0026mdash; TREKKIE TRAX (@TREKKIETRAX) August 26, 2015 Lolica Tonicaで一番有名な曲と思われるMake me Feelはポップで華やかなエネルギーが溢れる曲で、口ずさんでしまいたくなるボーカルカットアップも印象的。渋谷の繁華街で撮影されたPVもインターネットミュージックっぽくて良い。\nまた、この曲はSoundCloudに山のようにリミックスアップロードされていて聴き比べるのも楽しい。(リミックス素材が配布されていたことも原因らしい)\nそして、Make Me Feel EPがTRAKKIE TREXでリリースされたのが2015年9月2日。\n個人的にはEPの中ではMake me Feelも好きだけど、ボーカルカットアップが多用された4曲目のAtomic Futureが自分のツボにがっしりハマった。\nMake me Feelから1年以上経った2017年1月、満を持して2nd EPのEyes on youがマルチネからリリースされた。\n1stに比べて受ける印象が上品になって曲調もガラージっぽくなっている。Luv sickのGarage Editも収録されていてこちらも良い！Luv charmはおそらくLolica Tonicaで唯一のボーカル主体の歌モノ(ボーカルは結良まり)。\nLolica Tonica Eyes on you https://spincoaster.com/lolica-tonica-eyes-on-you\nEyes on youリリースにあたってはKy7ie.がリリースコメントを出している。Make me Feelの反響が大きすぎてハードルが上がってしまったこともあり2ndは相当難産だったようだ。\n2017.01.23 Eyes on you リリースに寄せて https://rrremixmyheaddd.tumblr.com/post/156264942359/20170123-eyes-on-you-%E3%83%AA%E3%83%AA%E3%83%BC%E3%82%B9%E3%81%AB%E5%AF%84%E3%81%9B%E3%81%A6\n普段私はクラブには行かないのだが、どうしてもLolica Tonicaを生で見たかったのでちょうどEyes on youがリリースされたのと同じタイミングぐらいでMaltine Recordsが主催していたMALTINE SEED STAGE 01というイベントに思い切って行った。\n〈Maltine Records〉のレギュラーイベント「MALTINE SEED STAGE 01」がスタート　Meuko! Meuko!、Hercelot、Miiiなどが全7組が出演 https://uncannyzine.com/posts/44744\n行って見たら会場はクラブっぽくない感じの場所で取り越し苦労だった。リリースされていた曲はほぼプレイされて、行って大満足だった。結果として、Lolica Tonicaを生で見たのはこれが最初で最後となってしまった。\nここで一旦脱線し、Lolica Tonicaのリミックス作品に触れたい。もはや別物と言っていいほどの曲の再構築が行われているところが好きである。\nLolica Tonica名義のおそらく最初の曲であるARIANA GRANDE — The Way (Lolica Tonica Bootleg REMIX)は攻撃的なビートや入り乱れるボーカルカットアップが心地よい。\n他にもSoundCloudにリミックスがアップロードされていてどれも名曲揃い。ChocoholicのリミックスEPに収録されたどこか哀愁漂うChoco Love (Lolica Tonica Remix)やchelmicoの名曲Love is Overのロリトニ的再解釈が好きである。\nそして、私がリミックスの中で一番好きなのは Henrik the Artist — Peddi Max (Lolica Tonica remix)である。\nHenrik the Artist(私はあまり詳しく知らず、すいません)のPeddi Maxという曲のリミックス企画で作られた曲のようである。\nPREMIERE: HENRIK THE ARTIST’S “PEDDI MAX” GETS 21 REMIXES FROM 21 TRUE FRIENDS\nhttps://nesthq.com/henrik-the-artist-peddi-max-remixes\nリミックス元の原形をほぼ留めていないLolica Tonica節炸裂のハイテンションなリミックスで、1曲の中でLolica Tonicaっぽい音の要素がやり過ぎってくらい詰め込まれていて、2分ぐらいから始まるなんども畳み掛けるような盛り上がり、絶妙な具合で差し込まれるサンプリングの妙味、がかなり好きでこの曲だけで数百回は聞いている。\nこれを書くまでてっきりSoundCloundでしか聞けないと思っていたのだが、(購入リンクがSoundCloudに貼られていなかった) Amazon Musicで購入できた。\nPeddi Max\nHenrik the Artist\nhttps://www.amazon.co.jp/Peddi-Max-Henrik-Artist/dp/B079524KFQ\n話を戻そう。\nLolica TonicaはEyes on youのリリース後の2017年8月、JR東日本のキャンペーンCMを担当していた。すでにキャンペーンが終了してしまったかららだろうか、YouTubeからはCMは消されてしまっているが、カワFuture Bassではなく爽やかなガラージっぽい曲調だったので意外に思った記憶がある。また聴きたい。\n【TVCM】 JR東日本『新幹線YEAR2017「みんなでつくる新幹線 長野」篇』にて、CM映像BGMの作編曲をLolica Tonicaとして担当致しました。 なんと地上波でも順次放映予定らしいです。 https://t.co/AgSXaTbPzf — @ky7ieee\nCM曲も担当し、今後ますます有名になっていくのかな、なんてぼんやり思っていたのだが、なんとこの一週間後に行われた2017年8月10日の【8.10 Thu. Anthem・MALTINE SEED BOX・GOODWEATHER × 異レギュラー】というイベントが実はLolica Tonicaとしてのラストライブであり、解散？休止？がアナウンスされたようだ。\nLolica Tonica 解散！？ #Anthem_ageHa\n\u0026mdash; mochilon/ロマンキャンセル柿本⚙ (@mochilon) August 10, 2017 え？Lolica Tonica解散するんですか\n\u0026mdash; Zekk (@zekk_wa_zetku) August 10, 2017 LolicaTonica 解散まじ！？！！？#Anthem_ageHa\n\u0026mdash; inotaku (@takkun0415) August 10, 2017 Lolica Tonica ラスト(らしい)見られて良かったー やはりかわいかった#Antem_ageHa pic.twitter.com/0fcJlEXAud\n\u0026mdash; 緑 (@turboiminashi) August 12, 2017 まさかこのタイミングで活動休止するとは思っていなかったのでまさに青天の霹靂だった。最初に言った通り、諦めの悪いことに定期的にTwitterを「Lolica Tonica」や「ロリカトニカ」で検索して何か出てこないか調べているが今の所目立った情報は見つからない。\nLolica Tonicaが再活動する夢観て嬉しくて実際に号泣しながら起きてしまったけど夢だった\n\u0026mdash; yuigot (@ygt_jpn) September 20, 2018 いきなりlolica tonica復活しないかな〜〜！！！俺が今聴きたいのは多分\nlolica tonicaの音楽！！！！\n\u0026mdash; Surfclam (@Surfclam\\__) September 20, 2018 解散後、Ky7ie.はリミックスを行うなど活動をしているようだが(情報は少ない)、ヒイラギペイジに関してはトラックメイカーとしての曲提供もなく、2018年に入ってFacebookやTwitterのアカウント(@blue_shoegazer)も削除してしまったようで、悲しい限りだ。何か情報があれば教えて欲しい。\n音楽はヒイラギペイジにとっては「退屈しのぎ」、Ky7ie.にとっては「呪いのようなもの」だったと言うことだったのだが、もはや退屈や呪いから解放されてしまったのだろうか……？\nー 音楽とは自分にとって何なのか\nPage Hiiragi：退屈しのぎ。\nKy7ie.：なくても生きていけるかもしれないけど、まともな人間として生きていける気が全然しない。\n自分という人間のあらゆる部分に染み付いてしまっているので、もう呪いのようなものかもしれません。\nhttps://musicsneak.live/artists/lolica-tonica\n(現在は閲覧不能)\n2020/8/3追記:\nコメント欄で教えてもらいましたが、3年半ぶりの新曲「Solid State」が3ヶ月限定でリリースされるようです! 教えてくださったNoVaLightさんありがとうございます。\n🔊 A N N O U N C E M E N T 🔊\n8.7 (Fri.) PDT 0:00 JST 16:00\n⚡️New release⚡️\nLolica Tonica - Solid State\n💝All the proceeds from this track will be donated to @clubasia_tokyo .\n⚠️ Limited sale for 3 months on Bandcamp 🏕\n🔜 https://t.co/N1BFUi8CYT 👈 👀#lolica_tonica pic.twitter.com/AJFSv3lcCt\n\u0026mdash; Lolica Tonica 🔊 8.7 NEW RELEASE (@LolicaTonica) August 3, 2020 📣NEWS📣｜@LolicaTonica\n\u0026quot;Ky7ie.\u0026quot;と\u0026quot;Page Hiiragi\u0026quot;による𝗟𝗼𝗹𝗶𝗰𝗮 𝗧𝗼𝗻𝗶𝗰𝗮が3年半ぶりの新曲「Solid State」をclubasia支援として3ヶ月限定リリース🎉Artworkは過去作品も手掛けた\u0026quot;rei nakanishi\u0026quot;✍️収益は全額寄付のご協力を頂きました🙇‍♂️\n2020.8.7 16:00 Sale!!\n🔜https://t.co/cd9kRDc8bf pic.twitter.com/hfN9JNr1Jv\n\u0026mdash; スー (@ShowSuzuki) August 3, 2020 Solid State by Lolica Tonica 2021/03/17追記:\nHenrik The Artist - Peddi Max (Lolica Tonica Remix)のリミックスを見つけた。\nbrutshits01 - Henrik The Artist - Peddi Max (Lolica Tonica Remix) [hallycore Flip]\nbrutshits · brutshits01 - Henrik The Artist - Peddi Max (Lolica Tonica Remix) [hallycore Flip] 祝、再始動。楽しみですね。\nTL;DR\nWe’re in the process of making our first album.\nyay 😎🙌 https://t.co/MobTysfRFK\n\u0026mdash; Lolica Tonica (@LolicaTonica) February 24, 2021 Lolica Tonica · GOKU VIBES (Lolica Tonica Remix) Lolica Tonica · TEMPLIME feat. 星宮とと - ネオンライト(Lolica Tonica EDIT) Lolica Tonica · all night (Lolica Tonica Remix) 次はヒイラギペイジのLolica Tonica前のPAGE, TemoTemoe名義での活動や、他のアーティストへの提供曲について書きたいと思う。\n",
    "permalink": "https://matsueushi.github.io/posts/lolica-tonica/",
    "tags": [
      "Music",
      "LolicaTonica"
    ],
    "title": "忘られぬLolica Tonica"
  },
  {
    "contents": "前回のマンハッタン編に引き続き、今回はブルックリン編。\nマンハッタンよりもブルックリンの方がCDが置いてある店が少なく、レコードメイン。 また、こっちの方が若者向けの店が多く活気がある印象で、ロックとかエレクトロニカなどが強い気がする。\nAcademy Records Annex アカデミーレコードのブルックリン店。 ブルックリンのレコード屋のなかで一押し。広くて綺麗で安い。\n置いてあるボリュームが相当あるので、嬉しいことに、自分の好きなジャンルの棚をじっくり見ようとすると相当な時間がかかる。\nテクノとかエレクトロニカとかハウスとかディスコとかの、ロック以外もジャンル関わらず充実しているような印象を受けた。 ライブラリーミュージックとかプライベートプレスとかマニアなジャンルも隅の方にあり、見ていて飽きない。\n店内奥の壁際の方に少しだけCDの取扱いがあるが、あまり流行っていない感じ。\n85 Oak St\nBrooklyn, NY 11222\nhttps://academy-lps.com/\nYelp : https://www.yelp.com/biz/academy-records-annex-brooklyn-2\nRough Trade NYC ブルックリンのEast River State Park近くにある。\nスタイリッシュで入りやすい雰囲気で、自分が立ち寄った時は若い人も多く活気がある。店内はとても広く、 置いてある新品LPはかなりの量があり、メジャー寄りのラインナップであるような印象。\nニューリリースの取扱いは手厚く、各レーベルのアーティスト紹介のブースもあって新しいアーティストを追いかけたいならオススメ。 隅の方に少しだけ中古LPの取り扱いがあり、あまりよく見てませんが珍しそうなものもちょこちょこ混ざっていた。 ブルックリンでは珍しく、CDの品揃えも充実していてなかなかマニアなものも置いてあった。\n二階には音楽やアート関係の本と、なぜか卓球台が置いてある。\n64 N 9th St\nWilliamsburg, NY 11249\nhttps://www.roughtrade.com/us\nYelp : https://www.yelp.com/biz/rough-trade-nyc-williamsburg\nCaptured Tracks Shop ブルックリンのGreenpoint Av駅近くにある、レコードレーベルCaptured Tracksの直営店です。階段を降りて半地下みたいな空間に店がある。\nCaptured Tracksに所属しているアーティストをはじめとしたインディー系の新譜の品揃えが魅力で、 所属しているアーティストはLPだけでなく、カセットテープも置いてある。CDの取扱いはない。 幅広く中古も取り揃えてあり、棚の上の方においてあるレア盤のジャケットを眺めるのも楽しい。\n195 Calyer St\nBrooklyn, NY 11222\nhttps://capturedtracks.com/\nhttps://www.omnianmusicgroup.com/collections/captured-tracks\nYelp : https://www.yelp.com/biz/captured-tracks-shop-brooklyn\nRecord Grouch こちらもGreepoint駅近くにある。レコードのみ。\nインディー系、ポストパンク・ニューウェイブ、エレクトロニカの新譜の品揃えがかなり充実していた。 行った時は客がかなり入っていて店員と楽しそうに談笑していて活気があるお店だった（私は会話に参加していませんでしたが……）\n986 Manhattan Ave\nBrooklyn, NY 11222\nhttp://recordgrouch.com/\nYelp : https://www.yelp.com/biz/record-grouch-brooklyn?osq=Record+Grouch\nCo-op 87 Records ブルックリンのNassau Av駅近くにある。レコードのみ。\n入口が狭かったりすれ違うのが難しいようなこじんまりとしたレコードショップだけどモダンで綺麗な佇まいで、価格も手頃な物が多い。 支払いの時にキャッシュオンリーと言われたことがあったので、現金を持っていった方が良い。\n87 Guernsey St\nBrooklyn, NY 11222\nhttps://www.facebook.com/pages/Co-Op-87-Records/175415712526474\nYelp : https://www.yelp.com/biz/co-op-87-records-brooklyn\n-\u0026gt; 2019/6/2追記 : Facebookがリダイレクトされていたので移転したかもしれない。\nhttps://www.brooklynrecordexchange.com/\nhttps://www.facebook.com/bkrecordexchange/\nNorman’s Sound and Vision Records ブルックリンのMetropolitan Av 駅から少し坂を登った左手にある。GoogleMapで検索しても出てこなくなったけど閉鎖したのかな？\n昔ながらのレコード屋という感じで所狭しとレコードが積み上がっている。ジャンルはヒップホップとかロックが多く、 他のジャンルは少なかった。ジャンル分けや整理は他のレコード屋に比べてちょっといい加減かも。\n店員はわざわざ何か探しているか声をかけてくれて親切。\n555 Metropolitan Ave\nBrooklyn, NY 11211\nYelp : https://www.yelp.com/biz/normans-sound-and-vision-brooklyn\nSecond Hand Records NYC Myrtle駅近くにあるレコードショップ。入口がちょっと自分には分かりづらかったです。レコードオンリーかな。\nディスコとかハウスとかジャズとかソウルとかが多めかな？居心地もよく、地元ブルックリンのアーティストのミニコーナーもあって見ていて楽しい。\n1165 Myrtle Ave\nBrooklyn, NY 11206\nhttp://www.secondhandrecordsnyc.com/\nYelp : https://www.yelp.com/biz/second-hand-records-nyc-brooklyn\n(2019/4/18追記)\nThe Thing リサイクルショップなのだが、奥の方に山のようにレコードが置いてあり、さらに地下には山のようなストックがあって圧倒される。 ジャンル別やアルファベット順になっておらず様々な種類のレコードがごちゃ混ぜに置いてあってカオスだが、ゴチャゴチャ度も良いものである。 埃まみれになっているレコードが多く真剣に見ていると手が汚れるのでウエットティッシュがあるといいかもしれない。(あとは、お気に入りの服を着ていかないとか)\nレコードは状態が悪いものもあるが、1枚$2と格安。CDは$3だった。\nカセットとかCDとか昔の雑誌とかVHSとか、レトロな商品が満載で面白いお店である。\n1001 Manhattan Ave\nBrooklyn, NY 11222\nYelp : https://www.yelp.com/biz/the-thing-brooklyn\n",
    "permalink": "https://matsueushi.github.io/posts/blooklyn-record-store/",
    "tags": [
      "Music",
      "Record"
    ],
    "title": "ブルックリンのレコードショップ"
  },
  {
    "contents": "今ニューヨークで暮らしていて、交友関係が皆無に近く旅行もそれほど好きではないのでレコードショップを巡っているので、 自分用まとめも兼ねて今まで行ったレコードショップをまとめたいと思う。\nもともと日本でCDをちょくちょく購入していたが、マンハッタンやブルックリンだとCDはそもそもショップで扱っていないところも多く、 置かれていても棚を眺めている人や購入している人は少なく、商品はあまり入れ替わっていないように感じる（クラシックだとまだ少し残っている印象はありますが)。 そのためCDという媒体に活気があまりないため、レコードプレイヤーを買ってレコードを見るようにした。\n新品LPの標準的な価格は20ドルくらいで日本よりもだいぶ安く、中古に至っては10ドルしないことが多い（クリアランスだと1ドルとかで置いてあったりする)。 食べ物とか他の物価が高いことを考えると気楽にレコードが買えるような価格設定だと思う。\n新規開拓したら随時更新したいと思う。順番は適当です。\nGeneration Records Bleecker St駅、Houston Street Station駅から等距離くらいかな？少し歩く。\n綺麗にジャンルごとに分かれて整理されていて見やすく、取り扱いのジャンルや量も豊富で、価格も手頃。 僕が訪れた時は平日夜にも関わらず賑わっていて、土日に行った時も幅広い年齢層の人が集まっていた。 一階と地下に分かれていて、一階はロック系の新譜・中古の取り扱いが充実し、 階段を降りて地下に入っていくとヒップホップとかソウルとかディスコとかサウンドトラックとかが揃っている。 （最初入って行く時ちょっと勇気必要だったけど……）\nこの店は珍しく中古CDがそれなりの量置いてあり、カセットやポスターの取り扱いもされている。\n210 Thompson St\nNew York, NY 10012\nhttp://www.generationrecordsnyc.com/generation/generation.html\nYelp : https://www.yelp.com/biz/generation-records-new-york\nAcademy Records \u0026amp; CDs 23th St駅で降りて少し下って18th St, 5Avと6Avの間にある。 似た名前のAcademy Recordsというのがマンハッタンとブルックリンにあるが、ホームページが異なるので多分系列店ではないはず。\nクラシックやジャズのCD、LPが他のショップに比べ充実しているのが特徴で、お客さんの年齢層も若干高め。 珍しくCDがしっかりと（レコードの隅に追いやられるような形ではなく）陳列されているお店。 佇まいとしては日本のディスクユニオンのクラシック館のような雰囲気。\n12 W 18th St\nNew York, NY 10011\nhttp://academy-records.com/\nYelp : https://www.yelp.com/biz/academy-records-and-cds-new-york\nAcademy Records (マンハッタン店) 1st Av駅から近い。レコードのみ。ブルックリンに姉妹店があり、自分の中では広さや品揃えの点でこちらが支店で、ブルックリンが本店という印象。\nブルックリン店よりも店内は小さく、ジャズとか古いロックとかクラシックの取り扱いが多い。 ロックとかディスコとかヒップホップとかエレクトロニカとかはブルックリンの方が充実していて、 マンハッタンとブルックリンの店でジャンルの住み分けをしていると思われる。\n415 E 12th St\nNew York, NY 10009\nhttps://academy-lps.com/\nYelp : https://www.yelp.com/biz/academy-records-new-york\nBookoff 45th St、5Avと6Avの間にあり立地はかなり良く、日本のブックオフとほとんど同じような感じで音楽以外にも本やらゲームやらDVDやら電化製品やら色々扱っていて、日本語の本や漫画が置いてあるフロアがある。\n音楽に関してはCDの取り扱いのみでレコードの取り扱いはないはず。CDの取り扱いに関してはニューヨーク、マンハッタン通して一番あるような気もする。 ただ、日本のブックオフ同様、陳列されているものがあまり選別されていない印象を受け、掘り出し物を見つけたいなら根気よく探す必要がある。\n日本のアーティストだけは抽出されて別のコーナーに配置されていたはず。最近の流行曲のCDはほぼなく、 仕事でニューヨークに来た日本人が日本から持って来たけど売ったと思われる過去のヒット曲のCDがたくさん置いてあるので眺めているとなんだか懐かしい気持ちになる。\n49 W 45th St\nNew York, NY 10036\nhttps://www.bookoffusa.com/\nYelp : https://www.yelp.com/biz/book-off-new-york\nLimited to One Record Shop コンパクトだが店内の雰囲気も置いてあるものもこだわりが感じられるお洒落な店。\n置いてある物はレアもの(廃盤、ファーストプレスなど)などが非常に多く厳選されている印象で、レコードのセレクトショップと言ったら良いだろうか。 レコードの扱いは丁寧で全て綺麗にビニールに包まれている。眺めてみたところコレクター商品が多いだけあって値段の方はお高めだが、珍しいものに巡りあえるかも。\n221 E 10th St\nNew York, NY 10003\nhttps://www.limitedtooneshop.com/\nYelp : https://www.yelp.com/biz/limited-to-one-record-shop-new-york?osq=limited+one\nA1 Records Academy Recordsから少し南下したところにある。レコードオンリー。\n歴史あるレコード屋という雰囲気で趣がある。\nロック、ソウル、ファンク、ヒップホップ、ディスコ、エレクトロニカ、それぞれのジャンルで相当な品揃えがあり、 店の広さもそれなりにある上、棚にレコードがぎっしり詰め込まれているのでいくら時間があっても足りない。\n439 E 6th St\nNew York, NY 10009\nYelp : https://www.yelp.com/biz/a1-records-new-york\nGood Records NYC Astor Pl駅が最寄駅。洗練された雰囲気の小さなお店です。\n扱いはレコードのみで、ソウル、ジャズ系の品揃えが良い気がする。値段は少し他の店より高めなんですが、品揃えが独特というか、あまり他で見たことないような珍しい感じのものが多くストックされていて、再訪したくなる良い店。\n218 E 5th St\nNew York, NY 10003\nhttps://goodrecordsnyc.com/\n-\u0026gt; 2019/6/2追記: 閉店して Stranded Recordsに変わったようです。\nGood Records Closing In East Village, Stranded Records Taking Over http://gothamist.com/2019/03/11/good_records_east_village_closing.php\nYelp : https://www.yelp.com/biz/stranded-records-nyc-new-york\nHouse of Oldies Rare Records おじいちゃんとおばあちゃんが二人で経営しているのでしょうか、相当昔からやっているんだろうなというビンテージ感のある店。\n通路ですれ違うのもやっとこさというぐらいの小さい店なのですが、ギッシリと詰め込まれたレコードの密度に圧倒。 壁に大量にストックされている7インチは売り物でしょうか……聞けず。50~70sのロックの品揃えが多かった。 Rare Recordsと名前を冠しているだけあり、値段は$20~の物が多く高め。\n35 Carmine St\nNew York, NY 10014\nhttp://www.houseofoldies.com/ http://www.houseofoldies.com/about.html\nYelp : https://www.yelp.com/biz/house-of-oldies-new-york\nWestsider Records 珍しくアッパーウェストにあるレコード屋。 記事に出てくるレコード屋の中で一番歴史があるのではないだろうか、中に入るとタイムスリップしたかのような古さ・埃っぽさがあった。\nクラシックとかジャズのLP/CDが山ほどあり、あとは戯曲の脚本もたくさん置いてあり珍しい趣向。\n233 W 72nd St\nNew York, NY 10023\nhttp://westsiderrecords.com/\nYelp : https://www.yelp.com/biz/westsider-records-new-york\nVillage Music World 店員さんはかなり親切で店に入ったら話しかけてくれた。わりとオーソドックスなロックとかジャズの品揃えが多かったような……\n197 Bleecker St\nNew York, NY 10012\nYelp : https://www.yelp.com/biz/village-music-world-new-york\n",
    "permalink": "https://matsueushi.github.io/posts/manhattan-record-store/",
    "tags": [
      "Music",
      "Record"
    ],
    "title": "マンハッタンのレコードショップ"
  },
  {
    "contents": " \\\nカッチリした硬質のビートが刻む複雑なリズム、ひんやりとしたメロディ。簡潔でミニマルだが、隙のないほどに知的なテクノだと思う。\n90年代のアナログ感満載のちょっとこもった感じの音もどこか懐かしい。\nアルバムの中でも、冒頭曲Object Orientの畳み掛けるような性急なリズム、奇妙な展開は特にお気に入りだ。\n聞いていると頭にビートが染み込み、電子の海を漂っているような気分になる素晴らしい一枚。\n",
    "permalink": "https://matsueushi.github.io/posts/bdp-bytes/",
    "tags": [
      "Music",
      "BlackDogProductions"
    ],
    "title": "Black Dog Productions - Bytes (1993)"
  },
  {
    "contents": " 最近はすっかり暑くなってきていよいよ夏本番という気がするが、この季節になるとBOaTを聴きたくなる。\n2001年に解散した後相当時間が経ってからバンドを知ったのでリアルタイムにリリースやライブを体験することはできなかったが、マイフェイバリット邦楽バンドTOP3に必ずランクインするほど好きなバンドだ。もしタイムマシンを1回だけ使うことができて好きなバンドの解散ライブを見ることができたらおそらくBOaTの解散ライブに行くだろう。 マイナーバンドなので好きなバンドを聞かれた時にBOaTの名前は基本的に出さないけども、酔っ払って気分が良くなっているときには、ふーんそうなんだ、聞いたことないけど、と言われるのを承知で喋ってしまう。\nBOaTが残した音源は少ない。オリジナルアルバム4枚(フルーツ☆リー、SOUL.THRASH.TRAIN、LISTENING SUICIDAL、RORO)とシングル数枚、コンピレーションに提供した曲ぐらいだ。どれも素晴らしいのだが、その中でもラストアルバムであるROROは一際輝く屈指の名作である。\n3枚目までのポップでファンキーなミクスチャーロック路線とは大きく変わり、3枚目のLISTENING SUICIDALに見え隠れしていたプログレ方面のアプローチが進化し、曲は長く、シリアスで叙情的になっている。\n夏の到来を告げるようなオーガニックな雰囲気を漂わせながら一曲目のAllが始まる。気分がゆっくりと高まってきていつの間にかROROの奇妙でポップ、そしてエモーショナルな世界観に引き込まれている。\nAkiramujinaはインスト曲で、ギターロック系の轟音ポストロックといった雰囲気。混沌かつ清冽な音がうねりながら変化していって、テンション高く暴れまわるギターとポップなメロディの融合が織りなすサウンドスケープには胸打たれる。\nそして続くRoots Of Summerは繰り返されるサビが聞いてて心地よく、爽やかかつめちゃくちゃポップな胸キュン曲。途中まで溜めて溜めてサビのところで一気に爆発してポップになる感じ、白熱するテンション、絶妙なバランスで絡みつくツインボーカルがスーパーエモーショナルで思わず歌い出しそうになる。「アキラムジナ吸って　夏を裏付けた」というどういうことか良くわからない歌詞も頭に残って印象的。何よりも、アインのキュートなボーカルが特徴的な、ラストで繰り返されるサビで味わう高揚感が最高だ。\nRummy Nightは前作LISTENING SUICIDAL (こちらのアルバムも名盤である) の初回限定版8cmに収録されているNIGHT HAWK NIGHTがさらに進化したようなポストロック風味の曲で、夜の静謐さが徐々に混沌へと変わっていくような印象で、美しくサイケデリックだ。\nTuesdayは長尺のプログレ調のインスト曲。2曲めのAkiramujinaもその点は共通するが、Akiramujinaがだんだんとテンションが上がって高揚していくような盛り上がり方をするのとは対照的に、Tuesdayは聞いているうちに、より深く、自分の内面に染み渡っていくような昂りを覚える。特に、曲の半ばで一旦静けさを取り戻してからの後半部分の盛り上がりが神懸かっていて、無情感とか喪失感とか寂寥感とか、夏の終わりに伴う感情がごちゃまぜになって押し寄せてくる。ROROを聞いているときの精神的な盛り上がりのピークはTuesdayの後半で間違いないと思う。\nCircle Soundはアルバムのラストを締めくくるポップチューン。イントロのトゥルトゥトゥトゥル〜ですでに最高なんだけど、揺らめくようなAメロ、Bメロから突入するテンション爆上がりのサビ、途中のギターソロも涙が出そうなほどカッコ良く、花火がパッと打ち上がって終わるような余韻で終わるところも好きだ。Listen to the light and don\u0026rsquo;t forgetという歌詞もお気に入りで、blogのタイトルはここから取っている。\nこのアルバムには初めは大人しめのムードで始まって徐々に気持ちを盛り上げるタイプの曲が多いが、全ての曲の盛り上げ方が自然でいつの間にか気持ちよくなっているのが不思議だ。うまく言葉にできないが、聞いてると妙にノスタルジックな気分になるというか、自分の奥深くの内面が揺れ動く気がする。\nAllで始まりCircle Soundで終わる、アルバムの中に夏の始まりから終わりがギュッと閉じ込められていて一つの流れになっている。僕の中で夏を裏付けるアルバムと言えばまさにこれであり、初めて聞いた時から何年も経っているが未だによく聞くアルバムでその度に良さを確認している。\n一つ悲しいことは、BOaT関連のCDが軒並み廃盤になっているのでこのアルバムに出会いづらいということだ。\nフルーツ☆リーとソウルスラッシュトレインに関してはAmazonマーケットプレイスで1000〜2000円ぐらいで買えるし、Apple MusicやiTunes Storeで聴けるのでハードルはそれほど高くない。\nLISTENING SUICIDALや(肝心の)ROROは、iTunesには無いので渋谷TSUTAYAやジャニスなどに借りに行くか、高い(ROROだと5000円〜ぐらい)がマケプレやディスクユニオンで買うしか無いと思われるのでちょっと大変。しかし、音楽好きならばコストや手間を払ってまで聞く価値があると思うし、その中でも特にROROは奇跡を感じるアルバムだと思う。\nAll\nAkiramujina\nRoots Of Summer\nRummy Night\nTuesday\nCircle Sound\n2020/08/30追記:\nBOaT まとめ を作りました。\n2022/07/18追記：\nBOATのROROがリリースされて本日で丸20年。ROROが成人(人じゃないけど)とAxSxEさんに連絡したら興奮気味の返事来たる。部屋にROROのアナログ盤を20年も飾り続けている事になるのだな。NATSUMENのライヴが観たいですと伝えました。またブッキングしたい。 pic.twitter.com/LT9e3Myk9Q\n\u0026mdash; 佐藤則之 (@rideononon) April 10, 2021 再発願う！\nBOaT「RORO」など3作をワーナーミュージックがサブスク解禁 https://natalie.mu/music/news/489185\nサブスク解禁されました。みんな聴きましょう。\n",
    "permalink": "https://matsueushi.github.io/posts/boat-roro/",
    "tags": [
      "Music",
      "BOaT"
    ],
    "title": "BOaT - RORO (2001)"
  },
  {
    "contents": " \\\n挫・人間の2ndアルバム、テレポート・ミュージック。 僕が良くやりがちなパターンなのですが、いろいろ聴きたい音楽を調べているうちにYouTubeで「セルアウト禅問答」のPVを見てフォーリンラブ、Apple Musicで一聴してすぐCD買った。\n\\\n歌詞に出てくる「ナゴムの遺伝子」だとか「グミチョコ」だとか「美術館で会った人です」だとかラノベっぽいタイトルのM5「可愛い転校生に告白されて付き合おうと思ったら彼女はなんと狐娘だったので人間のぼくが幸せについて本気出して考えてみた」とかちょくちょく入れ込んでくるサブカル感、そしてアルバムに共通する自意識過剰をこじらせてしまったタイプの妄想的な世界観、引きこもりサブカルこじらせタイプ（僕）は強烈なシンパシーを感じてしまった。\n\\\nストレートに無条件に「アイラブユー」と言いたい自分自身の愛情表現と、それを冷静に見つめる超自我的の二つが葛藤を繰り返す自意識のぶつかり合い。\nラップバトルっぽい「下川 vs 世間」では自分が脳内で作り上げた世間との脳内バトルが繰り広げられるところとか聞いてると「うわ、めっちゃわかる……」となり、同時に自分の頭の中が覗き見られてるようで恥ずかしい。\nこのアルバムで最終的に辿り着いた着地点が例えばセルアウト禅問答でのヤケクソの「アイラブユー」だったというところも好きなんですよね。\n中心にあるのが「アイラブユー」である点が、自分の「敵」に対する脳内の憎しみをグツグツと煮詰めたような前作の「苺苺苺苺苺」とは少し違うと思う。楽曲的にも世界観的にも段違いにポップになってて、(いい意味で)J-POPとして聞いてて楽しい。メタな視点からこじらせの気持ち悪さ（？）をバカバカしさに変換することに成功しているので、マイルドながらもちゃんとこじらせてる（？？？）ので「前作より丸くなったよね笑、ちょっと物足りないかな」みたいなのとも違うし。\nライブも行って、イメージに違わぬ妄想爆発ぶりで、そこいらに溢れる凡百の軟弱シティポップバンドなんか比べ物にならないほど最高に良かった。\n9月に出る新譜も本当に楽しみで、早く聴きたい。\n",
    "permalink": "https://matsueushi.github.io/posts/zaningen-teleport/",
    "tags": [
      "Music",
      "Zaningen"
    ],
    "title": "挫・人間 - テレポート・ミュージック (2015)"
  },
  {
    "contents": " アメリカ、サンフランシスコで活動していたバンド、Girls。活動期間は2007-2012年と短く、僅か2枚のスタジオアルバムと1枚のEPを残し解散してしまった。バンド名こそガールズだが、クリストファー・オウエンスとジャック\u0026quot;JR\u0026quot;ホワイトの男性2人のバンドだ。\nGirlsが残した2枚のアルバムは大変な傑作なんだけど、今回は特に僕が愛してやまないファーストアルバム、Albumについて書きたい。\nまず内容以前にコンセプトが好きで、バンドの名前がGirlsでアルバムのタイトルがAlbumって言うのが、何でも検索しちゃう今時の風潮に対して斜に構えている感じてイカしてるし、白をベースにした限りなく簡潔なアートワークもいい。余計な情報を頭に入れるより、まずは音源を聞いてくれ、みたいなメッセージなのかもしれない。\nLust For Lifeのイントロを一聴すればわかる。何かが始まる感覚っていうか、聞いているうちに楽しい世界に誘ってくれるようなワクワクや期待が詰まってて、でもどこか寂しげで心が揺さぶられて、バックコーラスが始まるころには思わず走り出したくなってしまうような特別な曲。\n\\\nHellhole Ratraceの大げさなまでに感情を込めてくる感じ、i don\u0026rsquo;t want to die～～って思わず歌いたくなる。\n\\\nMorning Lightは 部屋の中で大音量で流したい、退廃的な儚い夢のムード漂うシューゲイザー調の曲。不安げなイントロから始まり、暴力的なフィードバックギターと甘く浮遊感のあるボーカルが絡み、中盤からはただただフィードバックギターのメロディが繰り返され、無常感がある。かわいい女の子とメンバーがじゃれ合ってるPVもどこか寂しげで曲調にマッチしている。\n\\\nハイプだとかデモテープっぽいとか50/60sのポップソングのパクリとかいろいろ言われてたけど、むしろ、このデモテープっぽい荒削りさは魅力だと思うし、40s,50s,60sのエッセンスを現代に引き直しただけの単なる模倣でははないことは明らか。\nパンク、バラード、シューゲイザー、オルタナ、ネオアコなど様々なジャンルの要素をアルバムから感じるし、クリストファー・オウエンスのボーカルスタイルも、HeadachやLauren Marieでは甘ったるく優しく、Big Bad Mean MotherfuckerやSummertimeではおどけた歌い方をしたりと、幅広さを感じるアルバム。 とにかく聞いていて切ない気分になって心酔しちゃう、感傷に浸りたい時に真っ先に聞きたくなる一枚。人によって好みが別れるアルバムだと思うけど、Lust For Lifeを聞いて気に入ったらぜひアルバムを通して聞いて欲しい。\n",
    "permalink": "https://matsueushi.github.io/posts/girls-album/",
    "tags": [
      "Music",
      "Girls"
    ],
    "title": "Girls - Album (2009)"
  },
  {
    "contents": " \\\nジャケットでにこやかにチェックシャツを着てピースしているのが、カナダ出身、1990年生まれ(若い!)のシンガーソングライター、Mac Demarco。見た目で判断するのはあまり良くないとは思うけど、この愛嬌ある見た目！このちょっと子供っぽい感じ！聞く前から楽しい予感がしてくる。\nINTERVIEW:\nMAC DEMARCO: “I’VE REELED IT IN A LITTLE BIT, BUT NOT THAT MUCH”\nhttp://diymag.com/2015/08/08/mac-demarco-interview-ive-reeled-it-in-a-little-bit-but-not-that-much\nこの\u0026quot;2\u0026quot;、郷愁を感じるサイケデリック・ポップで、肩の力の抜けた、自然体のユルさが絶妙に心地よい。\n僕が一番アルバムの中で好きなのはお気に入りのタバコについて唄ったOde to Viceroy。\nAnd oh, don\u0026rsquo;t let me see you crying\n\u0026lsquo;Cause oh, honey, I\u0026rsquo;ll smoke you \u0026rsquo;til I\u0026rsquo;m dying\nこの部分最高。\n\\\nMy Kind of Womanなんて20代前半とは思えない哀愁が漂っている。\n\\\nちょっと疲れた時に気楽に聞きたくなる癒やしの一枚。くたくたになって帰ってきても、このアルバムを流すと部屋全体がやすらぎの空間になる感じ。是非一度生でライブを見てみたい。\n",
    "permalink": "https://matsueushi.github.io/posts/macdemarco-2/",
    "tags": [
      "Music",
      "MacDemarco"
    ],
    "title": "Mac Demarco - 2 (2012)"
  },
  {
    "contents": " ドイツの実験電子音楽グループOvalの4thアルバム、94 Diskont。 このアルバムは何と言っても1曲目のDo Whileの存在感が際立つ。\n温かい電子音の曖昧な揺らめきの反復が生み出す、しこたま飲酒してフラフラになって眠くなっている時のように感じるような、ドラッギーな酩酊。24分間にわたって繰り返されるアンビエントノイズは、聞いているうちに夢のなかに誘い込まれそうなほど幻想的で美しい。\n他にアルバムに収録されているCommerce ServerやShop In Stoneは、単体で聞けば結構いい曲だが、曲の長さが短くDo Whileのトリップ感を味わう前に曲が終わってしまうので、前半どっぷりとDo Whileの世界観に浸かってからアルバム後半を聞いていると若干物足りなく感じてしまうこともあるかもしれない。\n音源ソースを収録してCDの記録面をマジックペンで汚したり、カッターナイフで傷をつけたりして音飛びを発生させるなどの手法が用いられ、リリース当時は賛否両論だったらしい。\n人によってはずっと同じような音が流れているように聞こえて退屈に感じるかもしれないが、騙されたと思ってまずは一度、24分間、揺らぎながら変化していく音響に耳を傾けて欲しい。\n",
    "permalink": "https://matsueushi.github.io/posts/oval-94-diskont/",
    "tags": [
      "Music",
      "Oval"
    ],
    "title": "Oval - 94 Diskont (1995)"
  },
  {
    "contents": "New Orderの来日公演に行ってきた。New Orderを生で見るのは初。\nNew Orderに興味を持った時期はアジカンのナノムゲンコンピレーション(アッシュとかエルレガーデンとかの曲が入ってる青いジャケットのやつ)を買って、洋楽に興味を持ち始めた頃なので高校2年ぐらいだったと思う。YouTubeで色々探している間にCrystalのミュージックビデオにたどり着いた。\n\\\n曲がカッコいいし演奏している人もイケてる感じだしこれは総合的に良い感じなのでは……？と思い、Crystalが収録されているGet Readyというアルバムを即座に購入した。\nその時引っかかったのは、Amazonのレビューか何かに「New Orderを初めて聞く人にはこのGet Readyはおすすめ出来ない」と言った内容のレビューがあったこと。\n「こんなに今風のイケてる感じなのに何言ってんだコイツ」と脳内にハテナマークが浮かんだが、好き嫌いは人それぞれなのでこういうことはよくあるから気にしないで聞いていた。\nしかし、YouTubeでNew Orderのライブ動画を検索しているとおかしなことに気づく。\n\\\nおじさんが謎のダンスをしていたりジャンプしてワオ！とか言ってる感じ、カラオケではしゃいでるおじさんと同じだし、CrystalのPVのアップツーデートな雰囲気と全然違うし、そもそも顔と体型が根本的に違わないか？曲がなんというかスカスカに聞こえるし、歌も特別上手いわけじゃないし、どういう事なんだ……\n調べてみると、CrystalのPVに出てくるイケてる人たちはNew Orderのメンバーでもなんでもない若いイケてる役者で、本当のNew Orderのメンバーは(当然だが)ライブ映像に出てきた冴えない感じのおじさんたちで、完全に騙されていた。\n実はGet ReadyはNew Orderが一度解散した後、復活作としてリリースされたもので、キャリアの中では異色な作品だったということが色んな曲を聞いているうちに分かってきた。\nNew Orderで一番有名な曲、Blue Monday。最初に聞いた時は印象的なリズムと憂鬱な雰囲気にびっくりした。\n\\\n花のジャケットが美しいセカンドアルバム、Power,Corruption \u0026amp; Lies(邦題:権力の美学)のラストに収録されている、美しく哀愁あるLeave Me Alone。\n\\\n不審者がビンタしあっているシーンから始まる意味不明なPVも印象深いTrue Faith。\nリズムマシンが生み出す無機質なリズム、チープなシンセが奏でるちょっと物悲しい美しいメロディ、ペラペラなギター、目立つメロディアスな高音ベース、ヘロヘロのあんまり上手くない歌の組み合わせが絶妙で、すべてが微笑ましく、愛おしく聞こえてくるんですよ。\nNew Orderの他のアルバムも買って聞いて、全身バンドであるJoy Divisionもそのつながりで聴くようになって、ニューウェーブとかポストパンクとかいったジャンルのCDを集めるようになったのだった。\n知った当初はメンバー同士の不和で解散状態だったんだけど、4年前ぐらいに再結成していた時は嬉しくなったものだ。ベースのフッキーが脱退したことになっていて悲しかったが。\nそんな経緯もあり、10年ぶりの新作、29年ぶりの単独公演となれば狂喜乱舞しないわけがないでしょう。初めて知ってから8年……長かった。\n楽しみすぎて会社の有給取って、午前中は部屋でNew Orderの曲を聴き続けて、18時会場なのに1時間半も早い16時30分に駅に集合。そこは不毛地帯新木場、居酒屋が空いているわけでもないのでコンビニで酒買って駅前の植木を囲んでいる変な石の上でビール飲んで、それでも時間が若干余ったのでハトと戯れた。\nそして向かった新木場STUDIO COAST。驚くほどおじさん(とおばさん)の率が高い。つまりはおじさんの青春なのだ！親に強引に連れてこられたと思しき子供を見かけたが、子供だったらももクロとか嵐とか西野カナとか聞きたいだろうに……笑\nおじさんとともに入場し開演を待つ。開演が1時間押して始まったのが20:00。メンバーが出てきた瞬間興奮して全部どうでも良くなっちゃったけど。\n1曲目は新作Music CompleteからSingularity。1曲目からフロアの沸きが凄いし、思ったより演奏が下手じゃない！ 続いてRegretのイントロが流れた瞬間懐かしさがこみ上げてきて、おじさんたちと一緒に大合唱。\nそして Crystalの演奏中には後ろのスクリーンに僕が騙されたCrystalのPVがそのまま流れるという(僕個人にとって)感動の演出があり、PVの偽メンバーとステージ上のメンバーを見比べながらテンション上がってました。\n途中ずっと思ってたのですが、バーニーのギターを持たず歌っている時の「おじいちゃんがカラオケボックスで歌っている」感じ、本当にかわいい……（意味不明）\n本編ラストのThe Perfect Kiss, True Faith, Temptationの三連チャンは本当に盛り上がった。\nアンコール1曲目はBlue Monday。ただただカッコいい。バーニーがジリアンに歩み寄って並んでシンセを弾く微笑ましいシーンも。\nそのあとJoy DivisionのLove Will Tears Us Apartが流れて「Joy Division Forever」の文字とともにイアン・カーティスの写真が画面に出てきた時はちょっとしんみりした。\n最後、新しいアルバムの曲のSuperheatedで終わったのも、まだまだ俺たち現役だぜって感じでよかった。\n思い出補正もあるとは思うんだけど、本当に見れて良かった。Your Silenct Faceでピアニカを吹くバーニーでは思わず涙が出そうになったし、Tutti Frutti、Plasticとか、新しいアルバムからバチッとダンスミュージックを決めてきたところはめっちゃ盛り上がった。\nずっとファンで好きだったのに実際直接見てヨボヨボさにがっかりしたらどうしようなんて思ってたけどそんな心配を吹き飛ばすような最高のステージだった。そして、死ぬまでに、フッキーが戻ったオリジナル・メンバーのNew Orderのステージを見たい！\n",
    "permalink": "https://matsueushi.github.io/posts/new-order-coast/",
    "tags": [
      "Music",
      "NewOrder"
    ],
    "title": "New Order@新木場STUDIO COAST, 2016/5/25(水)"
  },
  {
    "contents": " \\\n渋谷系バンドCymbalsの1stアルバム、That\u0026rsquo;s Entertainment。 Cymbalsのメンバーは土岐麻子、沖井礼二、矢野博康の三人。1997年に結成、当初のコンセプトは「かわいくっていじわるな感じのバンド。ただしパンク」。 2003年12月に解散を発表し、今はそれぞれソロで活動中、とのこと。\nPOPで楽しくて爽やかで、おしゃれなギターポップ。聞いてるとなんとなく都会的な育ちの良さを感じる。 ジャケットとかのアートワークが洋楽っぽくて、歌詞は英詩の割合が多くてちょっと背伸びして「気取ってる」ところも可愛くてなんかいい。 フリッパーズ・ギターの1枚目の斜に構えた(失礼)英詩の感じとはちょっと趣が違って、素直。\n明るい日差しの中、芝生の上で寝転がりながら聞くWhat A Shiny Day！\nシャレオツな喫茶店のテラスで飲むメロンソーダフロート、雲ひとつ無い晴れた日の昼間、My Brave Faceのイントロの軽快な口笛を吹きながら川沿いの堤防でサイクリング！\nま、実際はメロンソーダは注文しないし、サイクリングなんか行かないんだけど、そんなことはどうでもいいんですよ！！！圧倒的なポップセンス最高！\nCD、Amazonにはなかったけどタワーレコードには置いてるのでタワレコに急げ！！！！\n",
    "permalink": "https://matsueushi.github.io/posts/cymbals-entertainment/",
    "tags": [
      "Music",
      "Cymbals"
    ],
    "title": "Cymbals - That's Entertainment (2000)"
  },
  {
    "contents": "自分用のメモです。\nWAの時に確認すべきこと 問題文は正しく読めているか？ オーバーフローしていないか？ 998244353や10^9+7で割った余りを求めるタイプの場合、余りを取っているか？ 負の値を足している時、res = (res % P + P) % Pのようなケアをしているか？ 二分探索をしている時、最小値、最大値に到達できるか？ 区間和 アルゴリズムと数学　演習問題集 041 俗にいう「いもす法」\nDFS ABC 138 D - Ki E - Ranges on Tree D - Takahashi Tour 木を辿る\nABC 220 F - Distance Sums 2 BFS ABC 151 D - Maze Master ABC 088 D - Grid Repainting Bit全探索 ABC 147 C - HonestOrUnkind2 区間スケジュール問題 キーエンス2020 B Robot Arms ぐるぐる遷移していくやつ アルゴリズムと数学　演習問題集 062 - Teleporter DP ABC 154 E Almost Everywhere Zero 1次元\nAGC 034 A - Kenken Race 2次元\nABC 183 E - Queen on Grid AGC 043 A - Range Flip Find Route ナップザック問題 ABC 153 E - Crested Ibis vs Monster 数列 数列の連続する項目が離れている条件-\u0026gt;累積和\nABC 253 E Distance Sequence ダイクストラ ABC 252 E Road Reduction ワーシャルフロイド ABC 079 D - Wall 橋 橋（bridge）検出アルゴリズム - nupiocaの日記 ABC 075 C - Bridge Fenwick Tree ABC 254 F - Operations on a Matrix 括弧 ABC 064 D - Insertion 約数 ABC 134 D - Preparing Boxes 素数 ABC 084 D - 2017-like Number 三角形 ABC 143 D - Triangles 円の交点 アルゴリズムと数学　演習問題集 035 - Two Circles LCA 蟻本 pp.292\n\\(d(u,v)=depth(u)+depth(v)-2depth(lca(u,v))\\)\n競プロ典型90問 35日目解説@e869120 マンハッタン距離 45度回転が有用。\nABC E - Dist Max チェスのナイト 斜めに動くとわかりづらいので、座標変換を行う。 $$ \\begin{aligned} \\left( \\begin{matrix} x \\\\ y \\end{matrix} \\right) = \\left( \\begin{matrix} 1 \u0026amp; 2 \\\\ 2 \u0026amp; 1 \\end{matrix} \\right) \\left( \\begin{matrix} s \\\\ t \\end{matrix} \\right) \\end{aligned} $$ だから、逆変換 $$ \\begin{aligned} \\left( \\begin{matrix} s \\\\ t \\end{matrix} \\right) = -\\frac{1}{3} \\left( \\begin{matrix} 1 \u0026amp; -2 \\\\ -2 \u0026amp; 1 \\end{matrix} \\right) \\left( \\begin{matrix} x \\\\ y \\end{matrix} \\right) \\end{aligned} $$ を考えることにより縦横の単純な移動に変換する。\n蟻本 pp.353 Endless Knight アルゴリズムと数学　演習問題集 052 - Knight ",
    "permalink": "https://matsueushi.github.io/atcoder/memo/",
    "tags": [
      "AtCoder",
      "CompetitiveProgramming"
    ],
    "title": "AtCoderメモ書き"
  }
]
